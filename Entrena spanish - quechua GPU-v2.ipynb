{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2c67e2e",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gold; background-color:black; padding:20px\">TRADUCTOR QUECHUA - ESPAÑOL / ESPAÑOL - QUECHUA</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e263aaa4",
   "metadata": {},
   "source": [
    "<h1>Importar librerias a utilizar</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9ecb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea182627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd6966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809fdacb",
   "metadata": {},
   "source": [
    "<h1>Definir funciones auxiliares</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b727190",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Imprime barra de progreso</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62cc105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimir_barra_progreso_v2(progreso, total):\n",
    "    # https://www.youtube.com/watch?v=x1eaT88vJUA\n",
    "    \n",
    "    p = int(100 * (progreso + 1)/total)\n",
    "\n",
    "    # Alt+291: █\n",
    "    barra = '█'*p + '-'*(100-p) \n",
    "\n",
    "    print(\"\\r|{}| {}%\".format(barra, p), end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702e8751",
   "metadata": {},
   "source": [
    "<h1>Importar datos</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a89f42",
   "metadata": {},
   "source": [
    "<p>Los archivos contienen palabras/oraciones paralelas\n",
    "<br>\n",
    "La primera columna está en español y la segunda en quechua</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2c4f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un dataframe vació que almacenará las traducciones (translations)\n",
    "df_trans = pd.DataFrame(columns=[\"español\",\"quechua\"])\n",
    "df_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1513c829",
   "metadata": {},
   "source": [
    "<p>Se utilizó un tab (\"\\t\") como separador de columnas para evitar confusiones con las comas propias de las oraciones</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19401cc0",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Importa DataFrames</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a47ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_opciones = [[40,[40,50,60]],\n",
    "               [50,[50,63,75]],\n",
    "               [60,[60,75,90]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e5c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Longitudes disponibles en español\")\n",
    "for i in range(3):\n",
    "    print(\"{}) - {}\".format(i, arr_opciones[i][0]) )\n",
    "MAX_ES_index = int(input(\"Ingrese la longitud máxima en español: \"))\n",
    "\n",
    "print(\"\\n\" + \"-\"*100)\n",
    "print(\"Longitudes disponibles en quechua\")\n",
    "for j in range(3):\n",
    "    print(\"{}) - {}\".format(j, arr_opciones[MAX_ES_index][1][j]))\n",
    "MAX_QU_index = int(input(\"Ingrese la longitud máxima en quechua: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb377b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ES = arr_opciones[MAX_ES_index][0]\n",
    "MAX_QU = arr_opciones[MAX_ES_index][1][MAX_QU_index]\n",
    "\n",
    "folder_consolidado = \"./Datos/consolidado_{}_{}/\".format(MAX_ES, MAX_QU)\n",
    "print(\"obteniendo datos de {}\".format(folder_consolidado))\n",
    "\n",
    "sub_paths = [folder_consolidado,\n",
    "             #\"./Datos/palabras/\", \"./Datos/grupos/\",\n",
    "             #\"./Datos/libros/\", \"./Datos/oraciones/\"\n",
    "            ]\n",
    "\n",
    "for sub_path in sub_paths:\n",
    "    arr_category = os.listdir(sub_path)\n",
    "\n",
    "    for item in arr_category:\n",
    "        if item[-4:] == \".csv\":\n",
    "            file = \"{}{}\".format(sub_path,item)\n",
    "            df_temp = pd.read_csv(file, encoding=\"utf-8\", sep=\"\\t\")\n",
    "            \n",
    "            df_trans = pd.concat([df_trans, df_temp]\n",
    "                                 , ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f8351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb246c4",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Eliminar frases muy largas</h3>\n",
    "<p>Los tres arreglos de numpy deben entrar en los 8 GB de VRAM, y dejar espacio para el resto de variables</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a073a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, registro in df_trans.iterrows():\n",
    "    txt_es = registro[0].strip()\n",
    "    txt_qu = registro[1].strip()\n",
    "    \n",
    "    if (len(txt_es) > MAX_ES) or (len(txt_qu) > MAX_QU):\n",
    "        #print(\"registro eliminado\")\n",
    "        df_trans = df_trans.drop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80d3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a2759f",
   "metadata": {},
   "source": [
    "<h1>Configuración</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb7950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # tamño de los lotes para entrenamiento\n",
    "epochs = 500 # Número de epochs\n",
    "latent_dim = 256 # dimensión del espacio latente para el encoder\n",
    "num_samples = len(df_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc2402",
   "metadata": {},
   "source": [
    "<h1>Preparar los datos</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf7020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectoriza los datos\n",
    "i=0\n",
    "target_text= ''\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34ade38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, registro in df_trans.iterrows():    \n",
    "    \n",
    "    input_text = registro[0].strip()\n",
    "    target_text = registro[1].strip()\n",
    "    \n",
    "    \n",
    "    if (index<100):\n",
    "        print(\"{} \\t I: |{}| \\t T: |{}|\"\n",
    "              .format(index, input_text, target_text))        \n",
    "\n",
    "    \n",
    "    # Usaremos \"tab\" como el  caracter de inicio (start sequence)\n",
    "    # para los targets, y \"\\n\" como el caracter de fin de secuencia \"end sequence\"\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    # sube las líneas a  las listas\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "  \n",
    "    # completa los conjuntos de caracteres si es necesario\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ef763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte los dos conjuntos de caracteres\n",
    "# en dos listas ordenadas\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))  \n",
    "# calcule el número de tokens (caracteres) en ambos lados\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "# calcula la máxima longitud de las secuencias en cada lado\n",
    "max_encoder_seq_length = max([len(text) for text in input_texts])\n",
    "max_decoder_seq_length = max([len(text) for text in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f44f962",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of samples:\", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
    "print(\"preparando datos...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebba2a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea diccionarios de tokens\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "# crea los tensores 1-hot para el encoder y el decoder\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\n",
    "\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62973e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    # Modificar los valores de la matriz del encoder\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    \n",
    "    \n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    \n",
    "    \n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
    "\n",
    "print (\"\\n....\")\n",
    "print(\"datos preparados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e7a6b1",
   "metadata": {},
   "source": [
    "<h1>Construir el modelo</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b6616e",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Encoder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f0cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define una secuencia de entrada y la procesa\n",
    "encoder_inputs = Input(shape = (None, num_encoder_tokens))\n",
    "\n",
    "# capa recurrente del encoder\n",
    "encoder = LSTM(latent_dim, return_state = True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# Descartamos las salidas (encoder_outputs)\n",
    "# solamente se conserva las memoria de  corto (state_h) y \n",
    "# largo plazo(state_c)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85df2bee",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Decoder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4169602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos el decoder, usando 'encoder_states' como estado inicial\n",
    "decoder_inputs = Input(shape= (None, num_decoder_tokens))\n",
    "\n",
    "# capa recurrente del decoder\n",
    "# Configuramos nuestro decodificador para devolver secuencias de salida completas,\n",
    "# y también para devolver estados internos. No usamos los\n",
    "# estados retornados en el modelo de entrenamiento, pero los usaremos en inferencia.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _,_ = decoder_lstm(decoder_inputs,initial_state = encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9068842f",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Modelo Completo</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58d44a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4505484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "plot_model(model, to_file='../Imagenes/s2s.png', \n",
    "           show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8078d390",
   "metadata": {},
   "source": [
    "<h1>Entrenar el modelo</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3272db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84936b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb09931",
   "metadata": {},
   "source": [
    "<h1>Guardar el modelo</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c59c1",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Diccionarios</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d954601",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/s2q/input_token_index.txt\", \"w\") as f:\n",
    "    json.dump(input_token_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77635fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/s2q/target_token_index.txt\", \"w\") as f:\n",
    "    json.dump(target_token_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f756f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/s2q/history.txt\", \"w\") as f:\n",
    "    json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445fbf86",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Valores puntuales</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b5e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"num_decoder_tokens: {}\".format(num_decoder_tokens))\n",
    "print(\"max_decoder_seq_length: {}\".format(max_decoder_seq_length))\n",
    "\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be3bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/s2q/otros.txt\", \"w\") as f:\n",
    "    f.write(\"num_encoder_tokens = {}\\n\".format(num_encoder_tokens))\n",
    "    f.write(\"num_decoder_tokens = {}\\n\".format(num_decoder_tokens))\n",
    "    \n",
    "    f.write(\"max_encoder_seq_length = {}\\n\").format(max_encoder_seq_length)\n",
    "    f.write(\"max_decoder_seq_length = {}\".format(max_decoder_seq_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880cf75b",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Arreglo numpy</h3>\n",
    "<p>Sólo las primeras 100 posiciones</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e456f8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./Modelos/s2q/encoder_input_data_sample.npy\"\n",
    "with open(file_name, \"wb\") as f:\n",
    "    np.save(f, encoder_input_data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f12bbad",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Modelo</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79defd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2q = Spanish to Quechua\n",
    "model.save(\"./Modelos/s2q/spanish_to_quechua\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0b29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./Modelos/s2q/spanish_to_quechua_file.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
