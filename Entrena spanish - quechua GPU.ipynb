{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2c67e2e",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gold; background-color:black; padding:20px\">TRADUCTOR QUECHUA - ESPAÑOL / ESPAÑOL - QUECHUA</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e263aaa4",
   "metadata": {},
   "source": [
    "<h1>Importar librerias a utilizar</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e9ecb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea182627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd6966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809fdacb",
   "metadata": {},
   "source": [
    "<h1>Definir funciones auxiliares</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b727190",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Imprime barra de progreso</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b62cc105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimir_barra_progreso_v2(progreso, total):\n",
    "    # https://www.youtube.com/watch?v=x1eaT88vJUA\n",
    "    \n",
    "    p = int(100 * (progreso + 1)/total)\n",
    "\n",
    "    # Alt+291: █\n",
    "    barra = '█'*p + '-'*(100-p) \n",
    "\n",
    "    print(\"\\r|{}| {}%\".format(barra, p), end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702e8751",
   "metadata": {},
   "source": [
    "<h1>Importar datos</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a89f42",
   "metadata": {},
   "source": [
    "<p>Los archivos contienen palabras/oraciones paralelas\n",
    "<br>\n",
    "La primera columna está en español y la segunda en quechua</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f2c4f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>español</th>\n",
       "      <th>quechua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [español, quechua]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un dataframe vació que almacenará las traducciones (translations)\n",
    "df_trans = pd.DataFrame(columns=[\"español\",\"quechua\"])\n",
    "df_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1513c829",
   "metadata": {},
   "source": [
    "<p>Se utilizó un tab (\"\\t\") como separador de columnas para evitar confusiones con las comas propias de las oraciones</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19401cc0",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Importa DataFrames</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb377b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_paths = [\"./Datos/palabras/\",\n",
    "             \"./Datos/Grupos/\",\n",
    "             \"./Datos/libros/\"]\n",
    "\n",
    "for sub_path in sub_paths:\n",
    "    arr_category = os.listdir(sub_path)\n",
    "\n",
    "    for item in arr_category:\n",
    "        if item[-4:] == \".csv\":\n",
    "            file = \"{}{}\".format(sub_path,item)\n",
    "            df_temp = pd.read_csv(file, encoding=\"utf-8\", sep=\"\\t\")\n",
    "            \n",
    "            df_trans = pd.concat([df_trans, df_temp]\n",
    "                                 , ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78f8351c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>español</th>\n",
       "      <th>quechua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ácido</td>\n",
       "      <td>ácido nisqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agradable</td>\n",
       "      <td>munasqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agrícola</td>\n",
       "      <td>chakra llamk’aymanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>algún</td>\n",
       "      <td>wakin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amable</td>\n",
       "      <td>kuyakuq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17576</th>\n",
       "      <td>que aumenten sus fatigas tu tesoro;</td>\n",
       "      <td>qhapaq kayniyki llank’ayninkuta yapachun;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17577</th>\n",
       "      <td>y cambia horas de espuma por divinas.</td>\n",
       "      <td>hinaspa horas de espuma cambiay divinopaq.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17578</th>\n",
       "      <td>Sé rica adentro, en vez de serlo afuera.</td>\n",
       "      <td>Hawamanta qhapaq kaymantaqa, ukhupi qhapaq kay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17579</th>\n",
       "      <td>Devora tú a la Muerte y no la nutras,</td>\n",
       "      <td>Wañuytaqa mikhunkichis, manataq mikhuchinkich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17580</th>\n",
       "      <td>pues si ella muere, no podrás morir.</td>\n",
       "      <td>Bueno, wañuptinqa manam wañuwaqchu.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17581 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        español  \\\n",
       "0                                         ácido   \n",
       "1                                     agradable   \n",
       "2                                      agrícola   \n",
       "3                                         algún   \n",
       "4                                        amable   \n",
       "...                                         ...   \n",
       "17576       que aumenten sus fatigas tu tesoro;   \n",
       "17577     y cambia horas de espuma por divinas.   \n",
       "17578  Sé rica adentro, en vez de serlo afuera.   \n",
       "17579     Devora tú a la Muerte y no la nutras,   \n",
       "17580      pues si ella muere, no podrás morir.   \n",
       "\n",
       "                                                 quechua  \n",
       "0                                            ácido nisqa  \n",
       "1                                                munasqa  \n",
       "2                                   chakra llamk’aymanta  \n",
       "3                                                  wakin  \n",
       "4                                                kuyakuq  \n",
       "...                                                  ...  \n",
       "17576          qhapaq kayniyki llank’ayninkuta yapachun;  \n",
       "17577         hinaspa horas de espuma cambiay divinopaq.  \n",
       "17578    Hawamanta qhapaq kaymantaqa, ukhupi qhapaq kay.  \n",
       "17579   Wañuytaqa mikhunkichis, manataq mikhuchinkich...  \n",
       "17580                Bueno, wañuptinqa manam wañuwaqchu.  \n",
       "\n",
       "[17581 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb246c4",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Eliminar frases muy largas</h3>\n",
    "<p>Antes de agregar esta línea, se generaba el siguiente error al separar espacio en memoria para los arreglos de numpy</p>\n",
    "<p>Unable to allocate 152. GiB for an array with shape (18435, 18240, 121) and data type float32</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a073a8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n",
      "registro eliminado\n"
     ]
    }
   ],
   "source": [
    "for index, registro in df_trans.iterrows():\n",
    "    txt_es = registro[0]\n",
    "    txt_qu = registro[1]\n",
    "    \n",
    "    if (len(txt_es) > 250) or (len(txt_qu) > 250):\n",
    "        #print(\"registro eliminado\")\n",
    "        df_trans = df_trans.drop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e80d3994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>español</th>\n",
       "      <th>quechua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ácido</td>\n",
       "      <td>ácido nisqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agradable</td>\n",
       "      <td>munasqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agrícola</td>\n",
       "      <td>chakra llamk’aymanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>algún</td>\n",
       "      <td>wakin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amable</td>\n",
       "      <td>kuyakuq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17576</th>\n",
       "      <td>que aumenten sus fatigas tu tesoro;</td>\n",
       "      <td>qhapaq kayniyki llank’ayninkuta yapachun;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17577</th>\n",
       "      <td>y cambia horas de espuma por divinas.</td>\n",
       "      <td>hinaspa horas de espuma cambiay divinopaq.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17578</th>\n",
       "      <td>Sé rica adentro, en vez de serlo afuera.</td>\n",
       "      <td>Hawamanta qhapaq kaymantaqa, ukhupi qhapaq kay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17579</th>\n",
       "      <td>Devora tú a la Muerte y no la nutras,</td>\n",
       "      <td>Wañuytaqa mikhunkichis, manataq mikhuchinkich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17580</th>\n",
       "      <td>pues si ella muere, no podrás morir.</td>\n",
       "      <td>Bueno, wañuptinqa manam wañuwaqchu.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16878 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        español  \\\n",
       "0                                         ácido   \n",
       "1                                     agradable   \n",
       "2                                      agrícola   \n",
       "3                                         algún   \n",
       "4                                        amable   \n",
       "...                                         ...   \n",
       "17576       que aumenten sus fatigas tu tesoro;   \n",
       "17577     y cambia horas de espuma por divinas.   \n",
       "17578  Sé rica adentro, en vez de serlo afuera.   \n",
       "17579     Devora tú a la Muerte y no la nutras,   \n",
       "17580      pues si ella muere, no podrás morir.   \n",
       "\n",
       "                                                 quechua  \n",
       "0                                            ácido nisqa  \n",
       "1                                                munasqa  \n",
       "2                                   chakra llamk’aymanta  \n",
       "3                                                  wakin  \n",
       "4                                                kuyakuq  \n",
       "...                                                  ...  \n",
       "17576          qhapaq kayniyki llank’ayninkuta yapachun;  \n",
       "17577         hinaspa horas de espuma cambiay divinopaq.  \n",
       "17578    Hawamanta qhapaq kaymantaqa, ukhupi qhapaq kay.  \n",
       "17579   Wañuytaqa mikhunkichis, manataq mikhuchinkich...  \n",
       "17580                Bueno, wañuptinqa manam wañuwaqchu.  \n",
       "\n",
       "[16878 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a2759f",
   "metadata": {},
   "source": [
    "<h1>Configuración</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cb7950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # tamño de los lotes para entrenamiento\n",
    "epochs = 100 # Número de epochs\n",
    "latent_dim = 256 # dimensión del espacio latente para el encoder\n",
    "num_samples = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc2402",
   "metadata": {},
   "source": [
    "<h1>Preparar los datos</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaf7020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectoriza los datos\n",
    "i=0\n",
    "targe_text= ''\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a34ade38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t I: ácido \t T: \n",
      "1 \t I: agradable \t T: \n",
      "2 \t I: agrícola \t T: \n",
      "3 \t I: algún \t T: \n",
      "4 \t I: amable \t T: \n",
      "5 \t I: amargo \t T: \n",
      "6 \t I: ambos \t T: \n",
      "7 \t I: ancho \t T: \n",
      "8 \t I: aquel \t T: \n",
      "9 \t I: aquellas \t T: \n"
     ]
    }
   ],
   "source": [
    "for index, registro in df_trans.iterrows():    \n",
    "    \n",
    "    input_text = registro[0]\n",
    "    target_text = registro[1]\n",
    "    \n",
    "    \n",
    "    if (index<10):\n",
    "        print(\"{} \\t I: {} \\t T: {}\"\n",
    "              .format(index, input_text, targe_text))        \n",
    "\n",
    "    \n",
    "    # Usaremos \"tab\" como el  caracter de inicio (start sequence)\n",
    "    # para los targets, y \"\\n\" como el caracter de fin de secuencia \"end sequence\"\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    # sube las líneas a  las listas\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "  \n",
    "    # completa los conjuntos de caracteres si es necesario\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "666ef763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convierte los dos conjuntos de caracteres\n",
    "# en dos listas ordenadas\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))  \n",
    "# calcule el número de tokens (caracteres) en ambos lados\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "# calcula la máxima longitud de las secuencias en cada lado\n",
    "max_encoder_seq_length = max([len(text) for text in input_texts])\n",
    "max_decoder_seq_length = max([len(text) for text in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f44f962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 16878\n",
      "Number of unique input tokens: 117\n",
      "Number of unique output tokens: 109\n",
      "Max sequence length for inputs: 250\n",
      "Max sequence length for outputs: 252\n",
      "preparando datos...\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples:\", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
    "print(\"preparando datos...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebba2a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea diccionarios de tokens\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "# crea los tensores 1-hot para el encoder y el decoder\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\n",
    "\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62973e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "datos preparados\n"
     ]
    }
   ],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
    "\n",
    "print (\"\\n....\")\n",
    "print(\"datos preparados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e7a6b1",
   "metadata": {},
   "source": [
    "<h1>Construir el modelo</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b6616e",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Encoder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f2f0cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define una secuencia de entrada y la procesa\n",
    "encoder_inputs = Input(shape = (None, num_encoder_tokens))\n",
    "\n",
    "# capa recurrente del encoder\n",
    "encoder = LSTM(latent_dim, return_state = True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# Descartamos las salidas (encoder_outputs)\n",
    "# solamente se conserva las memoria de  corto (state_h) y \n",
    "# largo plazo(state_c)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85df2bee",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Decoder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4169602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos el decoder, usando 'encoder_states' como estado inicial\n",
    "decoder_inputs = Input(shape= (None, num_decoder_tokens))\n",
    "\n",
    "# capa recurrente del decoder\n",
    "# Configuramos nuestro decodificador para devolver secuencias de salida completas,\n",
    "# y también para devolver estados internos. No usamos los\n",
    "# estados retornados en el modelo de entrenamiento, pero los usaremos en inferencia.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _,_ = decoder_lstm(decoder_inputs,initial_state = encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9068842f",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Modelo Completo</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e58d44a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4505484d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, 117)]  0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None, 109)]  0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 256),        382976      ['input_1[0][0]']                \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 256),  374784      ['input_2[0][0]',                \n",
      "                                 (None, 256),                     'lstm[0][1]',                   \n",
      "                                 (None, 256)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 109)    28013       ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 785,773\n",
      "Trainable params: 785,773\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "plot_model(model, to_file='../Imagenes/s2s.png', \n",
    "           show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8078d390",
   "metadata": {},
   "source": [
    "<h1>Entrenar el modelo</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c3272db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84936b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 21s 78ms/step - loss: 1.2252 - accuracy: 0.7170 - val_loss: 0.9712 - val_accuracy: 0.7256\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.8358 - accuracy: 0.7698 - val_loss: 0.7738 - val_accuracy: 0.7800\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 15s 71ms/step - loss: 0.7133 - accuracy: 0.7947 - val_loss: 0.7119 - val_accuracy: 0.7931\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 15s 71ms/step - loss: 0.6671 - accuracy: 0.8051 - val_loss: 0.6763 - val_accuracy: 0.8021\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 15s 72ms/step - loss: 0.6342 - accuracy: 0.8149 - val_loss: 0.6458 - val_accuracy: 0.8125\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.6084 - accuracy: 0.8227 - val_loss: 0.6245 - val_accuracy: 0.8181\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.5863 - accuracy: 0.8282 - val_loss: 0.6063 - val_accuracy: 0.8215\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 15s 72ms/step - loss: 0.5681 - accuracy: 0.8327 - val_loss: 0.5870 - val_accuracy: 0.8271\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 15s 71ms/step - loss: 0.5521 - accuracy: 0.8370 - val_loss: 0.5732 - val_accuracy: 0.8315\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 15s 71ms/step - loss: 0.5379 - accuracy: 0.8412 - val_loss: 0.5615 - val_accuracy: 0.8357\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.5254 - accuracy: 0.8450 - val_loss: 0.5518 - val_accuracy: 0.8378\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.5135 - accuracy: 0.8483 - val_loss: 0.5406 - val_accuracy: 0.8406\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.5013 - accuracy: 0.8517 - val_loss: 0.5292 - val_accuracy: 0.8432\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.4902 - accuracy: 0.8545 - val_loss: 0.5217 - val_accuracy: 0.8461\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.4798 - accuracy: 0.8575 - val_loss: 0.5111 - val_accuracy: 0.8488\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.4708 - accuracy: 0.8600 - val_loss: 0.5058 - val_accuracy: 0.8506\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 15s 71ms/step - loss: 0.4629 - accuracy: 0.8622 - val_loss: 0.4980 - val_accuracy: 0.8520\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.4551 - accuracy: 0.8644 - val_loss: 0.4919 - val_accuracy: 0.8537\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.4481 - accuracy: 0.8663 - val_loss: 0.4871 - val_accuracy: 0.8553\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.4415 - accuracy: 0.8682 - val_loss: 0.4826 - val_accuracy: 0.8566\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 15s 73ms/step - loss: 0.4350 - accuracy: 0.8700 - val_loss: 0.4768 - val_accuracy: 0.8582\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4291 - accuracy: 0.8716 - val_loss: 0.4727 - val_accuracy: 0.8591\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.4232 - accuracy: 0.8733 - val_loss: 0.4689 - val_accuracy: 0.8599\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.4180 - accuracy: 0.8747 - val_loss: 0.4643 - val_accuracy: 0.8610\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.4126 - accuracy: 0.8761 - val_loss: 0.4612 - val_accuracy: 0.8622\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.4072 - accuracy: 0.8774 - val_loss: 0.4568 - val_accuracy: 0.8635\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.4025 - accuracy: 0.8786 - val_loss: 0.4546 - val_accuracy: 0.8637\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.3981 - accuracy: 0.8799 - val_loss: 0.4510 - val_accuracy: 0.8647\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.3937 - accuracy: 0.8810 - val_loss: 0.4488 - val_accuracy: 0.8654\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3897 - accuracy: 0.8820 - val_loss: 0.4458 - val_accuracy: 0.8661\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3855 - accuracy: 0.8833 - val_loss: 0.4434 - val_accuracy: 0.8667\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3816 - accuracy: 0.8843 - val_loss: 0.4404 - val_accuracy: 0.8677\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3780 - accuracy: 0.8853 - val_loss: 0.4387 - val_accuracy: 0.8678\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3747 - accuracy: 0.8861 - val_loss: 0.4373 - val_accuracy: 0.8683\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.3713 - accuracy: 0.8869 - val_loss: 0.4351 - val_accuracy: 0.8687\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.3683 - accuracy: 0.8878 - val_loss: 0.4349 - val_accuracy: 0.8686\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3654 - accuracy: 0.8885 - val_loss: 0.4313 - val_accuracy: 0.8697\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3625 - accuracy: 0.8893 - val_loss: 0.4322 - val_accuracy: 0.8694\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3598 - accuracy: 0.8900 - val_loss: 0.4307 - val_accuracy: 0.8697\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3573 - accuracy: 0.8907 - val_loss: 0.4311 - val_accuracy: 0.8698\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3545 - accuracy: 0.8916 - val_loss: 0.4285 - val_accuracy: 0.8708\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3522 - accuracy: 0.8921 - val_loss: 0.4282 - val_accuracy: 0.8707\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3499 - accuracy: 0.8928 - val_loss: 0.4278 - val_accuracy: 0.8710\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3477 - accuracy: 0.8933 - val_loss: 0.4263 - val_accuracy: 0.8715\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3457 - accuracy: 0.8938 - val_loss: 0.4260 - val_accuracy: 0.8717\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.3434 - accuracy: 0.8945 - val_loss: 0.4258 - val_accuracy: 0.8718\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3417 - accuracy: 0.8951 - val_loss: 0.4243 - val_accuracy: 0.8721\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.3394 - accuracy: 0.8956 - val_loss: 0.4262 - val_accuracy: 0.8719\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.3374 - accuracy: 0.8962 - val_loss: 0.4248 - val_accuracy: 0.8724\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.3356 - accuracy: 0.8968 - val_loss: 0.4257 - val_accuracy: 0.8723\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.3337 - accuracy: 0.8972 - val_loss: 0.4242 - val_accuracy: 0.8728\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.3319 - accuracy: 0.8978 - val_loss: 0.4254 - val_accuracy: 0.8725\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.3305 - accuracy: 0.8981 - val_loss: 0.4271 - val_accuracy: 0.8719\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.3286 - accuracy: 0.8987 - val_loss: 0.4281 - val_accuracy: 0.8719\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3270 - accuracy: 0.8991 - val_loss: 0.4256 - val_accuracy: 0.8725\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3254 - accuracy: 0.8996 - val_loss: 0.4275 - val_accuracy: 0.8722\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3238 - accuracy: 0.9000 - val_loss: 0.4272 - val_accuracy: 0.8723\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3221 - accuracy: 0.9005 - val_loss: 0.4267 - val_accuracy: 0.8723\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3206 - accuracy: 0.9009 - val_loss: 0.4273 - val_accuracy: 0.8726\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.3191 - accuracy: 0.9014 - val_loss: 0.4281 - val_accuracy: 0.8722\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3178 - accuracy: 0.9018 - val_loss: 0.4272 - val_accuracy: 0.8728\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3164 - accuracy: 0.9022 - val_loss: 0.4296 - val_accuracy: 0.8722\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3151 - accuracy: 0.9025 - val_loss: 0.4291 - val_accuracy: 0.8726\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3136 - accuracy: 0.9030 - val_loss: 0.4300 - val_accuracy: 0.8724\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3121 - accuracy: 0.9033 - val_loss: 0.4294 - val_accuracy: 0.8726\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3110 - accuracy: 0.9036 - val_loss: 0.4324 - val_accuracy: 0.8719\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3099 - accuracy: 0.9040 - val_loss: 0.4320 - val_accuracy: 0.8724\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.3083 - accuracy: 0.9045 - val_loss: 0.4334 - val_accuracy: 0.8720\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3072 - accuracy: 0.9048 - val_loss: 0.4342 - val_accuracy: 0.8719\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3061 - accuracy: 0.9051 - val_loss: 0.4340 - val_accuracy: 0.8718\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3047 - accuracy: 0.9055 - val_loss: 0.4352 - val_accuracy: 0.8717\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3034 - accuracy: 0.9060 - val_loss: 0.4369 - val_accuracy: 0.8714\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3023 - accuracy: 0.9062 - val_loss: 0.4378 - val_accuracy: 0.8713\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.3012 - accuracy: 0.9065 - val_loss: 0.4386 - val_accuracy: 0.8714\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.3000 - accuracy: 0.9069 - val_loss: 0.4385 - val_accuracy: 0.8715\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 15s 71ms/step - loss: 0.2992 - accuracy: 0.9071 - val_loss: 0.4389 - val_accuracy: 0.8713\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.2978 - accuracy: 0.9075 - val_loss: 0.4407 - val_accuracy: 0.8711\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 15s 71ms/step - loss: 0.2969 - accuracy: 0.9078 - val_loss: 0.4403 - val_accuracy: 0.8712\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.2957 - accuracy: 0.9082 - val_loss: 0.4428 - val_accuracy: 0.8707\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2948 - accuracy: 0.9085 - val_loss: 0.4430 - val_accuracy: 0.8708\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2938 - accuracy: 0.9088 - val_loss: 0.4445 - val_accuracy: 0.8706\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2928 - accuracy: 0.9090 - val_loss: 0.4463 - val_accuracy: 0.8709\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2917 - accuracy: 0.9094 - val_loss: 0.4469 - val_accuracy: 0.8704\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2906 - accuracy: 0.9097 - val_loss: 0.4486 - val_accuracy: 0.8706\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2895 - accuracy: 0.9100 - val_loss: 0.4489 - val_accuracy: 0.8704\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2889 - accuracy: 0.9103 - val_loss: 0.4512 - val_accuracy: 0.8697\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2881 - accuracy: 0.9104 - val_loss: 0.4510 - val_accuracy: 0.8703\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2867 - accuracy: 0.9109 - val_loss: 0.4510 - val_accuracy: 0.8703\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2861 - accuracy: 0.9112 - val_loss: 0.4527 - val_accuracy: 0.8699\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2849 - accuracy: 0.9115 - val_loss: 0.4555 - val_accuracy: 0.8693\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2842 - accuracy: 0.9116 - val_loss: 0.4557 - val_accuracy: 0.8695\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2831 - accuracy: 0.9120 - val_loss: 0.4580 - val_accuracy: 0.8691\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2823 - accuracy: 0.9122 - val_loss: 0.4570 - val_accuracy: 0.8695\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2815 - accuracy: 0.9124 - val_loss: 0.4574 - val_accuracy: 0.8695\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2806 - accuracy: 0.9127 - val_loss: 0.4615 - val_accuracy: 0.8687\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2801 - accuracy: 0.9130 - val_loss: 0.4614 - val_accuracy: 0.8686\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2792 - accuracy: 0.9132 - val_loss: 0.4610 - val_accuracy: 0.8687\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2781 - accuracy: 0.9135 - val_loss: 0.4633 - val_accuracy: 0.8687\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2772 - accuracy: 0.9137 - val_loss: 0.4640 - val_accuracy: 0.8686\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2764 - accuracy: 0.9140 - val_loss: 0.4665 - val_accuracy: 0.8685\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb09931",
   "metadata": {},
   "source": [
    "<h1>Guardar el modelo</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6376f9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d954601",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/s2q/input_token_index.txt\", \"w\") as f:\n",
    "    json.dump(input_token_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e77635fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/s2q/target_token_index.txt\", \"w\") as f:\n",
    "    json.dump(target_token_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0191bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/s2q/encoder_input_data.npy\", \"wb\") as f:\n",
    "    np.save(f, encoder_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e93b5e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_decoder_tokens: 109\n",
      "max_decoder_seq_length: 252\n"
     ]
    }
   ],
   "source": [
    "print(\"num_decoder_tokens: {}\".format(num_decoder_tokens))\n",
    "print(\"max_decoder_seq_length: {}\".format(max_decoder_seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f79defd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Modelos/s2q/spanish_to_quechua\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Modelos/s2q/spanish_to_quechua\\assets\n"
     ]
    }
   ],
   "source": [
    "# s2q = Spanish to Quechua\n",
    "model.save(\"./Modelos/s2q/spanish_to_quechua\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
