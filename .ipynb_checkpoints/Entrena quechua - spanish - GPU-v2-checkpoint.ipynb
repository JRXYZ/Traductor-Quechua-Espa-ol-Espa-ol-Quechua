{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2c67e2e",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gold; background-color:black; padding:20px; font-size:40px; text-align: center\">TRADUCTOR QUECHUA - ESPAÑOL</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e263aaa4",
   "metadata": {},
   "source": [
    "<h1>Importar librerias a utilizar</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e9ecb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea182627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd6966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809fdacb",
   "metadata": {},
   "source": [
    "<h1>Definir funciones auxiliares</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b727190",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Imprime barra de progreso</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b62cc105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimir_barra_progreso_v2(progreso, total):\n",
    "    # https://www.youtube.com/watch?v=x1eaT88vJUA\n",
    "    \n",
    "    p = int(100 * (progreso + 1)/total)\n",
    "\n",
    "    # Alt+291: █\n",
    "    barra = '█'*p + '-'*(100-p) \n",
    "\n",
    "    print(\"\\r|{}| {}%\".format(barra, p), end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702e8751",
   "metadata": {},
   "source": [
    "<h1>Importar datos</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a89f42",
   "metadata": {},
   "source": [
    "<p>Los archivos contienen palabras/oraciones paralelas\n",
    "<br>\n",
    "La primera columna está en español y la segunda en quechua</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f2c4f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>español</th>\n",
       "      <th>quechua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [español, quechua]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un dataframe vació que almacenará las traducciones (translations)\n",
    "df_trans = pd.DataFrame(columns=[\"español\",\"quechua\"])\n",
    "df_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1513c829",
   "metadata": {},
   "source": [
    "<p>Se utilizó un tab (\"\\t\") como separador de columnas para evitar confusiones con las comas propias de las oraciones</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19401cc0",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Importa DataFrames</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a47ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_opciones = [[40,[40,50,60]],\n",
    "               [50,[50,63,75]],\n",
    "               [60,[60,75,90]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df4e5c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitudes disponibles en español\n",
      "0) - 40\n",
      "1) - 50\n",
      "2) - 60\n",
      "Ingrese la longitud máxima en español: 0\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Longitudes disponibles en quechua\n",
      "0) - 40\n",
      "1) - 50\n",
      "2) - 60\n",
      "Ingrese la longitud máxima en quechua: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Longitudes disponibles en español\")\n",
    "for i in range(3):\n",
    "    print(\"{}) - {}\".format(i, arr_opciones[i][0]) )\n",
    "MAX_ES_index = int(input(\"Ingrese la longitud máxima en español: \"))\n",
    "\n",
    "print(\"\\n\" + \"-\"*100)\n",
    "print(\"Longitudes disponibles en quechua\")\n",
    "for j in range(3):\n",
    "    print(\"{}) - {}\".format(j, arr_opciones[MAX_ES_index][1][j]))\n",
    "MAX_QU_index = int(input(\"Ingrese la longitud máxima en quechua: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb377b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obteniendo datos de ./Datos/consolidado_40_40/\n"
     ]
    }
   ],
   "source": [
    "MAX_ES = arr_opciones[MAX_ES_index][0]\n",
    "MAX_QU = arr_opciones[MAX_ES_index][1][MAX_QU_index]\n",
    "\n",
    "folder_consolidado = \"./Datos/consolidado_{}_{}/\".format(MAX_ES, MAX_QU)\n",
    "print(\"obteniendo datos de {}\".format(folder_consolidado))\n",
    "\n",
    "sub_paths = [folder_consolidado,\n",
    "             #\"./Datos/palabras/\", \"./Datos/grupos/\",\n",
    "             #\"./Datos/libros/\", \"./Datos/oraciones/\"\n",
    "            ]\n",
    "\n",
    "for sub_path in sub_paths:\n",
    "    arr_category = os.listdir(sub_path)\n",
    "\n",
    "    for item in arr_category:\n",
    "        if item[-4:] == \".csv\":\n",
    "            file = \"{}{}\".format(sub_path,item)\n",
    "            df_temp = pd.read_csv(file, encoding=\"utf-8\", sep=\"\\t\")\n",
    "            \n",
    "            df_trans = pd.concat([df_trans, df_temp]\n",
    "                                 , ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f8351c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>español</th>\n",
       "      <th>quechua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ve.</td>\n",
       "      <td>Riy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vete.</td>\n",
       "      <td>Lluqsiy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vaya.</td>\n",
       "      <td>Waw.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Váyase.</td>\n",
       "      <td>Lluqsiy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hola.</td>\n",
       "      <td>Allinllachu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Me escapé.</td>\n",
       "      <td>Ayqirqanim.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Huía.</td>\n",
       "      <td>ayqirqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Me escapaba.</td>\n",
       "      <td>Ayqichkarqanim.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Yo lo sé.</td>\n",
       "      <td>Chaytaqa yachani.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Sé.</td>\n",
       "      <td>PAY.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         español             quechua\n",
       "0            Ve.                Riy.\n",
       "1          Vete.            Lluqsiy.\n",
       "2          Vaya.                Waw.\n",
       "3        Váyase.            Lluqsiy.\n",
       "4          Hola.        Allinllachu.\n",
       "..           ...                 ...\n",
       "95    Me escapé.         Ayqirqanim.\n",
       "96         Huía.             ayqirqa\n",
       "97  Me escapaba.     Ayqichkarqanim.\n",
       "98     Yo lo sé.   Chaytaqa yachani.\n",
       "99           Sé.                PAY.\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dda6c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>español</th>\n",
       "      <th>quechua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90213</th>\n",
       "      <td>Como un padre decrépito disfruta</td>\n",
       "      <td>Imaynan huk decrepit tayta kusikun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90214</th>\n",
       "      <td>al ver de su hijo las empresas jóvenes,</td>\n",
       "      <td>churinpa wayna empresankunata rikuspa,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90215</th>\n",
       "      <td>así yo, mutilado por la suene,</td>\n",
       "      <td>chaymi ñoqa, t’oqyaywan mutilado, .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90216</th>\n",
       "      <td>el poder o el ingenio, uno o todos,</td>\n",
       "      <td>atiy utaq ingenio, huk utaq llapan, .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90217</th>\n",
       "      <td>para colmarme a mí con su opulencia,</td>\n",
       "      <td>qhapaq kayninwan hunt'achiwananpaq,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90308</th>\n",
       "      <td>Pobre alma, centro de culpable limo</td>\n",
       "      <td>Wakcha alma, huchayuq limo centro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90309</th>\n",
       "      <td>a la que burla, indócil, quien la ciñe,</td>\n",
       "      <td>burlakuq, mana kamachikuq, chumpikuq, .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90310</th>\n",
       "      <td>ornando tu morada pasajera?</td>\n",
       "      <td>temporal tiyasqaykita sumaqchaspa?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90311</th>\n",
       "      <td>Vive, alma, a expensas de tu servidor;</td>\n",
       "      <td>Kawsay, alma, kamachiykiq qolqenwan;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90312</th>\n",
       "      <td>pues si ella muere, no podrás morir.</td>\n",
       "      <td>Bueno, wañuptinqa manam wañuwaqchu.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       español  \\\n",
       "90213         Como un padre decrépito disfruta   \n",
       "90214  al ver de su hijo las empresas jóvenes,   \n",
       "90215           así yo, mutilado por la suene,   \n",
       "90216      el poder o el ingenio, uno o todos,   \n",
       "90217     para colmarme a mí con su opulencia,   \n",
       "...                                        ...   \n",
       "90308      Pobre alma, centro de culpable limo   \n",
       "90309  a la que burla, indócil, quien la ciñe,   \n",
       "90310              ornando tu morada pasajera?   \n",
       "90311   Vive, alma, a expensas de tu servidor;   \n",
       "90312     pues si ella muere, no podrás morir.   \n",
       "\n",
       "                                        quechua  \n",
       "90213        Imaynan huk decrepit tayta kusikun  \n",
       "90214    churinpa wayna empresankunata rikuspa,  \n",
       "90215       chaymi ñoqa, t’oqyaywan mutilado, .  \n",
       "90216     atiy utaq ingenio, huk utaq llapan, .  \n",
       "90217       qhapaq kayninwan hunt'achiwananpaq,  \n",
       "...                                         ...  \n",
       "90308         Wakcha alma, huchayuq limo centro  \n",
       "90309   burlakuq, mana kamachikuq, chumpikuq, .  \n",
       "90310        temporal tiyasqaykita sumaqchaspa?  \n",
       "90311      Kawsay, alma, kamachiykiq qolqenwan;  \n",
       "90312       Bueno, wañuptinqa manam wañuwaqchu.  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans.tail(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb246c4",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Eliminar frases muy largas</h3>\n",
    "<p>Los tres arreglos de numpy deben entrar en los 8 GB de VRAM, y dejar espacio para el resto de variables</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da29dae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud inicial del arreglo 90313\n"
     ]
    }
   ],
   "source": [
    "print(\"Longitud inicial del arreglo {}\".format(len(df_trans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a073a8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registro 0 analizado\n",
      "Registro 5000 analizado\n",
      "Registro 10000 analizado\n",
      "Registro 15000 analizado\n",
      "Registro 20000 analizado\n",
      "Registro 25000 analizado\n",
      "Registro 30000 analizado\n",
      "Registro 35000 analizado\n",
      "Registro 40000 analizado\n",
      "Registro 45000 analizado\n",
      "Registro 50000 analizado\n",
      "Registro 55000 analizado\n",
      "Registro 60000 analizado\n",
      "Registro 65000 analizado\n",
      "Registro 70000 analizado\n",
      "Registro 75000 analizado\n",
      "Registro 80000 analizado\n",
      "Registro 85000 analizado\n",
      "Registro 90000 analizado\n"
     ]
    }
   ],
   "source": [
    "for index, registro in df_trans.iterrows():\n",
    "    txt_es = registro[0].strip()\n",
    "    txt_qu = registro[1].strip()\n",
    "    \n",
    "    if (len(txt_es) > MAX_ES) or (len(txt_qu) > MAX_QU):\n",
    "        #print(\"registro eliminado\")\n",
    "        df_trans = df_trans.drop(index)\n",
    "        \n",
    "    if index % 5000 == 0:\n",
    "        print(\"Registro {} analizado\".format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e80d3994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nueva longitud del arreglo 90313\n"
     ]
    }
   ],
   "source": [
    "print(\"Nueva longitud del arreglo {}\".format(len(df_trans)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a2759f",
   "metadata": {},
   "source": [
    "<h1>Configuración</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cb7950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # tamño de los lotes para entrenamiento\n",
    "epochs = 250 # Número de epochs\n",
    "latent_dim = 256 # dimensión del espacio latente para el encoder\n",
    "num_samples = len(df_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc2402",
   "metadata": {},
   "source": [
    "<h1>Preparar los datos</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaf7020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectoriza los datos\n",
    "i=0\n",
    "target_text= ''\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a34ade38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t I: |Riy.|  ----------------  T: |Ve.|\n",
      "1 \t I: |Lluqsiy.|  ------------  T: |Vete.|\n",
      "2 \t I: |Waw.|  ----------------  T: |Vaya.|\n",
      "3 \t I: |Lluqsiy.|  ------------  T: |Váyase.|\n",
      "4 \t I: |Allinllachu.|  --------  T: |Hola.|\n",
      "5 \t I: |¡Runa!|  --------------  T: |¡Corre!|\n",
      "6 \t I: |Paway!|  --------------  T: |¡Corran!|\n",
      "7 \t I: |¡Ascapa!|  ------------  T: |¡Huye!|\n",
      "8 \t I: |Paway!|  --------------  T: |¡Corra!|\n",
      "9 \t I: |Paway!|  --------------  T: |¡Corred!|\n",
      "10 \t I: |Paway.|  --------------  T: |Corra.|\n",
      "11 \t I: |Paway.|  --------------  T: |Corred.|\n",
      "12 \t I: |Pi?|  -----------------  T: |¿Quién?|\n",
      "13 \t I: |Waw!|  ----------------  T: |¡Órale!|\n",
      "14 \t I: |Kumuy!|  --------------  T: |¡Inclínate!|\n",
      "15 \t I: |Nina!|  ---------------  T: |¡Fuego!|\n",
      "16 \t I: |Nina!|  ---------------  T: |¡Incendio!|\n",
      "17 \t I: |disparar!|  -----------  T: |¡Disparad!|\n",
      "18 \t I: |Yanapay!|  ------------  T: |¡Ayuda!|\n",
      "19 \t I: |Yanapay! Yanapay!|  ---  T: |¡Socorro! ¡Auxilio!|\n",
      "20 \t I: |Yanapay!|  ------------  T: |¡Auxilio!|\n",
      "21 \t I: |pakay.|  --------------  T: |Escóndete.|\n",
      "22 \t I: |paway!|  --------------  T: |¡Salta!|\n",
      "23 \t I: |paway.|  --------------  T: |Salte.|\n",
      "24 \t I: |Paway.|  --------------  T: |Salto.|\n",
      "25 \t I: |Takyay.|  -------------  T: |Quédate.|\n",
      "26 \t I: |Sayay!|  --------------  T: |¡Parad!|\n",
      "27 \t I: |¡Por!|  ---------------  T: |¡Para!|\n",
      "28 \t I: |sayay!|  --------------  T: |¡Pare!|\n",
      "29 \t I: |Suyay!|  --------------  T: |¡Espera!|\n",
      "30 \t I: |suyay!|  --------------  T: |¡Esperen!|\n",
      "31 \t I: |Suyay!|  --------------  T: |¡Espérate!|\n",
      "32 \t I: |suyay.|  --------------  T: |Esperen.|\n",
      "33 \t I: |Suyay.|  --------------  T: |Espera.|\n",
      "34 \t I: |Suyay.|  --------------  T: |Esperad.|\n",
      "35 \t I: |Qallariy.|  -----------  T: |Empieza.|\n",
      "36 \t I: |chayta ruway.|  -------  T: |Hacedlo.|\n",
      "37 \t I: |Hinallayá puririy.|  --  T: |Continúa.|\n",
      "38 \t I: |qatiq.|  --------------  T: |Continúe.|\n",
      "39 \t I: |Allinllachu.|  --------  T: |Hola.|\n",
      "40 \t I: |Allinllachu.|  --------  T: |Hola.|\n",
      "41 \t I: |Utqay!|  --------------  T: |¡Date prisa!|\n",
      "42 \t I: |Utqay!|  --------------  T: |¡Daos prisa!|\n",
      "43 \t I: |Utqay.|  --------------  T: |Dese prisa.|\n",
      "44 \t I: |Pakakurqanim.|  -------  T: |Me oculté.|\n",
      "45 \t I: |Pakakurqanim.|  -------  T: |Me escondí.|\n",
      "46 \t I: |Pakakuchkarqanim.|  ---  T: |Me ocultaba.|\n",
      "47 \t I: |Pakakurqanim.|  -------  T: |Me escondía.|\n",
      "48 \t I: |Phawarqanim.|  --------  T: |Corrí.|\n",
      "49 \t I: |pawasqa.|  ------------  T: |Corría.|\n",
      "50 \t I: |Kallpanchakuni.|  -----  T: |Lo intento.|\n",
      "51 \t I: |¡Ganarqanim!|  --------  T: |¡He ganado!|\n",
      "52 \t I: |¡Ñoqaqa ganarqanin!|  -  T: |¡He ganado yo!|\n",
      "53 \t I: |¡Ay mana!|  -----------  T: |¡Oh, no!|\n",
      "54 \t I: |Gaseosawan chayta hap’iy.|    T: |Tomátelo con soda.|\n",
      "55 \t I: |Llanpu sunqu.|  -------  T: |Tranquila.|\n",
      "56 \t I: |Nina!|  ---------------  T: |¡Fuego!|\n",
      "57 \t I: |disparar!|  -----------  T: |¡Disparad!|\n",
      "58 \t I: |disparar!|  -----------  T: |¡Disparen!|\n",
      "59 \t I: |Disparar.|  -----------  T: |Dispara.|\n",
      "60 \t I: |Disparar!|  -----------  T: |¡Dispara!|\n",
      "61 \t I: |Disparar!|  -----------  T: |¡Dispará!|\n",
      "62 \t I: |disparar!|  -----------  T: |¡Dispare!|\n",
      "63 \t I: |Asiy.|  ---------------  T: |Sonríe.|\n",
      "64 \t I: |Llakikunim?|  ---------  T: |¿Disculpa?|\n",
      "65 \t I: |Wayka!|  --------------  T: |¡Al ataque!|\n",
      "66 \t I: |wayka!|  --------------  T: |¡Atacad!|\n",
      "67 \t I: |Siqi!|  ---------------  T: |¡Ataque!|\n",
      "68 \t I: |wayka!|  --------------  T: |¡Ataquen!|\n",
      "69 \t I: |Wayka!|  --------------  T: |¡Ataca!|\n",
      "70 \t I: |rantiy.|  -------------  T: |Cómprela.|\n",
      "71 \t I: |rantiy.|  -------------  T: |Cómpralo.|\n",
      "72 \t I: |Mikhuy.|  -------------  T: |Cómetelo.|\n",
      "73 \t I: |chayta mikhuy|  -------  T: |Coméoslo.|\n",
      "74 \t I: |chayta mikhuy|  -------  T: |Cómaselo.|\n",
      "75 \t I: |chayta mikhuy|  -------  T: |Cómanselo.|\n",
      "76 \t I: |Wichay.|  -------------  T: |Levanta.|\n",
      "77 \t I: |Kunanpacha riy.|  -----  T: |Ve ahora mismo.|\n",
      "78 \t I: |Kunanpacha riy.|  -----  T: |Id ahora mismo.|\n",
      "79 \t I: |Kunanpacha riy.|  -----  T: |Vaya ahora mismo.|\n",
      "80 \t I: |Kunanpacha riy.|  -----  T: |Vayan ahora mismo.|\n",
      "81 \t I: |Riyña.|  --------------  T: |Ve ya.|\n",
      "82 \t I: |kunan riy|  -----------  T: |Id ya.|\n",
      "83 \t I: |kunan riy|  -----------  T: |Vaya ya.|\n",
      "84 \t I: |kunan riy|  -----------  T: |Vayan ya.|\n",
      "85 \t I: |¡Ñoqaqa chayta chaskini!|    T: |¡Lo tengo!|\n",
      "86 \t I: |¿Chayta jap’inkichu?|    T: |¿Lo pillas?|\n",
      "87 \t I: |entienderqankichu?|  --  T: |¿Entendiste?|\n",
      "88 \t I: |Payqa phawarirqan.|  --  T: |Él corrió.|\n",
      "89 \t I: |Pawasqa.|  ------------  T: |Corrió.|\n",
      "90 \t I: |Ukhuman yaykuy.|  -----  T: |Métete adentro.|\n",
      "91 \t I: |Abrazaway.|  ----------  T: |Abrázame.|\n",
      "92 \t I: |Llakisqam kachkani.|  -  T: |Me preocupo.|\n",
      "93 \t I: |Urmarqanim.|  ---------  T: |Me caí.|\n",
      "94 \t I: |Ayqirqanim.|  ---------  T: |Huí.|\n",
      "95 \t I: |Ayqirqanim.|  ---------  T: |Me escapé.|\n",
      "96 \t I: |ayqirqa|  -------------  T: |Huía.|\n",
      "97 \t I: |Ayqichkarqanim.|  -----  T: |Me escapaba.|\n",
      "98 \t I: |Chaytaqa yachani.|  ---  T: |Yo lo sé.|\n",
      "99 \t I: |PAY.|  ----------------  T: |Sé.|\n"
     ]
    }
   ],
   "source": [
    "for index, registro in df_trans.iterrows():    \n",
    "    # Notar que los índices están al revés\n",
    "    input_text = registro[1].strip()\n",
    "    target_text = registro[0].strip()\n",
    "    \n",
    "    \n",
    "    if (index<100):\n",
    "        pad_dashes = \" \" + \"-\"*(20-len(input_text)) + \" \"\n",
    "        print(\"{} \\t I: |{}| {} T: |{}|\"\n",
    "              .format(index, input_text, pad_dashes, target_text))        \n",
    "\n",
    "    \n",
    "    # Usaremos \"tab\" como el  caracter de inicio (start sequence)\n",
    "    # para los targets, y \"\\n\" como el caracter de fin de secuencia \"end sequence\"\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    # sube las líneas a  las listas\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "  \n",
    "    # completa los conjuntos de caracteres si es necesario\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "666ef763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte los dos conjuntos de caracteres\n",
    "# en dos listas ordenadas\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))  \n",
    "# calcule el número de tokens (caracteres) en ambos lados\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "# calcula la máxima longitud de las secuencias en cada lado\n",
    "max_encoder_seq_length = max([len(text) for text in input_texts])\n",
    "max_decoder_seq_length = max([len(text) for text in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f44f962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 90313\n",
      "Number of unique input tokens: 103\n",
      "Number of unique output tokens: 111\n",
      "Max sequence length for inputs: 40\n",
      "Max sequence length for outputs: 42\n",
      "preparando datos...\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples:\", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
    "print(\"preparando datos...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebba2a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea diccionarios de tokens\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "# crea los tensores 1-hot para el encoder y el decoder\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\n",
    "\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62973e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "datos preparados\n"
     ]
    }
   ],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    # Modificar los valores de la matriz del encoder\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    \n",
    "    \n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    \n",
    "    \n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
    "\n",
    "print (\"\\n....\")\n",
    "print(\"datos preparados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e7a6b1",
   "metadata": {},
   "source": [
    "<h1>Construir el modelo</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b6616e",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Encoder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f2f0cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define una secuencia de entrada y la procesa\n",
    "encoder_inputs = Input(shape = (None, num_encoder_tokens))\n",
    "\n",
    "# capa recurrente del encoder\n",
    "encoder = LSTM(latent_dim, return_state = True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# Descartamos las salidas (encoder_outputs)\n",
    "# solamente se conserva las memoria de  corto (state_h) y \n",
    "# largo plazo(state_c)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85df2bee",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Decoder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4169602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos el decoder, usando 'encoder_states' como estado inicial\n",
    "decoder_inputs = Input(shape= (None, num_decoder_tokens))\n",
    "\n",
    "# capa recurrente del decoder\n",
    "# Configuramos nuestro decodificador para devolver secuencias de salida completas,\n",
    "# y también para devolver estados internos. No usamos los\n",
    "# estados retornados en el modelo de entrenamiento, pero los usaremos en inferencia.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _,_ = decoder_lstm(decoder_inputs,initial_state = encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9068842f",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Modelo Completo</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e58d44a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4505484d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, 103)]  0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None, 111)]  0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 256),        368640      ['input_1[0][0]']                \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 256),  376832      ['input_2[0][0]',                \n",
      "                                 (None, 256),                     'lstm[0][1]',                   \n",
      "                                 (None, 256)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 111)    28527       ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 773,999\n",
      "Trainable params: 773,999\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "plot_model(model, to_file='../Imagenes/s2s.png', \n",
    "           show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8078d390",
   "metadata": {},
   "source": [
    "<h1>Entrenar el modelo</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c3272db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84936b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "565/565 [==============================] - 19s 28ms/step - loss: 1.5552 - accuracy: 0.5762 - val_loss: 1.7008 - val_accuracy: 0.5091\n",
      "Epoch 2/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 1.1518 - accuracy: 0.6484 - val_loss: 1.5465 - val_accuracy: 0.5557\n",
      "Epoch 3/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 1.0500 - accuracy: 0.6750 - val_loss: 1.4399 - val_accuracy: 0.5802\n",
      "Epoch 4/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.9672 - accuracy: 0.7014 - val_loss: 1.3678 - val_accuracy: 0.6021\n",
      "Epoch 5/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.9323 - accuracy: 0.7128 - val_loss: 1.3152 - val_accuracy: 0.6169\n",
      "Epoch 6/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.8721 - accuracy: 0.7308 - val_loss: 1.2702 - val_accuracy: 0.6331\n",
      "Epoch 7/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.8307 - accuracy: 0.7440 - val_loss: 1.2345 - val_accuracy: 0.6437\n",
      "Epoch 8/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.7965 - accuracy: 0.7546 - val_loss: 1.1935 - val_accuracy: 0.6578\n",
      "Epoch 9/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.7671 - accuracy: 0.7641 - val_loss: 1.1764 - val_accuracy: 0.6643\n",
      "Epoch 10/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.7375 - accuracy: 0.7739 - val_loss: 1.1433 - val_accuracy: 0.6757\n",
      "Epoch 11/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.7096 - accuracy: 0.7828 - val_loss: 1.1157 - val_accuracy: 0.6851\n",
      "Epoch 12/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.6841 - accuracy: 0.7900 - val_loss: 1.0891 - val_accuracy: 0.6924\n",
      "Epoch 13/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.6634 - accuracy: 0.7961 - val_loss: 1.0791 - val_accuracy: 0.6965\n",
      "Epoch 14/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.6442 - accuracy: 0.8019 - val_loss: 1.0633 - val_accuracy: 0.7018\n",
      "Epoch 15/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.6294 - accuracy: 0.8060 - val_loss: 1.0489 - val_accuracy: 0.7069\n",
      "Epoch 16/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.6148 - accuracy: 0.8105 - val_loss: 1.0334 - val_accuracy: 0.7113\n",
      "Epoch 17/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.5993 - accuracy: 0.8153 - val_loss: 1.0230 - val_accuracy: 0.7160\n",
      "Epoch 18/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.5857 - accuracy: 0.8195 - val_loss: 1.0193 - val_accuracy: 0.7162\n",
      "Epoch 19/250\n",
      "565/565 [==============================] - 13s 24ms/step - loss: 0.5725 - accuracy: 0.8235 - val_loss: 1.0082 - val_accuracy: 0.7211\n",
      "Epoch 20/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.5600 - accuracy: 0.8275 - val_loss: 0.9997 - val_accuracy: 0.7246\n",
      "Epoch 21/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.5477 - accuracy: 0.8316 - val_loss: 0.9967 - val_accuracy: 0.7250\n",
      "Epoch 22/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.5364 - accuracy: 0.8349 - val_loss: 0.9844 - val_accuracy: 0.7303\n",
      "Epoch 23/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.5255 - accuracy: 0.8385 - val_loss: 0.9882 - val_accuracy: 0.7289\n",
      "Epoch 24/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.5154 - accuracy: 0.8415 - val_loss: 0.9749 - val_accuracy: 0.7336\n",
      "Epoch 25/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.5058 - accuracy: 0.8445 - val_loss: 0.9815 - val_accuracy: 0.7325\n",
      "Epoch 26/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.4969 - accuracy: 0.8473 - val_loss: 0.9761 - val_accuracy: 0.7347\n",
      "Epoch 27/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.4886 - accuracy: 0.8499 - val_loss: 0.9719 - val_accuracy: 0.7363\n",
      "Epoch 28/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.4805 - accuracy: 0.8524 - val_loss: 0.9708 - val_accuracy: 0.7380\n",
      "Epoch 29/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.4738 - accuracy: 0.8545 - val_loss: 0.9674 - val_accuracy: 0.7393\n",
      "Epoch 30/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.4658 - accuracy: 0.8567 - val_loss: 0.9672 - val_accuracy: 0.7404\n",
      "Epoch 31/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.4595 - accuracy: 0.8587 - val_loss: 0.9759 - val_accuracy: 0.7385\n",
      "Epoch 32/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.4531 - accuracy: 0.8607 - val_loss: 0.9661 - val_accuracy: 0.7421\n",
      "Epoch 33/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.4468 - accuracy: 0.8627 - val_loss: 0.9681 - val_accuracy: 0.7423\n",
      "Epoch 34/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.4408 - accuracy: 0.8646 - val_loss: 0.9682 - val_accuracy: 0.7434\n",
      "Epoch 35/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.4349 - accuracy: 0.8663 - val_loss: 0.9709 - val_accuracy: 0.7436\n",
      "Epoch 36/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.4292 - accuracy: 0.8682 - val_loss: 0.9773 - val_accuracy: 0.7432\n",
      "Epoch 37/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.4239 - accuracy: 0.8698 - val_loss: 0.9758 - val_accuracy: 0.7445\n",
      "Epoch 38/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.4187 - accuracy: 0.8715 - val_loss: 0.9782 - val_accuracy: 0.7442\n",
      "Epoch 39/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.4135 - accuracy: 0.8731 - val_loss: 0.9775 - val_accuracy: 0.7453\n",
      "Epoch 40/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.4085 - accuracy: 0.8747 - val_loss: 0.9805 - val_accuracy: 0.7461\n",
      "Epoch 41/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.4037 - accuracy: 0.8760 - val_loss: 0.9836 - val_accuracy: 0.7459\n",
      "Epoch 42/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.3992 - accuracy: 0.8776 - val_loss: 0.9850 - val_accuracy: 0.7463\n",
      "Epoch 43/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3947 - accuracy: 0.8789 - val_loss: 0.9917 - val_accuracy: 0.7462\n",
      "Epoch 44/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.3902 - accuracy: 0.8802 - val_loss: 0.9942 - val_accuracy: 0.7459\n",
      "Epoch 45/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3859 - accuracy: 0.8815 - val_loss: 1.0015 - val_accuracy: 0.7448\n",
      "Epoch 46/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3817 - accuracy: 0.8830 - val_loss: 1.0031 - val_accuracy: 0.7450\n",
      "Epoch 47/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3778 - accuracy: 0.8842 - val_loss: 1.0077 - val_accuracy: 0.7448\n",
      "Epoch 48/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3737 - accuracy: 0.8854 - val_loss: 1.0144 - val_accuracy: 0.7446\n",
      "Epoch 49/250\n",
      "565/565 [==============================] - 13s 24ms/step - loss: 0.3700 - accuracy: 0.8866 - val_loss: 1.0135 - val_accuracy: 0.7460\n",
      "Epoch 50/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3661 - accuracy: 0.8877 - val_loss: 1.0230 - val_accuracy: 0.7448\n",
      "Epoch 51/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.3625 - accuracy: 0.8889 - val_loss: 1.0291 - val_accuracy: 0.7436\n",
      "Epoch 52/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.3589 - accuracy: 0.8899 - val_loss: 1.0306 - val_accuracy: 0.7433\n",
      "Epoch 53/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.3556 - accuracy: 0.8910 - val_loss: 1.0360 - val_accuracy: 0.7447\n",
      "Epoch 54/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.3523 - accuracy: 0.8921 - val_loss: 1.0418 - val_accuracy: 0.7439\n",
      "Epoch 55/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3486 - accuracy: 0.8931 - val_loss: 1.0496 - val_accuracy: 0.7429\n",
      "Epoch 56/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.3457 - accuracy: 0.8940 - val_loss: 1.0547 - val_accuracy: 0.7432\n",
      "Epoch 57/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.3425 - accuracy: 0.8949 - val_loss: 1.0673 - val_accuracy: 0.7412\n",
      "Epoch 58/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.3396 - accuracy: 0.8959 - val_loss: 1.0663 - val_accuracy: 0.7414\n",
      "Epoch 59/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.3368 - accuracy: 0.8966 - val_loss: 1.0651 - val_accuracy: 0.7434\n",
      "Epoch 60/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.3336 - accuracy: 0.8976 - val_loss: 1.0755 - val_accuracy: 0.7422\n",
      "Epoch 61/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.3311 - accuracy: 0.8985 - val_loss: 1.0795 - val_accuracy: 0.7418\n",
      "Epoch 62/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.3282 - accuracy: 0.8992 - val_loss: 1.0901 - val_accuracy: 0.7409\n",
      "Epoch 63/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3257 - accuracy: 0.9000 - val_loss: 1.0973 - val_accuracy: 0.7403\n",
      "Epoch 64/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3227 - accuracy: 0.9011 - val_loss: 1.0974 - val_accuracy: 0.7416\n",
      "Epoch 65/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.3203 - accuracy: 0.9017 - val_loss: 1.1039 - val_accuracy: 0.7408\n",
      "Epoch 66/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.3182 - accuracy: 0.9022 - val_loss: 1.1108 - val_accuracy: 0.7399\n",
      "Epoch 67/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.3158 - accuracy: 0.9031 - val_loss: 1.1184 - val_accuracy: 0.7384\n",
      "Epoch 68/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.3133 - accuracy: 0.9038 - val_loss: 1.1349 - val_accuracy: 0.7366\n",
      "Epoch 69/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.3118 - accuracy: 0.9042 - val_loss: 1.1335 - val_accuracy: 0.7382\n",
      "Epoch 70/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.3086 - accuracy: 0.9053 - val_loss: 1.1408 - val_accuracy: 0.7381\n",
      "Epoch 71/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3066 - accuracy: 0.9058 - val_loss: 1.1393 - val_accuracy: 0.7385\n",
      "Epoch 72/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3046 - accuracy: 0.9064 - val_loss: 1.1482 - val_accuracy: 0.7379\n",
      "Epoch 73/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.3027 - accuracy: 0.9070 - val_loss: 1.1523 - val_accuracy: 0.7383\n",
      "Epoch 74/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.3007 - accuracy: 0.9076 - val_loss: 1.1580 - val_accuracy: 0.7375\n",
      "Epoch 75/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2992 - accuracy: 0.9080 - val_loss: 1.1594 - val_accuracy: 0.7374\n",
      "Epoch 76/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2973 - accuracy: 0.9085 - val_loss: 1.1679 - val_accuracy: 0.7368\n",
      "Epoch 77/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2950 - accuracy: 0.9092 - val_loss: 1.1772 - val_accuracy: 0.7363\n",
      "Epoch 78/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2936 - accuracy: 0.9097 - val_loss: 1.1805 - val_accuracy: 0.7361\n",
      "Epoch 79/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2916 - accuracy: 0.9103 - val_loss: 1.1802 - val_accuracy: 0.7368\n",
      "Epoch 80/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2899 - accuracy: 0.9107 - val_loss: 1.1952 - val_accuracy: 0.7342\n",
      "Epoch 81/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2882 - accuracy: 0.9112 - val_loss: 1.1981 - val_accuracy: 0.7349\n",
      "Epoch 82/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2866 - accuracy: 0.9118 - val_loss: 1.2071 - val_accuracy: 0.7340\n",
      "Epoch 83/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2853 - accuracy: 0.9120 - val_loss: 1.2153 - val_accuracy: 0.7334\n",
      "Epoch 84/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2839 - accuracy: 0.9125 - val_loss: 1.2134 - val_accuracy: 0.7346\n",
      "Epoch 85/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2822 - accuracy: 0.9130 - val_loss: 1.2235 - val_accuracy: 0.7330\n",
      "Epoch 86/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2806 - accuracy: 0.9135 - val_loss: 1.2291 - val_accuracy: 0.7328\n",
      "Epoch 87/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2792 - accuracy: 0.9139 - val_loss: 1.2353 - val_accuracy: 0.7324\n",
      "Epoch 88/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2779 - accuracy: 0.9142 - val_loss: 1.2336 - val_accuracy: 0.7330\n",
      "Epoch 89/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2765 - accuracy: 0.9145 - val_loss: 1.2454 - val_accuracy: 0.7317\n",
      "Epoch 90/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2749 - accuracy: 0.9151 - val_loss: 1.2493 - val_accuracy: 0.7320\n",
      "Epoch 91/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2744 - accuracy: 0.9151 - val_loss: 1.2525 - val_accuracy: 0.7327\n",
      "Epoch 92/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.2728 - accuracy: 0.9157 - val_loss: 1.2558 - val_accuracy: 0.7324\n",
      "Epoch 93/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.2715 - accuracy: 0.9160 - val_loss: 1.2593 - val_accuracy: 0.7318\n",
      "Epoch 94/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2707 - accuracy: 0.9162 - val_loss: 1.2633 - val_accuracy: 0.7318\n",
      "Epoch 95/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2689 - accuracy: 0.9169 - val_loss: 1.2676 - val_accuracy: 0.7308\n",
      "Epoch 96/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2680 - accuracy: 0.9170 - val_loss: 1.2809 - val_accuracy: 0.7304\n",
      "Epoch 97/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2670 - accuracy: 0.9174 - val_loss: 1.2785 - val_accuracy: 0.7315\n",
      "Epoch 98/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2659 - accuracy: 0.9178 - val_loss: 1.2887 - val_accuracy: 0.7300\n",
      "Epoch 99/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2648 - accuracy: 0.9180 - val_loss: 1.2880 - val_accuracy: 0.7311\n",
      "Epoch 100/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2632 - accuracy: 0.9187 - val_loss: 1.2947 - val_accuracy: 0.7308\n",
      "Epoch 101/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2627 - accuracy: 0.9188 - val_loss: 1.3066 - val_accuracy: 0.7283\n",
      "Epoch 102/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2616 - accuracy: 0.9190 - val_loss: 1.3022 - val_accuracy: 0.7296\n",
      "Epoch 103/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2609 - accuracy: 0.9191 - val_loss: 1.3044 - val_accuracy: 0.7294\n",
      "Epoch 104/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2600 - accuracy: 0.9195 - val_loss: 1.3124 - val_accuracy: 0.7289\n",
      "Epoch 105/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2587 - accuracy: 0.9198 - val_loss: 1.3216 - val_accuracy: 0.7285\n",
      "Epoch 106/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2579 - accuracy: 0.9200 - val_loss: 1.3159 - val_accuracy: 0.7295\n",
      "Epoch 107/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2583 - accuracy: 0.9198 - val_loss: 1.3188 - val_accuracy: 0.7295\n",
      "Epoch 108/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2560 - accuracy: 0.9206 - val_loss: 1.3305 - val_accuracy: 0.7280\n",
      "Epoch 109/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2560 - accuracy: 0.9205 - val_loss: 1.3365 - val_accuracy: 0.7276\n",
      "Epoch 110/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2548 - accuracy: 0.9210 - val_loss: 1.3394 - val_accuracy: 0.7274\n",
      "Epoch 111/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2536 - accuracy: 0.9213 - val_loss: 1.3381 - val_accuracy: 0.7284\n",
      "Epoch 112/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2526 - accuracy: 0.9214 - val_loss: 1.3470 - val_accuracy: 0.7273\n",
      "Epoch 113/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2516 - accuracy: 0.9219 - val_loss: 1.3432 - val_accuracy: 0.7285\n",
      "Epoch 114/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2515 - accuracy: 0.9217 - val_loss: 1.3556 - val_accuracy: 0.7274\n",
      "Epoch 115/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2503 - accuracy: 0.9222 - val_loss: 1.3513 - val_accuracy: 0.7286\n",
      "Epoch 116/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2501 - accuracy: 0.9223 - val_loss: 1.3613 - val_accuracy: 0.7263\n",
      "Epoch 117/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2496 - accuracy: 0.9224 - val_loss: 1.3615 - val_accuracy: 0.7278\n",
      "Epoch 118/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2480 - accuracy: 0.9229 - val_loss: 1.3651 - val_accuracy: 0.7272\n",
      "Epoch 119/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2470 - accuracy: 0.9232 - val_loss: 1.3745 - val_accuracy: 0.7265\n",
      "Epoch 120/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2475 - accuracy: 0.9229 - val_loss: 1.3714 - val_accuracy: 0.7273\n",
      "Epoch 121/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2467 - accuracy: 0.9231 - val_loss: 1.3764 - val_accuracy: 0.7273\n",
      "Epoch 122/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2454 - accuracy: 0.9236 - val_loss: 1.3777 - val_accuracy: 0.7267\n",
      "Epoch 123/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2450 - accuracy: 0.9237 - val_loss: 1.3816 - val_accuracy: 0.7275\n",
      "Epoch 124/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2442 - accuracy: 0.9239 - val_loss: 1.3868 - val_accuracy: 0.7265\n",
      "Epoch 125/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2436 - accuracy: 0.9241 - val_loss: 1.3897 - val_accuracy: 0.7267\n",
      "Epoch 126/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2424 - accuracy: 0.9244 - val_loss: 1.3919 - val_accuracy: 0.7262\n",
      "Epoch 127/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2424 - accuracy: 0.9244 - val_loss: 1.3979 - val_accuracy: 0.7254\n",
      "Epoch 128/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2428 - accuracy: 0.9243 - val_loss: 1.4003 - val_accuracy: 0.7259\n",
      "Epoch 129/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2417 - accuracy: 0.9247 - val_loss: 1.4001 - val_accuracy: 0.7265\n",
      "Epoch 130/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2396 - accuracy: 0.9253 - val_loss: 1.4035 - val_accuracy: 0.7267\n",
      "Epoch 131/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2396 - accuracy: 0.9254 - val_loss: 1.4122 - val_accuracy: 0.7254\n",
      "Epoch 132/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2392 - accuracy: 0.9253 - val_loss: 1.4098 - val_accuracy: 0.7264\n",
      "Epoch 133/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2396 - accuracy: 0.9251 - val_loss: 1.4209 - val_accuracy: 0.7246\n",
      "Epoch 134/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2373 - accuracy: 0.9260 - val_loss: 1.4244 - val_accuracy: 0.7248\n",
      "Epoch 135/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2376 - accuracy: 0.9258 - val_loss: 1.4241 - val_accuracy: 0.7252\n",
      "Epoch 136/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2383 - accuracy: 0.9255 - val_loss: 1.4188 - val_accuracy: 0.7258\n",
      "Epoch 137/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2372 - accuracy: 0.9258 - val_loss: 1.4218 - val_accuracy: 0.7267\n",
      "Epoch 138/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.2358 - accuracy: 0.9263 - val_loss: 1.4367 - val_accuracy: 0.7245\n",
      "Epoch 139/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2356 - accuracy: 0.9263 - val_loss: 1.4434 - val_accuracy: 0.7230\n",
      "Epoch 140/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.2355 - accuracy: 0.9264 - val_loss: 1.4404 - val_accuracy: 0.7251\n",
      "Epoch 141/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2353 - accuracy: 0.9265 - val_loss: 1.4380 - val_accuracy: 0.7244\n",
      "Epoch 142/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2338 - accuracy: 0.9269 - val_loss: 1.4405 - val_accuracy: 0.7247\n",
      "Epoch 143/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2333 - accuracy: 0.9269 - val_loss: 1.4428 - val_accuracy: 0.7254\n",
      "Epoch 144/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2328 - accuracy: 0.9271 - val_loss: 1.4398 - val_accuracy: 0.7257\n",
      "Epoch 145/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2331 - accuracy: 0.9270 - val_loss: 1.4440 - val_accuracy: 0.7252\n",
      "Epoch 146/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2324 - accuracy: 0.9271 - val_loss: 1.4541 - val_accuracy: 0.7243\n",
      "Epoch 147/250\n",
      "565/565 [==============================] - 15s 27ms/step - loss: 0.2327 - accuracy: 0.9271 - val_loss: 1.4526 - val_accuracy: 0.7249\n",
      "Epoch 148/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2315 - accuracy: 0.9275 - val_loss: 1.4619 - val_accuracy: 0.7231\n",
      "Epoch 149/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2312 - accuracy: 0.9275 - val_loss: 1.4620 - val_accuracy: 0.7242\n",
      "Epoch 150/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2318 - accuracy: 0.9273 - val_loss: 1.4692 - val_accuracy: 0.7233\n",
      "Epoch 151/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2304 - accuracy: 0.9279 - val_loss: 1.4610 - val_accuracy: 0.7248\n",
      "Epoch 152/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2296 - accuracy: 0.9280 - val_loss: 1.4743 - val_accuracy: 0.7230\n",
      "Epoch 153/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2292 - accuracy: 0.9282 - val_loss: 1.4743 - val_accuracy: 0.7244\n",
      "Epoch 154/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2288 - accuracy: 0.9281 - val_loss: 1.4799 - val_accuracy: 0.7222\n",
      "Epoch 155/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2288 - accuracy: 0.9282 - val_loss: 1.4788 - val_accuracy: 0.7232\n",
      "Epoch 156/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2275 - accuracy: 0.9287 - val_loss: 1.4924 - val_accuracy: 0.7213\n",
      "Epoch 157/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2281 - accuracy: 0.9285 - val_loss: 1.4785 - val_accuracy: 0.7241\n",
      "Epoch 158/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2274 - accuracy: 0.9287 - val_loss: 1.4820 - val_accuracy: 0.7245\n",
      "Epoch 159/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2266 - accuracy: 0.9288 - val_loss: 1.4821 - val_accuracy: 0.7236\n",
      "Epoch 160/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2263 - accuracy: 0.9288 - val_loss: 1.4925 - val_accuracy: 0.7223\n",
      "Epoch 161/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2263 - accuracy: 0.9290 - val_loss: 1.4906 - val_accuracy: 0.7238\n",
      "Epoch 162/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2260 - accuracy: 0.9290 - val_loss: 1.4946 - val_accuracy: 0.7230\n",
      "Epoch 163/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2256 - accuracy: 0.9291 - val_loss: 1.5034 - val_accuracy: 0.7220\n",
      "Epoch 164/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2252 - accuracy: 0.9292 - val_loss: 1.4937 - val_accuracy: 0.7241\n",
      "Epoch 165/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2247 - accuracy: 0.9293 - val_loss: 1.5013 - val_accuracy: 0.7227\n",
      "Epoch 166/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2243 - accuracy: 0.9296 - val_loss: 1.4988 - val_accuracy: 0.7231\n",
      "Epoch 167/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2234 - accuracy: 0.9299 - val_loss: 1.5040 - val_accuracy: 0.7236\n",
      "Epoch 168/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2229 - accuracy: 0.9300 - val_loss: 1.5058 - val_accuracy: 0.7226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2241 - accuracy: 0.9295 - val_loss: 1.5065 - val_accuracy: 0.7233\n",
      "Epoch 170/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2233 - accuracy: 0.9297 - val_loss: 1.5165 - val_accuracy: 0.7221\n",
      "Epoch 171/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2232 - accuracy: 0.9298 - val_loss: 1.5204 - val_accuracy: 0.7220\n",
      "Epoch 172/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2224 - accuracy: 0.9299 - val_loss: 1.5207 - val_accuracy: 0.7224\n",
      "Epoch 173/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2221 - accuracy: 0.9302 - val_loss: 1.5207 - val_accuracy: 0.7230\n",
      "Epoch 174/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2217 - accuracy: 0.9301 - val_loss: 1.5273 - val_accuracy: 0.7217\n",
      "Epoch 175/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2209 - accuracy: 0.9303 - val_loss: 1.5240 - val_accuracy: 0.7229\n",
      "Epoch 176/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2210 - accuracy: 0.9304 - val_loss: 1.5306 - val_accuracy: 0.7214\n",
      "Epoch 177/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2209 - accuracy: 0.9303 - val_loss: 1.5298 - val_accuracy: 0.7210\n",
      "Epoch 178/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2211 - accuracy: 0.9303 - val_loss: 1.5311 - val_accuracy: 0.7224\n",
      "Epoch 179/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2202 - accuracy: 0.9307 - val_loss: 1.5227 - val_accuracy: 0.7235\n",
      "Epoch 180/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2199 - accuracy: 0.9307 - val_loss: 1.5276 - val_accuracy: 0.7232\n",
      "Epoch 181/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2188 - accuracy: 0.9310 - val_loss: 1.5382 - val_accuracy: 0.7216\n",
      "Epoch 182/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2192 - accuracy: 0.9308 - val_loss: 1.5381 - val_accuracy: 0.7229\n",
      "Epoch 183/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2184 - accuracy: 0.9313 - val_loss: 1.5486 - val_accuracy: 0.7206\n",
      "Epoch 184/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2180 - accuracy: 0.9314 - val_loss: 1.5465 - val_accuracy: 0.7210\n",
      "Epoch 185/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2188 - accuracy: 0.9310 - val_loss: 1.5432 - val_accuracy: 0.7227\n",
      "Epoch 186/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2178 - accuracy: 0.9314 - val_loss: 1.5441 - val_accuracy: 0.7210\n",
      "Epoch 187/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2186 - accuracy: 0.9309 - val_loss: 1.5495 - val_accuracy: 0.7213\n",
      "Epoch 188/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2177 - accuracy: 0.9315 - val_loss: 1.5502 - val_accuracy: 0.7214\n",
      "Epoch 189/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2172 - accuracy: 0.9314 - val_loss: 1.5405 - val_accuracy: 0.7231\n",
      "Epoch 190/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2173 - accuracy: 0.9313 - val_loss: 1.5552 - val_accuracy: 0.7209\n",
      "Epoch 191/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2160 - accuracy: 0.9319 - val_loss: 1.5590 - val_accuracy: 0.7219\n",
      "Epoch 192/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2166 - accuracy: 0.9316 - val_loss: 1.5662 - val_accuracy: 0.7195\n",
      "Epoch 193/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2162 - accuracy: 0.9316 - val_loss: 1.5664 - val_accuracy: 0.7205\n",
      "Epoch 194/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2166 - accuracy: 0.9316 - val_loss: 1.5687 - val_accuracy: 0.7203\n",
      "Epoch 195/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2159 - accuracy: 0.9318 - val_loss: 1.5625 - val_accuracy: 0.7225\n",
      "Epoch 196/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2146 - accuracy: 0.9322 - val_loss: 1.5671 - val_accuracy: 0.7213\n",
      "Epoch 197/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2149 - accuracy: 0.9321 - val_loss: 1.5596 - val_accuracy: 0.7223\n",
      "Epoch 198/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2150 - accuracy: 0.9320 - val_loss: 1.5734 - val_accuracy: 0.7210\n",
      "Epoch 199/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2144 - accuracy: 0.9321 - val_loss: 1.5773 - val_accuracy: 0.7202\n",
      "Epoch 200/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2144 - accuracy: 0.9322 - val_loss: 1.5714 - val_accuracy: 0.7212\n",
      "Epoch 201/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2143 - accuracy: 0.9321 - val_loss: 1.5655 - val_accuracy: 0.7219\n",
      "Epoch 202/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2137 - accuracy: 0.9325 - val_loss: 1.5771 - val_accuracy: 0.7203\n",
      "Epoch 203/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.2141 - accuracy: 0.9323 - val_loss: 1.5702 - val_accuracy: 0.7222\n",
      "Epoch 204/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.2140 - accuracy: 0.9324 - val_loss: 1.5809 - val_accuracy: 0.7202\n",
      "Epoch 205/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2131 - accuracy: 0.9326 - val_loss: 1.5805 - val_accuracy: 0.7211\n",
      "Epoch 206/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2123 - accuracy: 0.9329 - val_loss: 1.5724 - val_accuracy: 0.7219\n",
      "Epoch 207/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2128 - accuracy: 0.9326 - val_loss: 1.5865 - val_accuracy: 0.7211\n",
      "Epoch 208/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2126 - accuracy: 0.9328 - val_loss: 1.5859 - val_accuracy: 0.7213\n",
      "Epoch 209/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2117 - accuracy: 0.9331 - val_loss: 1.5949 - val_accuracy: 0.7199\n",
      "Epoch 210/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2129 - accuracy: 0.9326 - val_loss: 1.5859 - val_accuracy: 0.7208\n",
      "Epoch 211/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2123 - accuracy: 0.9326 - val_loss: 1.5942 - val_accuracy: 0.7198\n",
      "Epoch 212/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2113 - accuracy: 0.9331 - val_loss: 1.5890 - val_accuracy: 0.7203\n",
      "Epoch 213/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2113 - accuracy: 0.9330 - val_loss: 1.6035 - val_accuracy: 0.7191\n",
      "Epoch 214/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2117 - accuracy: 0.9329 - val_loss: 1.5956 - val_accuracy: 0.7201\n",
      "Epoch 215/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2107 - accuracy: 0.9333 - val_loss: 1.6045 - val_accuracy: 0.7201\n",
      "Epoch 216/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2106 - accuracy: 0.9332 - val_loss: 1.6003 - val_accuracy: 0.7200\n",
      "Epoch 217/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2097 - accuracy: 0.9335 - val_loss: 1.6000 - val_accuracy: 0.7198\n",
      "Epoch 218/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2102 - accuracy: 0.9335 - val_loss: 1.5998 - val_accuracy: 0.7212\n",
      "Epoch 219/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2099 - accuracy: 0.9334 - val_loss: 1.6111 - val_accuracy: 0.7193\n",
      "Epoch 220/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2118 - accuracy: 0.9329 - val_loss: 1.6147 - val_accuracy: 0.7179\n",
      "Epoch 221/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2090 - accuracy: 0.9338 - val_loss: 1.6085 - val_accuracy: 0.7189\n",
      "Epoch 222/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2094 - accuracy: 0.9336 - val_loss: 1.6092 - val_accuracy: 0.7204\n",
      "Epoch 223/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2102 - accuracy: 0.9333 - val_loss: 1.6068 - val_accuracy: 0.7208\n",
      "Epoch 224/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2080 - accuracy: 0.9340 - val_loss: 1.6097 - val_accuracy: 0.7205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.2088 - accuracy: 0.9337 - val_loss: 1.6235 - val_accuracy: 0.7183\n",
      "Epoch 226/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2092 - accuracy: 0.9336 - val_loss: 1.6258 - val_accuracy: 0.7175\n",
      "Epoch 227/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2082 - accuracy: 0.9340 - val_loss: 1.6212 - val_accuracy: 0.7194\n",
      "Epoch 228/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2083 - accuracy: 0.9340 - val_loss: 1.6128 - val_accuracy: 0.7205\n",
      "Epoch 229/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2086 - accuracy: 0.9338 - val_loss: 1.6131 - val_accuracy: 0.7197\n",
      "Epoch 230/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2071 - accuracy: 0.9342 - val_loss: 1.6227 - val_accuracy: 0.7194\n",
      "Epoch 231/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2075 - accuracy: 0.9340 - val_loss: 1.6253 - val_accuracy: 0.7191\n",
      "Epoch 232/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2072 - accuracy: 0.9342 - val_loss: 1.6284 - val_accuracy: 0.7187\n",
      "Epoch 233/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2076 - accuracy: 0.9341 - val_loss: 1.6155 - val_accuracy: 0.7210\n",
      "Epoch 234/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2071 - accuracy: 0.9342 - val_loss: 1.6318 - val_accuracy: 0.7196\n",
      "Epoch 235/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2061 - accuracy: 0.9345 - val_loss: 1.6283 - val_accuracy: 0.7204\n",
      "Epoch 236/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2072 - accuracy: 0.9341 - val_loss: 1.6299 - val_accuracy: 0.7197\n",
      "Epoch 237/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2100 - accuracy: 0.9331 - val_loss: 1.6282 - val_accuracy: 0.7202\n",
      "Epoch 238/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2056 - accuracy: 0.9347 - val_loss: 1.6322 - val_accuracy: 0.7196\n",
      "Epoch 239/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2052 - accuracy: 0.9349 - val_loss: 1.6349 - val_accuracy: 0.7196\n",
      "Epoch 240/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2065 - accuracy: 0.9342 - val_loss: 1.6263 - val_accuracy: 0.7204\n",
      "Epoch 241/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2057 - accuracy: 0.9347 - val_loss: 1.6378 - val_accuracy: 0.7186\n",
      "Epoch 242/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2051 - accuracy: 0.9349 - val_loss: 1.6352 - val_accuracy: 0.7203\n",
      "Epoch 243/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2056 - accuracy: 0.9347 - val_loss: 1.6355 - val_accuracy: 0.7198\n",
      "Epoch 244/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2058 - accuracy: 0.9346 - val_loss: 1.6342 - val_accuracy: 0.7206\n",
      "Epoch 245/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2049 - accuracy: 0.9349 - val_loss: 1.6363 - val_accuracy: 0.7207\n",
      "Epoch 246/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2049 - accuracy: 0.9348 - val_loss: 1.6482 - val_accuracy: 0.7189\n",
      "Epoch 247/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2044 - accuracy: 0.9350 - val_loss: 1.6400 - val_accuracy: 0.7212\n",
      "Epoch 248/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2049 - accuracy: 0.9349 - val_loss: 1.6462 - val_accuracy: 0.7195\n",
      "Epoch 249/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2054 - accuracy: 0.9348 - val_loss: 1.6518 - val_accuracy: 0.7185\n",
      "Epoch 250/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.2044 - accuracy: 0.9350 - val_loss: 1.6475 - val_accuracy: 0.7198\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb09931",
   "metadata": {},
   "source": [
    "<h1>Guardar el modelo</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c59c1",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Diccionarios</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d954601",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/q2s/input_token_index.txt\", \"w\") as f:\n",
    "    json.dump(input_token_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e77635fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/q2s/target_token_index.txt\", \"w\") as f:\n",
    "    json.dump(target_token_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13f756f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/q2s/history.txt\", \"w\") as f:\n",
    "    json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445fbf86",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Valores puntuales</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e93b5e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_decoder_tokens: 111\n",
      "max_decoder_seq_length: 42\n",
      "Number of unique input tokens: 103\n",
      "Number of unique output tokens: 111\n",
      "Max sequence length for inputs: 40\n",
      "Max sequence length for outputs: 42\n"
     ]
    }
   ],
   "source": [
    "print(\"num_decoder_tokens: {}\".format(num_decoder_tokens))\n",
    "print(\"max_decoder_seq_length: {}\".format(max_decoder_seq_length))\n",
    "\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5be3bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/q2s/otros.txt\", \"w\") as f:\n",
    "    f.write(\"num_encoder_tokens = {}\\n\".format(num_encoder_tokens))\n",
    "    f.write(\"num_decoder_tokens = {}\\n\".format(num_decoder_tokens))\n",
    "    \n",
    "    f.write(\"max_encoder_seq_length = {}\\n\".format(max_encoder_seq_length))\n",
    "    f.write(\"max_decoder_seq_length = {}\".format(max_decoder_seq_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880cf75b",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Arreglo numpy</h3>\n",
    "<p>Sólo las primeras 100 posiciones</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e456f8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./Modelos/q2s/encoder_input_data_sample.npy\"\n",
    "with open(file_name, \"wb\") as f:\n",
    "    np.save(f, encoder_input_data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f12bbad",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Modelo</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f79defd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Modelos/q2s/spanish_to_quechua\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Modelos/q2s/spanish_to_quechua\\assets\n"
     ]
    }
   ],
   "source": [
    "# s2q = Spanish to Quechua\n",
    "model.save(\"./Modelos/q2s/spanish_to_quechua\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a0b29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./Modelos/q2s/spanish_to_quechua_file.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
