{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2c67e2e",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gold; background-color:black; padding:20px\">TRADUCTOR QUECHUA - ESPAÑOL / ESPAÑOL - QUECHUA</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e263aaa4",
   "metadata": {},
   "source": [
    "<h1>Importar librerias a utilizar</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e9ecb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea182627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd6966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809fdacb",
   "metadata": {},
   "source": [
    "<h1>Definir funciones auxiliares</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b727190",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Imprime barra de progreso</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b62cc105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimir_barra_progreso_v2(progreso, total):\n",
    "    # https://www.youtube.com/watch?v=x1eaT88vJUA\n",
    "    \n",
    "    p = int(100 * (progreso + 1)/total)\n",
    "\n",
    "    # Alt+291: █\n",
    "    barra = '█'*p + '-'*(100-p) \n",
    "\n",
    "    print(\"\\r|{}| {}%\".format(barra, p), end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702e8751",
   "metadata": {},
   "source": [
    "<h1>Importar datos</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a89f42",
   "metadata": {},
   "source": [
    "<p>Los archivos contienen palabras/oraciones paralelas\n",
    "<br>\n",
    "La primera columna está en español y la segunda en quechua</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f2c4f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>español</th>\n",
       "      <th>quechua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [español, quechua]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un dataframe vació que almacenará las traducciones (translations)\n",
    "df_trans = pd.DataFrame(columns=[\"español\",\"quechua\"])\n",
    "df_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1513c829",
   "metadata": {},
   "source": [
    "<p>Se utilizó un tab (\"\\t\") como separador de columnas para evitar confusiones con las comas propias de las oraciones</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19401cc0",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Importa DataFrames</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb377b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_paths = [\"./Datos/palabras/\",\n",
    "             \"./Datos/grupos/\",\n",
    "             \"./Datos/libros/\"]\n",
    "\n",
    "for sub_path in sub_paths:\n",
    "    arr_category = os.listdir(sub_path)\n",
    "\n",
    "    for item in arr_category:\n",
    "        if item[-4:] == \".csv\":\n",
    "            file = \"{}{}\".format(sub_path,item)\n",
    "            df_temp = pd.read_csv(file, encoding=\"utf-8\", sep=\"\\t\")\n",
    "            \n",
    "            df_trans = pd.concat([df_trans, df_temp]\n",
    "                                 , ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78f8351c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>español</th>\n",
       "      <th>quechua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ácido</td>\n",
       "      <td>ácido nisqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agradable</td>\n",
       "      <td>munasqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agrícola</td>\n",
       "      <td>chakra llamk’aymanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>algún</td>\n",
       "      <td>wakin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amable</td>\n",
       "      <td>kuyakuq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17576</th>\n",
       "      <td>que aumenten sus fatigas tu tesoro;</td>\n",
       "      <td>qhapaq kayniyki llank’ayninkuta yapachun;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17577</th>\n",
       "      <td>y cambia horas de espuma por divinas.</td>\n",
       "      <td>hinaspa horas de espuma cambiay divinopaq.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17578</th>\n",
       "      <td>Sé rica adentro, en vez de serlo afuera.</td>\n",
       "      <td>Hawamanta qhapaq kaymantaqa, ukhupi qhapaq kay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17579</th>\n",
       "      <td>Devora tú a la Muerte y no la nutras,</td>\n",
       "      <td>Wañuytaqa mikhunkichis, manataq mikhuchinkich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17580</th>\n",
       "      <td>pues si ella muere, no podrás morir.</td>\n",
       "      <td>Bueno, wañuptinqa manam wañuwaqchu.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17581 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        español  \\\n",
       "0                                         ácido   \n",
       "1                                     agradable   \n",
       "2                                      agrícola   \n",
       "3                                         algún   \n",
       "4                                        amable   \n",
       "...                                         ...   \n",
       "17576       que aumenten sus fatigas tu tesoro;   \n",
       "17577     y cambia horas de espuma por divinas.   \n",
       "17578  Sé rica adentro, en vez de serlo afuera.   \n",
       "17579     Devora tú a la Muerte y no la nutras,   \n",
       "17580      pues si ella muere, no podrás morir.   \n",
       "\n",
       "                                                 quechua  \n",
       "0                                            ácido nisqa  \n",
       "1                                                munasqa  \n",
       "2                                   chakra llamk’aymanta  \n",
       "3                                                  wakin  \n",
       "4                                                kuyakuq  \n",
       "...                                                  ...  \n",
       "17576          qhapaq kayniyki llank’ayninkuta yapachun;  \n",
       "17577         hinaspa horas de espuma cambiay divinopaq.  \n",
       "17578    Hawamanta qhapaq kaymantaqa, ukhupi qhapaq kay.  \n",
       "17579   Wañuytaqa mikhunkichis, manataq mikhuchinkich...  \n",
       "17580                Bueno, wañuptinqa manam wañuwaqchu.  \n",
       "\n",
       "[17581 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb246c4",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Eliminar frases muy largas</h3>\n",
    "<p>Antes de agregar esta línea, se generaba el siguiente error al separar espacio en memoria para los arreglos de numpy</p>\n",
    "<p>Unable to allocate 152. GiB for an array with shape (18435, 18240, 121) and data type float32</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a073a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, registro in df_trans.iterrows():\n",
    "    txt_es = registro[0]\n",
    "    txt_qu = registro[1]\n",
    "    \n",
    "    if (len(txt_es) > 250) or (len(txt_qu) > 250):\n",
    "        #print(\"registro eliminado\")\n",
    "        df_trans = df_trans.drop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e80d3994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>español</th>\n",
       "      <th>quechua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ácido</td>\n",
       "      <td>ácido nisqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agradable</td>\n",
       "      <td>munasqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agrícola</td>\n",
       "      <td>chakra llamk’aymanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>algún</td>\n",
       "      <td>wakin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amable</td>\n",
       "      <td>kuyakuq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17576</th>\n",
       "      <td>que aumenten sus fatigas tu tesoro;</td>\n",
       "      <td>qhapaq kayniyki llank’ayninkuta yapachun;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17577</th>\n",
       "      <td>y cambia horas de espuma por divinas.</td>\n",
       "      <td>hinaspa horas de espuma cambiay divinopaq.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17578</th>\n",
       "      <td>Sé rica adentro, en vez de serlo afuera.</td>\n",
       "      <td>Hawamanta qhapaq kaymantaqa, ukhupi qhapaq kay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17579</th>\n",
       "      <td>Devora tú a la Muerte y no la nutras,</td>\n",
       "      <td>Wañuytaqa mikhunkichis, manataq mikhuchinkich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17580</th>\n",
       "      <td>pues si ella muere, no podrás morir.</td>\n",
       "      <td>Bueno, wañuptinqa manam wañuwaqchu.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16878 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        español  \\\n",
       "0                                         ácido   \n",
       "1                                     agradable   \n",
       "2                                      agrícola   \n",
       "3                                         algún   \n",
       "4                                        amable   \n",
       "...                                         ...   \n",
       "17576       que aumenten sus fatigas tu tesoro;   \n",
       "17577     y cambia horas de espuma por divinas.   \n",
       "17578  Sé rica adentro, en vez de serlo afuera.   \n",
       "17579     Devora tú a la Muerte y no la nutras,   \n",
       "17580      pues si ella muere, no podrás morir.   \n",
       "\n",
       "                                                 quechua  \n",
       "0                                            ácido nisqa  \n",
       "1                                                munasqa  \n",
       "2                                   chakra llamk’aymanta  \n",
       "3                                                  wakin  \n",
       "4                                                kuyakuq  \n",
       "...                                                  ...  \n",
       "17576          qhapaq kayniyki llank’ayninkuta yapachun;  \n",
       "17577         hinaspa horas de espuma cambiay divinopaq.  \n",
       "17578    Hawamanta qhapaq kaymantaqa, ukhupi qhapaq kay.  \n",
       "17579   Wañuytaqa mikhunkichis, manataq mikhuchinkich...  \n",
       "17580                Bueno, wañuptinqa manam wañuwaqchu.  \n",
       "\n",
       "[16878 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a2759f",
   "metadata": {},
   "source": [
    "<h1>Configuración</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cb7950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # tamño de los lotes para entrenamiento\n",
    "epochs = 250 # Número de epochs\n",
    "latent_dim = 256 # dimensión del espacio latente para el encoder\n",
    "num_samples = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc2402",
   "metadata": {},
   "source": [
    "<h1>Preparar los datos</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaf7020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectoriza los datos\n",
    "i=0\n",
    "targe_text= ''\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a34ade38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t I: ácido \t T: \n",
      "1 \t I: agradable \t T: \n",
      "2 \t I: agrícola \t T: \n",
      "3 \t I: algún \t T: \n",
      "4 \t I: amable \t T: \n",
      "5 \t I: amargo \t T: \n",
      "6 \t I: ambos \t T: \n",
      "7 \t I: ancho \t T: \n",
      "8 \t I: aquel \t T: \n",
      "9 \t I: aquellas \t T: \n"
     ]
    }
   ],
   "source": [
    "for index, registro in df_trans.iterrows():    \n",
    "    \n",
    "    input_text = registro[0]\n",
    "    target_text = registro[1]\n",
    "    \n",
    "    \n",
    "    if (index<10):\n",
    "        print(\"{} \\t I: {} \\t T: {}\"\n",
    "              .format(index, input_text, targe_text))        \n",
    "\n",
    "    \n",
    "    # Usaremos \"tab\" como el  caracter de inicio (start sequence)\n",
    "    # para los targets, y \"\\n\" como el caracter de fin de secuencia \"end sequence\"\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    # sube las líneas a  las listas\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "  \n",
    "    # completa los conjuntos de caracteres si es necesario\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "666ef763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convierte los dos conjuntos de caracteres\n",
    "# en dos listas ordenadas\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))  \n",
    "# calcule el número de tokens (caracteres) en ambos lados\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "# calcula la máxima longitud de las secuencias en cada lado\n",
    "max_encoder_seq_length = max([len(text) for text in input_texts])\n",
    "max_decoder_seq_length = max([len(text) for text in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f44f962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 16878\n",
      "Number of unique input tokens: 117\n",
      "Number of unique output tokens: 109\n",
      "Max sequence length for inputs: 250\n",
      "Max sequence length for outputs: 252\n",
      "preparando datos...\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples:\", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
    "print(\"preparando datos...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebba2a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea diccionarios de tokens\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "# crea los tensores 1-hot para el encoder y el decoder\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\n",
    "\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62973e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "datos preparados\n"
     ]
    }
   ],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
    "\n",
    "print (\"\\n....\")\n",
    "print(\"datos preparados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e7a6b1",
   "metadata": {},
   "source": [
    "<h1>Construir el modelo</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b6616e",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Encoder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f2f0cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define una secuencia de entrada y la procesa\n",
    "encoder_inputs = Input(shape = (None, num_encoder_tokens))\n",
    "\n",
    "# capa recurrente del encoder\n",
    "encoder = LSTM(latent_dim, return_state = True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# Descartamos las salidas (encoder_outputs)\n",
    "# solamente se conserva las memoria de  corto (state_h) y \n",
    "# largo plazo(state_c)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85df2bee",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Decoder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4169602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos el decoder, usando 'encoder_states' como estado inicial\n",
    "decoder_inputs = Input(shape= (None, num_decoder_tokens))\n",
    "\n",
    "# capa recurrente del decoder\n",
    "# Configuramos nuestro decodificador para devolver secuencias de salida completas,\n",
    "# y también para devolver estados internos. No usamos los\n",
    "# estados retornados en el modelo de entrenamiento, pero los usaremos en inferencia.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _,_ = decoder_lstm(decoder_inputs,initial_state = encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9068842f",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Modelo Completo</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e58d44a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4505484d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, 117)]  0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None, 109)]  0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 256),        382976      ['input_1[0][0]']                \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 256),  374784      ['input_2[0][0]',                \n",
      "                                 (None, 256),                     'lstm[0][1]',                   \n",
      "                                 (None, 256)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 109)    28013       ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 785,773\n",
      "Trainable params: 785,773\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "plot_model(model, to_file='../Imagenes/s2s.png', \n",
    "           show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8078d390",
   "metadata": {},
   "source": [
    "<h1>Entrenar el modelo</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c3272db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84936b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "211/211 [==============================] - 20s 77ms/step - loss: 1.2462 - accuracy: 0.7164 - val_loss: 0.9761 - val_accuracy: 0.7291\n",
      "Epoch 2/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.8345 - accuracy: 0.7698 - val_loss: 0.7762 - val_accuracy: 0.7802\n",
      "Epoch 3/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.7173 - accuracy: 0.7939 - val_loss: 0.7151 - val_accuracy: 0.7909\n",
      "Epoch 4/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.6712 - accuracy: 0.8028 - val_loss: 0.6815 - val_accuracy: 0.7994\n",
      "Epoch 5/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.6403 - accuracy: 0.8111 - val_loss: 0.6553 - val_accuracy: 0.8068\n",
      "Epoch 6/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.6137 - accuracy: 0.8194 - val_loss: 0.6259 - val_accuracy: 0.8163\n",
      "Epoch 7/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.5909 - accuracy: 0.8264 - val_loss: 0.6070 - val_accuracy: 0.8215\n",
      "Epoch 8/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.5713 - accuracy: 0.8319 - val_loss: 0.5909 - val_accuracy: 0.8263\n",
      "Epoch 9/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.5548 - accuracy: 0.8369 - val_loss: 0.5754 - val_accuracy: 0.8310\n",
      "Epoch 10/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.5396 - accuracy: 0.8412 - val_loss: 0.5628 - val_accuracy: 0.8348\n",
      "Epoch 11/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.5266 - accuracy: 0.8448 - val_loss: 0.5508 - val_accuracy: 0.8380\n",
      "Epoch 12/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.5145 - accuracy: 0.8482 - val_loss: 0.5415 - val_accuracy: 0.8401\n",
      "Epoch 13/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.5038 - accuracy: 0.8514 - val_loss: 0.5335 - val_accuracy: 0.8426\n",
      "Epoch 14/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4935 - accuracy: 0.8545 - val_loss: 0.5256 - val_accuracy: 0.8455\n",
      "Epoch 15/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.4845 - accuracy: 0.8571 - val_loss: 0.5186 - val_accuracy: 0.8468\n",
      "Epoch 16/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.4759 - accuracy: 0.8594 - val_loss: 0.5100 - val_accuracy: 0.8494\n",
      "Epoch 17/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.4677 - accuracy: 0.8616 - val_loss: 0.5051 - val_accuracy: 0.8510\n",
      "Epoch 18/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4598 - accuracy: 0.8638 - val_loss: 0.4975 - val_accuracy: 0.8533\n",
      "Epoch 19/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.4527 - accuracy: 0.8659 - val_loss: 0.4918 - val_accuracy: 0.8546\n",
      "Epoch 20/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.4458 - accuracy: 0.8679 - val_loss: 0.4875 - val_accuracy: 0.8555\n",
      "Epoch 21/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.4392 - accuracy: 0.8696 - val_loss: 0.4816 - val_accuracy: 0.8572\n",
      "Epoch 22/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.4330 - accuracy: 0.8712 - val_loss: 0.4768 - val_accuracy: 0.8585\n",
      "Epoch 23/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4275 - accuracy: 0.8727 - val_loss: 0.4732 - val_accuracy: 0.8594\n",
      "Epoch 24/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.4223 - accuracy: 0.8741 - val_loss: 0.4690 - val_accuracy: 0.8607\n",
      "Epoch 25/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.4172 - accuracy: 0.8755 - val_loss: 0.4672 - val_accuracy: 0.8613\n",
      "Epoch 26/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.4122 - accuracy: 0.8767 - val_loss: 0.4623 - val_accuracy: 0.8628\n",
      "Epoch 27/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.4075 - accuracy: 0.8780 - val_loss: 0.4589 - val_accuracy: 0.8630\n",
      "Epoch 28/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4031 - accuracy: 0.8791 - val_loss: 0.4570 - val_accuracy: 0.8635\n",
      "Epoch 29/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3983 - accuracy: 0.8804 - val_loss: 0.4523 - val_accuracy: 0.8651\n",
      "Epoch 30/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3930 - accuracy: 0.8818 - val_loss: 0.4497 - val_accuracy: 0.8653\n",
      "Epoch 31/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3904 - accuracy: 0.8824 - val_loss: 0.4503 - val_accuracy: 0.8653\n",
      "Epoch 32/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3869 - accuracy: 0.8834 - val_loss: 0.4453 - val_accuracy: 0.8668\n",
      "Epoch 33/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3829 - accuracy: 0.8845 - val_loss: 0.4424 - val_accuracy: 0.8677\n",
      "Epoch 34/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3794 - accuracy: 0.8853 - val_loss: 0.4428 - val_accuracy: 0.8678\n",
      "Epoch 35/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3761 - accuracy: 0.8862 - val_loss: 0.4384 - val_accuracy: 0.8687\n",
      "Epoch 36/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3729 - accuracy: 0.8870 - val_loss: 0.4381 - val_accuracy: 0.8686\n",
      "Epoch 37/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.3703 - accuracy: 0.8878 - val_loss: 0.4360 - val_accuracy: 0.8695\n",
      "Epoch 38/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.3676 - accuracy: 0.8884 - val_loss: 0.4367 - val_accuracy: 0.8693\n",
      "Epoch 39/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.3647 - accuracy: 0.8891 - val_loss: 0.4337 - val_accuracy: 0.8698\n",
      "Epoch 40/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3623 - accuracy: 0.8898 - val_loss: 0.4330 - val_accuracy: 0.8699\n",
      "Epoch 41/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.3597 - accuracy: 0.8906 - val_loss: 0.4326 - val_accuracy: 0.8705\n",
      "Epoch 42/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.3576 - accuracy: 0.8912 - val_loss: 0.4314 - val_accuracy: 0.8707\n",
      "Epoch 43/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.3551 - accuracy: 0.8918 - val_loss: 0.4304 - val_accuracy: 0.8708\n",
      "Epoch 44/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.3531 - accuracy: 0.8923 - val_loss: 0.4290 - val_accuracy: 0.8714\n",
      "Epoch 45/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3507 - accuracy: 0.8929 - val_loss: 0.4292 - val_accuracy: 0.8713\n",
      "Epoch 46/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.3488 - accuracy: 0.8935 - val_loss: 0.4282 - val_accuracy: 0.8714\n",
      "Epoch 47/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.3467 - accuracy: 0.8939 - val_loss: 0.4284 - val_accuracy: 0.8715\n",
      "Epoch 48/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3446 - accuracy: 0.8946 - val_loss: 0.4287 - val_accuracy: 0.8713\n",
      "Epoch 49/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3428 - accuracy: 0.8951 - val_loss: 0.4275 - val_accuracy: 0.8720\n",
      "Epoch 50/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3407 - accuracy: 0.8955 - val_loss: 0.4278 - val_accuracy: 0.8722\n",
      "Epoch 51/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3390 - accuracy: 0.8960 - val_loss: 0.4286 - val_accuracy: 0.8716\n",
      "Epoch 52/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3374 - accuracy: 0.8964 - val_loss: 0.4298 - val_accuracy: 0.8716\n",
      "Epoch 53/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3359 - accuracy: 0.8967 - val_loss: 0.4289 - val_accuracy: 0.8720\n",
      "Epoch 54/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3341 - accuracy: 0.8973 - val_loss: 0.4266 - val_accuracy: 0.8727\n",
      "Epoch 55/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3327 - accuracy: 0.8975 - val_loss: 0.4276 - val_accuracy: 0.8725\n",
      "Epoch 56/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3309 - accuracy: 0.8982 - val_loss: 0.4283 - val_accuracy: 0.8725\n",
      "Epoch 57/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3297 - accuracy: 0.8985 - val_loss: 0.4293 - val_accuracy: 0.8724\n",
      "Epoch 58/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3281 - accuracy: 0.8989 - val_loss: 0.4300 - val_accuracy: 0.8723\n",
      "Epoch 59/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3267 - accuracy: 0.8994 - val_loss: 0.4285 - val_accuracy: 0.8726\n",
      "Epoch 60/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3252 - accuracy: 0.8997 - val_loss: 0.4290 - val_accuracy: 0.8724\n",
      "Epoch 61/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3240 - accuracy: 0.9000 - val_loss: 0.4313 - val_accuracy: 0.8719\n",
      "Epoch 62/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3225 - accuracy: 0.9004 - val_loss: 0.4310 - val_accuracy: 0.8721\n",
      "Epoch 63/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3213 - accuracy: 0.9008 - val_loss: 0.4306 - val_accuracy: 0.8724\n",
      "Epoch 64/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3200 - accuracy: 0.9012 - val_loss: 0.4324 - val_accuracy: 0.8717\n",
      "Epoch 65/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3187 - accuracy: 0.9016 - val_loss: 0.4318 - val_accuracy: 0.8724\n",
      "Epoch 66/250\n",
      "211/211 [==============================] - 14s 66ms/step - loss: 0.3175 - accuracy: 0.9018 - val_loss: 0.4329 - val_accuracy: 0.8722\n",
      "Epoch 67/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3164 - accuracy: 0.9021 - val_loss: 0.4349 - val_accuracy: 0.8712\n",
      "Epoch 68/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3151 - accuracy: 0.9025 - val_loss: 0.4337 - val_accuracy: 0.8722\n",
      "Epoch 69/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3139 - accuracy: 0.9029 - val_loss: 0.4350 - val_accuracy: 0.8719\n",
      "Epoch 70/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3126 - accuracy: 0.9032 - val_loss: 0.4348 - val_accuracy: 0.8718\n",
      "Epoch 71/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3116 - accuracy: 0.9036 - val_loss: 0.4347 - val_accuracy: 0.8722\n",
      "Epoch 72/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3105 - accuracy: 0.9039 - val_loss: 0.4366 - val_accuracy: 0.8720\n",
      "Epoch 73/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3094 - accuracy: 0.9043 - val_loss: 0.4381 - val_accuracy: 0.8714\n",
      "Epoch 74/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3083 - accuracy: 0.9045 - val_loss: 0.4375 - val_accuracy: 0.8717\n",
      "Epoch 75/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3072 - accuracy: 0.9049 - val_loss: 0.4394 - val_accuracy: 0.8715\n",
      "Epoch 76/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3063 - accuracy: 0.9050 - val_loss: 0.4398 - val_accuracy: 0.8712\n",
      "Epoch 77/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3051 - accuracy: 0.9056 - val_loss: 0.4409 - val_accuracy: 0.8710\n",
      "Epoch 78/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3042 - accuracy: 0.9057 - val_loss: 0.4419 - val_accuracy: 0.8711\n",
      "Epoch 79/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3031 - accuracy: 0.9061 - val_loss: 0.4429 - val_accuracy: 0.8713\n",
      "Epoch 80/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3020 - accuracy: 0.9063 - val_loss: 0.4434 - val_accuracy: 0.8706\n",
      "Epoch 81/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3010 - accuracy: 0.9067 - val_loss: 0.4446 - val_accuracy: 0.8706\n",
      "Epoch 82/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3004 - accuracy: 0.9068 - val_loss: 0.4444 - val_accuracy: 0.8706\n",
      "Epoch 83/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2991 - accuracy: 0.9073 - val_loss: 0.4454 - val_accuracy: 0.8710\n",
      "Epoch 84/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2984 - accuracy: 0.9075 - val_loss: 0.4471 - val_accuracy: 0.8708\n",
      "Epoch 85/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2974 - accuracy: 0.9077 - val_loss: 0.4465 - val_accuracy: 0.8707\n",
      "Epoch 86/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2965 - accuracy: 0.9081 - val_loss: 0.4477 - val_accuracy: 0.8708\n",
      "Epoch 87/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2959 - accuracy: 0.9082 - val_loss: 0.4500 - val_accuracy: 0.8701\n",
      "Epoch 88/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2949 - accuracy: 0.9085 - val_loss: 0.4514 - val_accuracy: 0.8704\n",
      "Epoch 89/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2938 - accuracy: 0.9089 - val_loss: 0.4529 - val_accuracy: 0.8702\n",
      "Epoch 90/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2929 - accuracy: 0.9092 - val_loss: 0.4527 - val_accuracy: 0.8698\n",
      "Epoch 91/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2922 - accuracy: 0.9093 - val_loss: 0.4540 - val_accuracy: 0.8698\n",
      "Epoch 92/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2913 - accuracy: 0.9095 - val_loss: 0.4559 - val_accuracy: 0.8696\n",
      "Epoch 93/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2903 - accuracy: 0.9100 - val_loss: 0.4556 - val_accuracy: 0.8694\n",
      "Epoch 94/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2897 - accuracy: 0.9101 - val_loss: 0.4582 - val_accuracy: 0.8691\n",
      "Epoch 95/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2889 - accuracy: 0.9104 - val_loss: 0.4586 - val_accuracy: 0.8691\n",
      "Epoch 96/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2885 - accuracy: 0.9104 - val_loss: 0.4600 - val_accuracy: 0.8686\n",
      "Epoch 97/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2874 - accuracy: 0.9108 - val_loss: 0.4618 - val_accuracy: 0.8689\n",
      "Epoch 98/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2864 - accuracy: 0.9112 - val_loss: 0.4641 - val_accuracy: 0.8679\n",
      "Epoch 99/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2860 - accuracy: 0.9113 - val_loss: 0.4614 - val_accuracy: 0.8691\n",
      "Epoch 100/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2852 - accuracy: 0.9116 - val_loss: 0.4623 - val_accuracy: 0.8691\n",
      "Epoch 101/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2844 - accuracy: 0.9117 - val_loss: 0.4643 - val_accuracy: 0.8689\n",
      "Epoch 102/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2836 - accuracy: 0.9120 - val_loss: 0.4666 - val_accuracy: 0.8683\n",
      "Epoch 103/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2831 - accuracy: 0.9121 - val_loss: 0.4664 - val_accuracy: 0.8687\n",
      "Epoch 104/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2821 - accuracy: 0.9123 - val_loss: 0.4680 - val_accuracy: 0.8683\n",
      "Epoch 105/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2813 - accuracy: 0.9127 - val_loss: 0.4694 - val_accuracy: 0.8679\n",
      "Epoch 106/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2808 - accuracy: 0.9129 - val_loss: 0.4709 - val_accuracy: 0.8677\n",
      "Epoch 107/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2802 - accuracy: 0.9130 - val_loss: 0.4706 - val_accuracy: 0.8680\n",
      "Epoch 108/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2795 - accuracy: 0.9132 - val_loss: 0.4730 - val_accuracy: 0.8672\n",
      "Epoch 109/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2789 - accuracy: 0.9134 - val_loss: 0.4750 - val_accuracy: 0.8672\n",
      "Epoch 110/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2784 - accuracy: 0.9135 - val_loss: 0.4751 - val_accuracy: 0.8673\n",
      "Epoch 111/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2773 - accuracy: 0.9139 - val_loss: 0.4745 - val_accuracy: 0.8676\n",
      "Epoch 112/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2770 - accuracy: 0.9139 - val_loss: 0.4770 - val_accuracy: 0.8670\n",
      "Epoch 113/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2762 - accuracy: 0.9143 - val_loss: 0.4782 - val_accuracy: 0.8669\n",
      "Epoch 114/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2757 - accuracy: 0.9143 - val_loss: 0.4776 - val_accuracy: 0.8675\n",
      "Epoch 115/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2755 - accuracy: 0.9144 - val_loss: 0.4784 - val_accuracy: 0.8672\n",
      "Epoch 116/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2747 - accuracy: 0.9147 - val_loss: 0.4798 - val_accuracy: 0.8668\n",
      "Epoch 117/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2740 - accuracy: 0.9149 - val_loss: 0.4806 - val_accuracy: 0.8668\n",
      "Epoch 118/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2735 - accuracy: 0.9151 - val_loss: 0.4840 - val_accuracy: 0.8664\n",
      "Epoch 119/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2731 - accuracy: 0.9152 - val_loss: 0.4823 - val_accuracy: 0.8667\n",
      "Epoch 120/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2724 - accuracy: 0.9155 - val_loss: 0.4853 - val_accuracy: 0.8667\n",
      "Epoch 121/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2717 - accuracy: 0.9156 - val_loss: 0.4856 - val_accuracy: 0.8666\n",
      "Epoch 122/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2714 - accuracy: 0.9157 - val_loss: 0.4863 - val_accuracy: 0.8661\n",
      "Epoch 123/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2710 - accuracy: 0.9157 - val_loss: 0.4869 - val_accuracy: 0.8666\n",
      "Epoch 124/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2704 - accuracy: 0.9159 - val_loss: 0.4867 - val_accuracy: 0.8665\n",
      "Epoch 125/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2698 - accuracy: 0.9162 - val_loss: 0.4901 - val_accuracy: 0.8658\n",
      "Epoch 126/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2695 - accuracy: 0.9163 - val_loss: 0.4909 - val_accuracy: 0.8654\n",
      "Epoch 127/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2688 - accuracy: 0.9165 - val_loss: 0.4904 - val_accuracy: 0.8657\n",
      "Epoch 128/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2687 - accuracy: 0.9165 - val_loss: 0.4913 - val_accuracy: 0.8661\n",
      "Epoch 129/250\n",
      "211/211 [==============================] - 14s 66ms/step - loss: 0.2680 - accuracy: 0.9167 - val_loss: 0.4936 - val_accuracy: 0.8655\n",
      "Epoch 130/250\n",
      "211/211 [==============================] - 14s 66ms/step - loss: 0.2680 - accuracy: 0.9166 - val_loss: 0.4924 - val_accuracy: 0.8661\n",
      "Epoch 131/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2669 - accuracy: 0.9170 - val_loss: 0.4931 - val_accuracy: 0.8661\n",
      "Epoch 132/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2673 - accuracy: 0.9168 - val_loss: 0.4954 - val_accuracy: 0.8656\n",
      "Epoch 133/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2660 - accuracy: 0.9172 - val_loss: 0.4952 - val_accuracy: 0.8659\n",
      "Epoch 134/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2659 - accuracy: 0.9172 - val_loss: 0.4976 - val_accuracy: 0.8655\n",
      "Epoch 135/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2652 - accuracy: 0.9176 - val_loss: 0.4982 - val_accuracy: 0.8654\n",
      "Epoch 136/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2652 - accuracy: 0.9174 - val_loss: 0.4991 - val_accuracy: 0.8650\n",
      "Epoch 137/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2646 - accuracy: 0.9177 - val_loss: 0.4986 - val_accuracy: 0.8654\n",
      "Epoch 138/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2642 - accuracy: 0.9178 - val_loss: 0.4990 - val_accuracy: 0.8653\n",
      "Epoch 139/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2638 - accuracy: 0.9180 - val_loss: 0.5017 - val_accuracy: 0.8652\n",
      "Epoch 140/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2634 - accuracy: 0.9181 - val_loss: 0.5007 - val_accuracy: 0.8652\n",
      "Epoch 141/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2622 - accuracy: 0.9184 - val_loss: 0.5048 - val_accuracy: 0.8650\n",
      "Epoch 142/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2647 - accuracy: 0.9175 - val_loss: 0.5037 - val_accuracy: 0.8650\n",
      "Epoch 143/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2783 - accuracy: 0.9151 - val_loss: 0.5213 - val_accuracy: 0.8606\n",
      "Epoch 144/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2984 - accuracy: 0.9079 - val_loss: 0.4980 - val_accuracy: 0.8648\n",
      "Epoch 145/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2726 - accuracy: 0.9152 - val_loss: 0.4969 - val_accuracy: 0.8656\n",
      "Epoch 146/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2693 - accuracy: 0.9162 - val_loss: 0.4993 - val_accuracy: 0.8654\n",
      "Epoch 147/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2659 - accuracy: 0.9172 - val_loss: 0.5010 - val_accuracy: 0.8651\n",
      "Epoch 148/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2647 - accuracy: 0.9178 - val_loss: 0.4993 - val_accuracy: 0.8655\n",
      "Epoch 149/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2763 - accuracy: 0.9137 - val_loss: 0.4984 - val_accuracy: 0.8657\n",
      "Epoch 150/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2657 - accuracy: 0.9173 - val_loss: 0.5019 - val_accuracy: 0.8651\n",
      "Epoch 151/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2623 - accuracy: 0.9184 - val_loss: 0.5019 - val_accuracy: 0.8653\n",
      "Epoch 152/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2616 - accuracy: 0.9186 - val_loss: 0.5021 - val_accuracy: 0.8650\n",
      "Epoch 153/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2607 - accuracy: 0.9188 - val_loss: 0.5045 - val_accuracy: 0.8649\n",
      "Epoch 154/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2611 - accuracy: 0.9188 - val_loss: 0.5054 - val_accuracy: 0.8647\n",
      "Epoch 155/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2611 - accuracy: 0.9186 - val_loss: 0.5061 - val_accuracy: 0.8646\n",
      "Epoch 156/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2599 - accuracy: 0.9191 - val_loss: 0.5086 - val_accuracy: 0.8649\n",
      "Epoch 157/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2595 - accuracy: 0.9192 - val_loss: 0.5083 - val_accuracy: 0.8647\n",
      "Epoch 158/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2609 - accuracy: 0.9186 - val_loss: 0.5099 - val_accuracy: 0.8647\n",
      "Epoch 159/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2604 - accuracy: 0.9187 - val_loss: 0.5090 - val_accuracy: 0.8647\n",
      "Epoch 160/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2588 - accuracy: 0.9194 - val_loss: 0.5119 - val_accuracy: 0.8644\n",
      "Epoch 161/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2586 - accuracy: 0.9194 - val_loss: 0.5112 - val_accuracy: 0.8640\n",
      "Epoch 162/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2584 - accuracy: 0.9195 - val_loss: 0.5122 - val_accuracy: 0.8640\n",
      "Epoch 163/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2575 - accuracy: 0.9197 - val_loss: 0.5133 - val_accuracy: 0.8642\n",
      "Epoch 164/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2579 - accuracy: 0.9197 - val_loss: 0.5140 - val_accuracy: 0.8638\n",
      "Epoch 165/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2581 - accuracy: 0.9195 - val_loss: 0.5147 - val_accuracy: 0.8639\n",
      "Epoch 166/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2581 - accuracy: 0.9194 - val_loss: 0.5155 - val_accuracy: 0.8637\n",
      "Epoch 167/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2565 - accuracy: 0.9200 - val_loss: 0.5178 - val_accuracy: 0.8639\n",
      "Epoch 168/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2565 - accuracy: 0.9200 - val_loss: 0.5164 - val_accuracy: 0.8638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2564 - accuracy: 0.9201 - val_loss: 0.5165 - val_accuracy: 0.8642\n",
      "Epoch 170/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2549 - accuracy: 0.9206 - val_loss: 0.5187 - val_accuracy: 0.8638\n",
      "Epoch 171/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2554 - accuracy: 0.9204 - val_loss: 0.5188 - val_accuracy: 0.8639\n",
      "Epoch 172/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2547 - accuracy: 0.9206 - val_loss: 0.5209 - val_accuracy: 0.8636\n",
      "Epoch 173/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2560 - accuracy: 0.9200 - val_loss: 0.5185 - val_accuracy: 0.8642\n",
      "Epoch 174/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2542 - accuracy: 0.9208 - val_loss: 0.5220 - val_accuracy: 0.8632\n",
      "Epoch 175/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2555 - accuracy: 0.9202 - val_loss: 0.5208 - val_accuracy: 0.8636\n",
      "Epoch 176/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2547 - accuracy: 0.9205 - val_loss: 0.5203 - val_accuracy: 0.8638\n",
      "Epoch 177/250\n",
      "211/211 [==============================] - 3946s 19s/step - loss: 0.2541 - accuracy: 0.9208 - val_loss: 0.5224 - val_accuracy: 0.8632\n",
      "Epoch 178/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2535 - accuracy: 0.9210 - val_loss: 0.5209 - val_accuracy: 0.8638\n",
      "Epoch 179/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2538 - accuracy: 0.9209 - val_loss: 0.5241 - val_accuracy: 0.8631\n",
      "Epoch 180/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2560 - accuracy: 0.9200 - val_loss: 0.5248 - val_accuracy: 0.8631\n",
      "Epoch 181/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2529 - accuracy: 0.9211 - val_loss: 0.5247 - val_accuracy: 0.8632\n",
      "Epoch 182/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2529 - accuracy: 0.9211 - val_loss: 0.5244 - val_accuracy: 0.8633\n",
      "Epoch 183/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2526 - accuracy: 0.9212 - val_loss: 0.5263 - val_accuracy: 0.8632\n",
      "Epoch 184/250\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.2536 - accuracy: 0.9208 - val_loss: 0.5266 - val_accuracy: 0.8632\n",
      "Epoch 185/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2529 - accuracy: 0.9211 - val_loss: 0.5263 - val_accuracy: 0.8632\n",
      "Epoch 186/250\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.2514 - accuracy: 0.9216 - val_loss: 0.5271 - val_accuracy: 0.8629\n",
      "Epoch 187/250\n",
      "211/211 [==============================] - 15s 72ms/step - loss: 0.2546 - accuracy: 0.9205 - val_loss: 0.5278 - val_accuracy: 0.8628\n",
      "Epoch 188/250\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.2520 - accuracy: 0.9213 - val_loss: 0.5292 - val_accuracy: 0.8628\n",
      "Epoch 189/250\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.2508 - accuracy: 0.9218 - val_loss: 0.5288 - val_accuracy: 0.8631\n",
      "Epoch 190/250\n",
      "211/211 [==============================] - 15s 72ms/step - loss: 0.2520 - accuracy: 0.9213 - val_loss: 0.5288 - val_accuracy: 0.8630\n",
      "Epoch 191/250\n",
      "211/211 [==============================] - 16s 74ms/step - loss: 0.2503 - accuracy: 0.9219 - val_loss: 0.5307 - val_accuracy: 0.8626\n",
      "Epoch 192/250\n",
      "211/211 [==============================] - 16s 77ms/step - loss: 0.2512 - accuracy: 0.9216 - val_loss: 0.5299 - val_accuracy: 0.8632\n",
      "Epoch 193/250\n",
      "211/211 [==============================] - 16s 75ms/step - loss: 0.2511 - accuracy: 0.9216 - val_loss: 0.5295 - val_accuracy: 0.8637\n",
      "Epoch 194/250\n",
      "211/211 [==============================] - 16s 75ms/step - loss: 0.2535 - accuracy: 0.9207 - val_loss: 0.5324 - val_accuracy: 0.8625\n",
      "Epoch 195/250\n",
      "211/211 [==============================] - 16s 75ms/step - loss: 0.2721 - accuracy: 0.9150 - val_loss: 0.5251 - val_accuracy: 0.8637\n",
      "Epoch 196/250\n",
      "211/211 [==============================] - 17s 80ms/step - loss: 0.2548 - accuracy: 0.9203 - val_loss: 0.5257 - val_accuracy: 0.8635\n",
      "Epoch 197/250\n",
      "211/211 [==============================] - 16s 76ms/step - loss: 0.2506 - accuracy: 0.9217 - val_loss: 0.5306 - val_accuracy: 0.8628\n",
      "Epoch 198/250\n",
      "211/211 [==============================] - 15s 71ms/step - loss: 0.2721 - accuracy: 0.9146 - val_loss: 0.5250 - val_accuracy: 0.8635\n",
      "Epoch 199/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2502 - accuracy: 0.9219 - val_loss: 0.5286 - val_accuracy: 0.8630\n",
      "Epoch 200/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2525 - accuracy: 0.9210 - val_loss: 0.5281 - val_accuracy: 0.8632\n",
      "Epoch 201/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2623 - accuracy: 0.9178 - val_loss: 0.5265 - val_accuracy: 0.8635\n",
      "Epoch 202/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2510 - accuracy: 0.9216 - val_loss: 0.5296 - val_accuracy: 0.8628\n",
      "Epoch 203/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2478 - accuracy: 0.9228 - val_loss: 0.5302 - val_accuracy: 0.8624\n",
      "Epoch 204/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2591 - accuracy: 0.9188 - val_loss: 0.5290 - val_accuracy: 0.8629\n",
      "Epoch 205/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2495 - accuracy: 0.9221 - val_loss: 0.5305 - val_accuracy: 0.8630\n",
      "Epoch 206/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2468 - accuracy: 0.9231 - val_loss: 0.5315 - val_accuracy: 0.8628\n",
      "Epoch 207/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2468 - accuracy: 0.9230 - val_loss: 0.5340 - val_accuracy: 0.8624\n",
      "Epoch 208/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2467 - accuracy: 0.9232 - val_loss: 0.5330 - val_accuracy: 0.8627\n",
      "Epoch 209/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2719 - accuracy: 0.9147 - val_loss: 0.5302 - val_accuracy: 0.8626\n",
      "Epoch 210/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2507 - accuracy: 0.9217 - val_loss: 0.5341 - val_accuracy: 0.8621\n",
      "Epoch 211/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2605 - accuracy: 0.9186 - val_loss: 0.5282 - val_accuracy: 0.8625\n",
      "Epoch 212/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2577 - accuracy: 0.9190 - val_loss: 0.5299 - val_accuracy: 0.8628\n",
      "Epoch 213/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2500 - accuracy: 0.9218 - val_loss: 0.5311 - val_accuracy: 0.8627\n",
      "Epoch 214/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2464 - accuracy: 0.9231 - val_loss: 0.5355 - val_accuracy: 0.8618\n",
      "Epoch 215/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2455 - accuracy: 0.9235 - val_loss: 0.5354 - val_accuracy: 0.8625\n",
      "Epoch 216/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2452 - accuracy: 0.9235 - val_loss: 0.5398 - val_accuracy: 0.8617\n",
      "Epoch 217/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2472 - accuracy: 0.9227 - val_loss: 0.5368 - val_accuracy: 0.8621\n",
      "Epoch 218/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2496 - accuracy: 0.9219 - val_loss: 0.5346 - val_accuracy: 0.8629\n",
      "Epoch 219/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2468 - accuracy: 0.9229 - val_loss: 0.5367 - val_accuracy: 0.8625\n",
      "Epoch 220/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2482 - accuracy: 0.9224 - val_loss: 0.5387 - val_accuracy: 0.8623\n",
      "Epoch 221/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2461 - accuracy: 0.9231 - val_loss: 0.5375 - val_accuracy: 0.8623\n",
      "Epoch 222/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2483 - accuracy: 0.9223 - val_loss: 0.5374 - val_accuracy: 0.8626\n",
      "Epoch 223/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2543 - accuracy: 0.9204 - val_loss: 0.5340 - val_accuracy: 0.8622\n",
      "Epoch 224/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2681 - accuracy: 0.9159 - val_loss: 0.5315 - val_accuracy: 0.8625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2561 - accuracy: 0.9196 - val_loss: 0.5335 - val_accuracy: 0.8626\n",
      "Epoch 226/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2482 - accuracy: 0.9222 - val_loss: 0.5352 - val_accuracy: 0.8626\n",
      "Epoch 227/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2475 - accuracy: 0.9226 - val_loss: 0.5361 - val_accuracy: 0.8620\n",
      "Epoch 228/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2479 - accuracy: 0.9224 - val_loss: 0.5384 - val_accuracy: 0.8620\n",
      "Epoch 229/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2442 - accuracy: 0.9238 - val_loss: 0.5378 - val_accuracy: 0.8620\n",
      "Epoch 230/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2431 - accuracy: 0.9242 - val_loss: 0.5386 - val_accuracy: 0.8622\n",
      "Epoch 231/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2470 - accuracy: 0.9226 - val_loss: 0.5403 - val_accuracy: 0.8623\n",
      "Epoch 232/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2515 - accuracy: 0.9210 - val_loss: 0.5396 - val_accuracy: 0.8621\n",
      "Epoch 233/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2473 - accuracy: 0.9226 - val_loss: 0.5410 - val_accuracy: 0.8618\n",
      "Epoch 234/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2447 - accuracy: 0.9235 - val_loss: 0.5410 - val_accuracy: 0.8619\n",
      "Epoch 235/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2447 - accuracy: 0.9235 - val_loss: 0.5416 - val_accuracy: 0.8622\n",
      "Epoch 236/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2473 - accuracy: 0.9225 - val_loss: 0.5422 - val_accuracy: 0.8620\n",
      "Epoch 237/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2441 - accuracy: 0.9237 - val_loss: 0.5439 - val_accuracy: 0.8620\n",
      "Epoch 238/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2515 - accuracy: 0.9210 - val_loss: 0.5417 - val_accuracy: 0.8619\n",
      "Epoch 239/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2442 - accuracy: 0.9236 - val_loss: 0.5438 - val_accuracy: 0.8621\n",
      "Epoch 240/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2482 - accuracy: 0.9224 - val_loss: 0.5431 - val_accuracy: 0.8611\n",
      "Epoch 241/250\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.2515 - accuracy: 0.9210 - val_loss: 0.5416 - val_accuracy: 0.8619\n",
      "Epoch 242/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2464 - accuracy: 0.9230 - val_loss: 0.5406 - val_accuracy: 0.8621\n",
      "Epoch 243/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2462 - accuracy: 0.9228 - val_loss: 0.5419 - val_accuracy: 0.8619\n",
      "Epoch 244/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2449 - accuracy: 0.9235 - val_loss: 0.5421 - val_accuracy: 0.8622\n",
      "Epoch 245/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2450 - accuracy: 0.9233 - val_loss: 0.5441 - val_accuracy: 0.8620\n",
      "Epoch 246/250\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.2414 - accuracy: 0.9246 - val_loss: 0.5451 - val_accuracy: 0.8618\n",
      "Epoch 247/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2488 - accuracy: 0.9220 - val_loss: 0.5459 - val_accuracy: 0.8619\n",
      "Epoch 248/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2506 - accuracy: 0.9214 - val_loss: 0.5449 - val_accuracy: 0.8621\n",
      "Epoch 249/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2433 - accuracy: 0.9239 - val_loss: 0.5467 - val_accuracy: 0.8614\n",
      "Epoch 250/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.2456 - accuracy: 0.9230 - val_loss: 0.5457 - val_accuracy: 0.8621\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb09931",
   "metadata": {},
   "source": [
    "<h1>Guardar el modelo</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c59c1",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Diccionarios</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d954601",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/s2q/input_token_index.txt\", \"w\") as f:\n",
    "    json.dump(input_token_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e77635fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/s2q/target_token_index.txt\", \"w\") as f:\n",
    "    json.dump(target_token_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13f756f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/s2q/history.txt\", \"w\") as f:\n",
    "    json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bb787f",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">NumPy arrays</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0191bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/s2q/encoder_input_data.npy\", \"wb\") as f:\n",
    "    np.save(f, encoder_input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445fbf86",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Valores puntuales</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e93b5e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_decoder_tokens: 109\n",
      "max_decoder_seq_length: 252\n"
     ]
    }
   ],
   "source": [
    "print(\"num_decoder_tokens: {}\".format(num_decoder_tokens))\n",
    "print(\"max_decoder_seq_length: {}\".format(max_decoder_seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5be3bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/s2q/otros.txt\", \"w\") as f:\n",
    "    f.write(\"num_decoder_tokens: {}\".format(num_decoder_tokens))\n",
    "    f.write(\"\\nmax_decoder_seq_length: {}\".format(max_decoder_seq_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f12bbad",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Modelo</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f79defd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Modelos/s2q/spanish_to_quechua\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Modelos/s2q/spanish_to_quechua\\assets\n"
     ]
    }
   ],
   "source": [
    "# s2q = Spanish to Quechua\n",
    "model.save(\"./Modelos/s2q/spanish_to_quechua\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a0b29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./Modelos/s2q/spanish_to_quechua_file.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
