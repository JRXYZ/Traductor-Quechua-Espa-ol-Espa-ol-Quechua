{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2c67e2e",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gold; background-color:black; padding:20px\">TRADUCTOR QUECHUA - ESPAÑOL / ESPAÑOL - QUECHUA</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e263aaa4",
   "metadata": {},
   "source": [
    "<h1>Importar librerias a utilizar</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e9ecb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea182627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd6966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809fdacb",
   "metadata": {},
   "source": [
    "<h1>Definir funciones auxiliares</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b727190",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Imprime barra de progreso</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b62cc105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimir_barra_progreso_v2(progreso, total):\n",
    "    # https://www.youtube.com/watch?v=x1eaT88vJUA\n",
    "    \n",
    "    p = int(100 * (progreso + 1)/total)\n",
    "\n",
    "    # Alt+291: █\n",
    "    barra = '█'*p + '-'*(100-p) \n",
    "\n",
    "    print(\"\\r|{}| {}%\".format(barra, p), end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702e8751",
   "metadata": {},
   "source": [
    "<h1>Importar datos</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a89f42",
   "metadata": {},
   "source": [
    "<p>Los archivos contienen palabras/oraciones paralelas\n",
    "<br>\n",
    "La primera columna está en español y la segunda en quechua</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f2c4f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>español</th>\n",
       "      <th>quechua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [español, quechua]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un dataframe vació que almacenará las traducciones (translations)\n",
    "df_trans = pd.DataFrame(columns=[\"español\",\"quechua\"])\n",
    "df_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1513c829",
   "metadata": {},
   "source": [
    "<p>Se utilizó un tab (\"\\t\") como separador de columnas para evitar confusiones con las comas propias de las oraciones</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19401cc0",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Importa DataFrames</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb377b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_paths = [\"./Datos/palabras/\",\n",
    "             \"./Datos/grupos/\",\n",
    "             \"./Datos/libros/\"]\n",
    "\n",
    "for sub_path in sub_paths:\n",
    "    arr_category = os.listdir(sub_path)\n",
    "\n",
    "    for item in arr_category:\n",
    "        if item[-4:] == \".csv\":\n",
    "            file = \"{}{}\".format(sub_path,item)\n",
    "            df_temp = pd.read_csv(file, encoding=\"utf-8\", sep=\"\\t\")\n",
    "            \n",
    "            df_trans = pd.concat([df_trans, df_temp]\n",
    "                                 , ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78f8351c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>español</th>\n",
       "      <th>quechua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ácido</td>\n",
       "      <td>ácido nisqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agradable</td>\n",
       "      <td>munasqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agrícola</td>\n",
       "      <td>chakra llamk’aymanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>algún</td>\n",
       "      <td>wakin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amable</td>\n",
       "      <td>kuyakuq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17576</th>\n",
       "      <td>que aumenten sus fatigas tu tesoro;</td>\n",
       "      <td>qhapaq kayniyki llank’ayninkuta yapachun;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17577</th>\n",
       "      <td>y cambia horas de espuma por divinas.</td>\n",
       "      <td>hinaspa horas de espuma cambiay divinopaq.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17578</th>\n",
       "      <td>Sé rica adentro, en vez de serlo afuera.</td>\n",
       "      <td>Hawamanta qhapaq kaymantaqa, ukhupi qhapaq kay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17579</th>\n",
       "      <td>Devora tú a la Muerte y no la nutras,</td>\n",
       "      <td>Wañuytaqa mikhunkichis, manataq mikhuchinkich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17580</th>\n",
       "      <td>pues si ella muere, no podrás morir.</td>\n",
       "      <td>Bueno, wañuptinqa manam wañuwaqchu.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17581 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        español  \\\n",
       "0                                         ácido   \n",
       "1                                     agradable   \n",
       "2                                      agrícola   \n",
       "3                                         algún   \n",
       "4                                        amable   \n",
       "...                                         ...   \n",
       "17576       que aumenten sus fatigas tu tesoro;   \n",
       "17577     y cambia horas de espuma por divinas.   \n",
       "17578  Sé rica adentro, en vez de serlo afuera.   \n",
       "17579     Devora tú a la Muerte y no la nutras,   \n",
       "17580      pues si ella muere, no podrás morir.   \n",
       "\n",
       "                                                 quechua  \n",
       "0                                            ácido nisqa  \n",
       "1                                                munasqa  \n",
       "2                                   chakra llamk’aymanta  \n",
       "3                                                  wakin  \n",
       "4                                                kuyakuq  \n",
       "...                                                  ...  \n",
       "17576          qhapaq kayniyki llank’ayninkuta yapachun;  \n",
       "17577         hinaspa horas de espuma cambiay divinopaq.  \n",
       "17578    Hawamanta qhapaq kaymantaqa, ukhupi qhapaq kay.  \n",
       "17579   Wañuytaqa mikhunkichis, manataq mikhuchinkich...  \n",
       "17580                Bueno, wañuptinqa manam wañuwaqchu.  \n",
       "\n",
       "[17581 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb246c4",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Eliminar frases muy largas</h3>\n",
    "<p>Antes de agregar esta línea, se generaba el siguiente error al separar espacio en memoria para los arreglos de numpy</p>\n",
    "<p>Unable to allocate 152. GiB for an array with shape (18435, 18240, 121) and data type float32</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a073a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, registro in df_trans.iterrows():\n",
    "    txt_es = registro[0]\n",
    "    txt_qu = registro[1]\n",
    "    \n",
    "    if (len(txt_es) > 250) or (len(txt_qu) > 250):\n",
    "        #print(\"registro eliminado\")\n",
    "        df_trans = df_trans.drop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e80d3994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>español</th>\n",
       "      <th>quechua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ácido</td>\n",
       "      <td>ácido nisqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agradable</td>\n",
       "      <td>munasqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agrícola</td>\n",
       "      <td>chakra llamk’aymanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>algún</td>\n",
       "      <td>wakin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amable</td>\n",
       "      <td>kuyakuq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17576</th>\n",
       "      <td>que aumenten sus fatigas tu tesoro;</td>\n",
       "      <td>qhapaq kayniyki llank’ayninkuta yapachun;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17577</th>\n",
       "      <td>y cambia horas de espuma por divinas.</td>\n",
       "      <td>hinaspa horas de espuma cambiay divinopaq.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17578</th>\n",
       "      <td>Sé rica adentro, en vez de serlo afuera.</td>\n",
       "      <td>Hawamanta qhapaq kaymantaqa, ukhupi qhapaq kay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17579</th>\n",
       "      <td>Devora tú a la Muerte y no la nutras,</td>\n",
       "      <td>Wañuytaqa mikhunkichis, manataq mikhuchinkich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17580</th>\n",
       "      <td>pues si ella muere, no podrás morir.</td>\n",
       "      <td>Bueno, wañuptinqa manam wañuwaqchu.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16878 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        español  \\\n",
       "0                                         ácido   \n",
       "1                                     agradable   \n",
       "2                                      agrícola   \n",
       "3                                         algún   \n",
       "4                                        amable   \n",
       "...                                         ...   \n",
       "17576       que aumenten sus fatigas tu tesoro;   \n",
       "17577     y cambia horas de espuma por divinas.   \n",
       "17578  Sé rica adentro, en vez de serlo afuera.   \n",
       "17579     Devora tú a la Muerte y no la nutras,   \n",
       "17580      pues si ella muere, no podrás morir.   \n",
       "\n",
       "                                                 quechua  \n",
       "0                                            ácido nisqa  \n",
       "1                                                munasqa  \n",
       "2                                   chakra llamk’aymanta  \n",
       "3                                                  wakin  \n",
       "4                                                kuyakuq  \n",
       "...                                                  ...  \n",
       "17576          qhapaq kayniyki llank’ayninkuta yapachun;  \n",
       "17577         hinaspa horas de espuma cambiay divinopaq.  \n",
       "17578    Hawamanta qhapaq kaymantaqa, ukhupi qhapaq kay.  \n",
       "17579   Wañuytaqa mikhunkichis, manataq mikhuchinkich...  \n",
       "17580                Bueno, wañuptinqa manam wañuwaqchu.  \n",
       "\n",
       "[16878 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a2759f",
   "metadata": {},
   "source": [
    "<h1>Configuración</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cb7950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # tamño de los lotes para entrenamiento\n",
    "epochs = 250 # Número de epochs\n",
    "latent_dim = 256 # dimensión del espacio latente para el encoder\n",
    "num_samples = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc2402",
   "metadata": {},
   "source": [
    "<h1>Preparar los datos</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaf7020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectoriza los datos\n",
    "i=0\n",
    "targe_text= ''\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a34ade38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t I: ácido nisqa \t T: \n",
      "1 \t I: munasqa \t T: \n",
      "2 \t I: chakra llamk’aymanta \t T: \n",
      "3 \t I: wakin \t T: \n",
      "4 \t I: kuyakuq \t T: \n",
      "5 \t I: qatqi \t T: \n",
      "6 \t I: iskaynin \t T: \n",
      "7 \t I: kinray \t T: \n",
      "8 \t I: chayta \t T: \n",
      "9 \t I: wakkuna \t T: \n"
     ]
    }
   ],
   "source": [
    "for index, registro in df_trans.iterrows():    \n",
    "    # Notar que los índices están en orden invertido\n",
    "    input_text = registro[1]\n",
    "    target_text = registro[0]\n",
    "    \n",
    "    \n",
    "    if (index<10):\n",
    "        print(\"{} \\t I: {} \\t T: {}\"\n",
    "              .format(index, input_text, targe_text))        \n",
    "\n",
    "    \n",
    "    # Usaremos \"tab\" como el  caracter de inicio (start sequence)\n",
    "    # para los targets, y \"\\n\" como el caracter de fin de secuencia \"end sequence\"\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    # sube las líneas a  las listas\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "  \n",
    "    # completa los conjuntos de caracteres si es necesario\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "666ef763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convierte los dos conjuntos de caracteres\n",
    "# en dos listas ordenadas\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))  \n",
    "# calcule el número de tokens (caracteres) en ambos lados\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "# calcula la máxima longitud de las secuencias en cada lado\n",
    "max_encoder_seq_length = max([len(text) for text in input_texts])\n",
    "max_decoder_seq_length = max([len(text) for text in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f44f962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 16878\n",
      "Number of unique input tokens: 108\n",
      "Number of unique output tokens: 118\n",
      "Max sequence length for inputs: 250\n",
      "Max sequence length for outputs: 252\n",
      "preparando datos...\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples:\", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
    "print(\"preparando datos...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebba2a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea diccionarios de tokens\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "# crea los tensores 1-hot para el encoder y el decoder\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\n",
    "\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62973e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "datos preparados\n"
     ]
    }
   ],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
    "\n",
    "print (\"\\n....\")\n",
    "print(\"datos preparados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e7a6b1",
   "metadata": {},
   "source": [
    "<h1>Construir el modelo</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b6616e",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Encoder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f2f0cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define una secuencia de entrada y la procesa\n",
    "encoder_inputs = Input(shape = (None, num_encoder_tokens))\n",
    "\n",
    "# capa recurrente del encoder\n",
    "encoder = LSTM(latent_dim, return_state = True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# Descartamos las salidas (encoder_outputs)\n",
    "# solamente se conserva las memoria de  corto (state_h) y \n",
    "# largo plazo(state_c)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85df2bee",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Decoder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4169602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos el decoder, usando 'encoder_states' como estado inicial\n",
    "decoder_inputs = Input(shape= (None, num_decoder_tokens))\n",
    "\n",
    "# capa recurrente del decoder\n",
    "# Configuramos nuestro decodificador para devolver secuencias de salida completas,\n",
    "# y también para devolver estados internos. No usamos los\n",
    "# estados retornados en el modelo de entrenamiento, pero los usaremos en inferencia.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _,_ = decoder_lstm(decoder_inputs,initial_state = encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9068842f",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Modelo Completo</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e58d44a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4505484d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, 108)]  0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None, 118)]  0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 256),        373760      ['input_1[0][0]']                \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 256),  384000      ['input_2[0][0]',                \n",
      "                                 (None, 256),                     'lstm[0][1]',                   \n",
      "                                 (None, 256)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 118)    30326       ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 788,086\n",
      "Trainable params: 788,086\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "plot_model(model, to_file='./Imagenes/q2s.png', \n",
    "           show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8078d390",
   "metadata": {},
   "source": [
    "<h1>Entrenar el modelo</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c3272db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84936b54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "211/211 [==============================] - 20s 76ms/step - loss: 1.2042 - accuracy: 0.7372 - val_loss: 0.9701 - val_accuracy: 0.7311\n",
      "Epoch 2/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.8705 - accuracy: 0.7600 - val_loss: 0.8251 - val_accuracy: 0.7637\n",
      "Epoch 3/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.7492 - accuracy: 0.7823 - val_loss: 0.7477 - val_accuracy: 0.7785\n",
      "Epoch 4/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.6983 - accuracy: 0.7942 - val_loss: 0.7151 - val_accuracy: 0.7854\n",
      "Epoch 5/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.6707 - accuracy: 0.8007 - val_loss: 0.6927 - val_accuracy: 0.7905\n",
      "Epoch 6/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.6515 - accuracy: 0.8054 - val_loss: 0.6775 - val_accuracy: 0.7933\n",
      "Epoch 7/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.6364 - accuracy: 0.8088 - val_loss: 0.6656 - val_accuracy: 0.7969\n",
      "Epoch 8/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.6237 - accuracy: 0.8116 - val_loss: 0.6517 - val_accuracy: 0.8015\n",
      "Epoch 9/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.6125 - accuracy: 0.8148 - val_loss: 0.6432 - val_accuracy: 0.8041\n",
      "Epoch 10/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.6024 - accuracy: 0.8178 - val_loss: 0.6334 - val_accuracy: 0.8070\n",
      "Epoch 11/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.5931 - accuracy: 0.8209 - val_loss: 0.6269 - val_accuracy: 0.8089\n",
      "Epoch 12/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.5840 - accuracy: 0.8238 - val_loss: 0.6188 - val_accuracy: 0.8115\n",
      "Epoch 13/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.5754 - accuracy: 0.8265 - val_loss: 0.6124 - val_accuracy: 0.8136\n",
      "Epoch 14/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.5672 - accuracy: 0.8291 - val_loss: 0.6048 - val_accuracy: 0.8159\n",
      "Epoch 15/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.5594 - accuracy: 0.8316 - val_loss: 0.5988 - val_accuracy: 0.8181\n",
      "Epoch 16/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.5519 - accuracy: 0.8339 - val_loss: 0.5931 - val_accuracy: 0.8195\n",
      "Epoch 17/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.5447 - accuracy: 0.8362 - val_loss: 0.5880 - val_accuracy: 0.8212\n",
      "Epoch 18/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.5377 - accuracy: 0.8382 - val_loss: 0.5825 - val_accuracy: 0.8230\n",
      "Epoch 19/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.5307 - accuracy: 0.8404 - val_loss: 0.5765 - val_accuracy: 0.8253\n",
      "Epoch 20/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.5241 - accuracy: 0.8421 - val_loss: 0.5705 - val_accuracy: 0.8262\n",
      "Epoch 21/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.5158 - accuracy: 0.8443 - val_loss: 0.5638 - val_accuracy: 0.8279\n",
      "Epoch 22/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.5081 - accuracy: 0.8463 - val_loss: 0.5587 - val_accuracy: 0.8300\n",
      "Epoch 23/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.5020 - accuracy: 0.8481 - val_loss: 0.5530 - val_accuracy: 0.8312\n",
      "Epoch 24/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.5123 - accuracy: 0.8458 - val_loss: 0.5724 - val_accuracy: 0.8272\n",
      "Epoch 25/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.5053 - accuracy: 0.8481 - val_loss: 0.5535 - val_accuracy: 0.8319\n",
      "Epoch 26/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.4961 - accuracy: 0.8506 - val_loss: 0.5511 - val_accuracy: 0.8332\n",
      "Epoch 27/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4913 - accuracy: 0.8518 - val_loss: 0.5476 - val_accuracy: 0.8339\n",
      "Epoch 28/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4861 - accuracy: 0.8532 - val_loss: 0.5412 - val_accuracy: 0.8358\n",
      "Epoch 29/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4782 - accuracy: 0.8550 - val_loss: 0.5362 - val_accuracy: 0.8367\n",
      "Epoch 30/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4739 - accuracy: 0.8562 - val_loss: 0.5350 - val_accuracy: 0.8369\n",
      "Epoch 31/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4701 - accuracy: 0.8574 - val_loss: 0.5303 - val_accuracy: 0.8385\n",
      "Epoch 32/250\n",
      "211/211 [==============================] - 15s 70ms/step - loss: 0.4663 - accuracy: 0.8585 - val_loss: 0.5272 - val_accuracy: 0.8395\n",
      "Epoch 33/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.4627 - accuracy: 0.8595 - val_loss: 0.5256 - val_accuracy: 0.8403\n",
      "Epoch 34/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.4593 - accuracy: 0.8605 - val_loss: 0.5235 - val_accuracy: 0.8407\n",
      "Epoch 35/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4557 - accuracy: 0.8616 - val_loss: 0.5207 - val_accuracy: 0.8414\n",
      "Epoch 36/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4526 - accuracy: 0.8624 - val_loss: 0.5179 - val_accuracy: 0.8422\n",
      "Epoch 37/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4492 - accuracy: 0.8635 - val_loss: 0.5162 - val_accuracy: 0.8424\n",
      "Epoch 38/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4459 - accuracy: 0.8643 - val_loss: 0.5138 - val_accuracy: 0.8435\n",
      "Epoch 39/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4427 - accuracy: 0.8652 - val_loss: 0.5119 - val_accuracy: 0.8438\n",
      "Epoch 40/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4401 - accuracy: 0.8660 - val_loss: 0.5103 - val_accuracy: 0.8445\n",
      "Epoch 41/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4369 - accuracy: 0.8669 - val_loss: 0.5085 - val_accuracy: 0.8447\n",
      "Epoch 42/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.4341 - accuracy: 0.8676 - val_loss: 0.5063 - val_accuracy: 0.8456\n",
      "Epoch 43/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4313 - accuracy: 0.8684 - val_loss: 0.5049 - val_accuracy: 0.8466\n",
      "Epoch 44/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4288 - accuracy: 0.8691 - val_loss: 0.5034 - val_accuracy: 0.8466\n",
      "Epoch 45/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4259 - accuracy: 0.8698 - val_loss: 0.5032 - val_accuracy: 0.8471\n",
      "Epoch 46/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4233 - accuracy: 0.8706 - val_loss: 0.5007 - val_accuracy: 0.8476\n",
      "Epoch 47/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4207 - accuracy: 0.8713 - val_loss: 0.5000 - val_accuracy: 0.8476\n",
      "Epoch 48/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4180 - accuracy: 0.8720 - val_loss: 0.4981 - val_accuracy: 0.8480\n",
      "Epoch 49/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4157 - accuracy: 0.8727 - val_loss: 0.5001 - val_accuracy: 0.8480\n",
      "Epoch 50/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4134 - accuracy: 0.8733 - val_loss: 0.4964 - val_accuracy: 0.8491\n",
      "Epoch 51/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4112 - accuracy: 0.8740 - val_loss: 0.4956 - val_accuracy: 0.8495\n",
      "Epoch 52/250\n",
      "211/211 [==============================] - 14s 66ms/step - loss: 0.4090 - accuracy: 0.8746 - val_loss: 0.4933 - val_accuracy: 0.8500\n",
      "Epoch 53/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.4066 - accuracy: 0.8753 - val_loss: 0.4936 - val_accuracy: 0.8499\n",
      "Epoch 54/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4049 - accuracy: 0.8757 - val_loss: 0.4920 - val_accuracy: 0.8505\n",
      "Epoch 55/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4025 - accuracy: 0.8765 - val_loss: 0.4924 - val_accuracy: 0.8507\n",
      "Epoch 56/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.4007 - accuracy: 0.8769 - val_loss: 0.4920 - val_accuracy: 0.8507\n",
      "Epoch 57/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3990 - accuracy: 0.8774 - val_loss: 0.4903 - val_accuracy: 0.8511\n",
      "Epoch 58/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3970 - accuracy: 0.8780 - val_loss: 0.4915 - val_accuracy: 0.8509\n",
      "Epoch 59/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3952 - accuracy: 0.8784 - val_loss: 0.4886 - val_accuracy: 0.8518\n",
      "Epoch 60/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3935 - accuracy: 0.8789 - val_loss: 0.4897 - val_accuracy: 0.8515\n",
      "Epoch 61/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3916 - accuracy: 0.8795 - val_loss: 0.4892 - val_accuracy: 0.8517\n",
      "Epoch 62/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3901 - accuracy: 0.8799 - val_loss: 0.4878 - val_accuracy: 0.8523\n",
      "Epoch 63/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3886 - accuracy: 0.8803 - val_loss: 0.4886 - val_accuracy: 0.8525\n",
      "Epoch 64/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3871 - accuracy: 0.8808 - val_loss: 0.4892 - val_accuracy: 0.8519\n",
      "Epoch 65/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3851 - accuracy: 0.8813 - val_loss: 0.4875 - val_accuracy: 0.8527\n",
      "Epoch 66/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3837 - accuracy: 0.8817 - val_loss: 0.4881 - val_accuracy: 0.8527\n",
      "Epoch 67/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3825 - accuracy: 0.8820 - val_loss: 0.4886 - val_accuracy: 0.8525\n",
      "Epoch 68/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3807 - accuracy: 0.8826 - val_loss: 0.4895 - val_accuracy: 0.8523\n",
      "Epoch 69/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3792 - accuracy: 0.8830 - val_loss: 0.4881 - val_accuracy: 0.8530\n",
      "Epoch 70/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3779 - accuracy: 0.8833 - val_loss: 0.4889 - val_accuracy: 0.8532\n",
      "Epoch 71/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3766 - accuracy: 0.8837 - val_loss: 0.4889 - val_accuracy: 0.8528\n",
      "Epoch 72/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3752 - accuracy: 0.8841 - val_loss: 0.4904 - val_accuracy: 0.8524\n",
      "Epoch 73/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3740 - accuracy: 0.8844 - val_loss: 0.4891 - val_accuracy: 0.8526\n",
      "Epoch 74/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3727 - accuracy: 0.8847 - val_loss: 0.4901 - val_accuracy: 0.8528\n",
      "Epoch 75/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3713 - accuracy: 0.8853 - val_loss: 0.4888 - val_accuracy: 0.8531\n",
      "Epoch 76/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3702 - accuracy: 0.8855 - val_loss: 0.4893 - val_accuracy: 0.8534\n",
      "Epoch 77/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3685 - accuracy: 0.8860 - val_loss: 0.4901 - val_accuracy: 0.8532\n",
      "Epoch 78/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3675 - accuracy: 0.8861 - val_loss: 0.4883 - val_accuracy: 0.8537\n",
      "Epoch 79/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3660 - accuracy: 0.8866 - val_loss: 0.4899 - val_accuracy: 0.8534\n",
      "Epoch 80/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3648 - accuracy: 0.8869 - val_loss: 0.4897 - val_accuracy: 0.8532\n",
      "Epoch 81/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3636 - accuracy: 0.8873 - val_loss: 0.4895 - val_accuracy: 0.8536\n",
      "Epoch 82/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3624 - accuracy: 0.8877 - val_loss: 0.4891 - val_accuracy: 0.8535\n",
      "Epoch 83/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3616 - accuracy: 0.8878 - val_loss: 0.4909 - val_accuracy: 0.8535\n",
      "Epoch 84/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3601 - accuracy: 0.8883 - val_loss: 0.4901 - val_accuracy: 0.8540\n",
      "Epoch 85/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3590 - accuracy: 0.8887 - val_loss: 0.4924 - val_accuracy: 0.8529\n",
      "Epoch 86/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3578 - accuracy: 0.8889 - val_loss: 0.4925 - val_accuracy: 0.8533\n",
      "Epoch 87/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3571 - accuracy: 0.8893 - val_loss: 0.4927 - val_accuracy: 0.8531\n",
      "Epoch 88/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3556 - accuracy: 0.8896 - val_loss: 0.4938 - val_accuracy: 0.8529\n",
      "Epoch 89/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3545 - accuracy: 0.8901 - val_loss: 0.4947 - val_accuracy: 0.8525\n",
      "Epoch 90/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3536 - accuracy: 0.8903 - val_loss: 0.4941 - val_accuracy: 0.8532\n",
      "Epoch 91/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3524 - accuracy: 0.8906 - val_loss: 0.4937 - val_accuracy: 0.8534\n",
      "Epoch 92/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3512 - accuracy: 0.8910 - val_loss: 0.4956 - val_accuracy: 0.8534\n",
      "Epoch 93/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3503 - accuracy: 0.8913 - val_loss: 0.4959 - val_accuracy: 0.8531\n",
      "Epoch 94/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3494 - accuracy: 0.8915 - val_loss: 0.4966 - val_accuracy: 0.8528\n",
      "Epoch 95/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3488 - accuracy: 0.8917 - val_loss: 0.4965 - val_accuracy: 0.8535\n",
      "Epoch 96/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3473 - accuracy: 0.8922 - val_loss: 0.4982 - val_accuracy: 0.8524\n",
      "Epoch 97/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3465 - accuracy: 0.8923 - val_loss: 0.4992 - val_accuracy: 0.8525\n",
      "Epoch 98/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3454 - accuracy: 0.8926 - val_loss: 0.4995 - val_accuracy: 0.8524\n",
      "Epoch 99/250\n",
      "211/211 [==============================] - 15s 69ms/step - loss: 0.3446 - accuracy: 0.8928 - val_loss: 0.5018 - val_accuracy: 0.8522\n",
      "Epoch 100/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3436 - accuracy: 0.8931 - val_loss: 0.5015 - val_accuracy: 0.8522\n",
      "Epoch 101/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3425 - accuracy: 0.8935 - val_loss: 0.5010 - val_accuracy: 0.8526\n",
      "Epoch 102/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3417 - accuracy: 0.8937 - val_loss: 0.5019 - val_accuracy: 0.8524\n",
      "Epoch 103/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3408 - accuracy: 0.8941 - val_loss: 0.5035 - val_accuracy: 0.8524\n",
      "Epoch 104/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3398 - accuracy: 0.8943 - val_loss: 0.5019 - val_accuracy: 0.8527\n",
      "Epoch 105/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3391 - accuracy: 0.8945 - val_loss: 0.5041 - val_accuracy: 0.8527\n",
      "Epoch 106/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3381 - accuracy: 0.8948 - val_loss: 0.5057 - val_accuracy: 0.8525\n",
      "Epoch 107/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3374 - accuracy: 0.8950 - val_loss: 0.5062 - val_accuracy: 0.8524\n",
      "Epoch 108/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3365 - accuracy: 0.8952 - val_loss: 0.5058 - val_accuracy: 0.8520\n",
      "Epoch 109/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3356 - accuracy: 0.8955 - val_loss: 0.5071 - val_accuracy: 0.8524\n",
      "Epoch 110/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3345 - accuracy: 0.8958 - val_loss: 0.5073 - val_accuracy: 0.8522\n",
      "Epoch 111/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3336 - accuracy: 0.8961 - val_loss: 0.5102 - val_accuracy: 0.8514\n",
      "Epoch 112/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3334 - accuracy: 0.8961 - val_loss: 0.5107 - val_accuracy: 0.8516\n",
      "Epoch 113/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3324 - accuracy: 0.8964 - val_loss: 0.5109 - val_accuracy: 0.8519\n",
      "Epoch 114/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3313 - accuracy: 0.8967 - val_loss: 0.5140 - val_accuracy: 0.8509\n",
      "Epoch 115/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3304 - accuracy: 0.8971 - val_loss: 0.5137 - val_accuracy: 0.8508\n",
      "Epoch 116/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3301 - accuracy: 0.8971 - val_loss: 0.5141 - val_accuracy: 0.8514\n",
      "Epoch 117/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3289 - accuracy: 0.8975 - val_loss: 0.5174 - val_accuracy: 0.8506\n",
      "Epoch 118/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3280 - accuracy: 0.8979 - val_loss: 0.5153 - val_accuracy: 0.8509\n",
      "Epoch 119/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3275 - accuracy: 0.8980 - val_loss: 0.5169 - val_accuracy: 0.8507\n",
      "Epoch 120/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3263 - accuracy: 0.8983 - val_loss: 0.5177 - val_accuracy: 0.8510\n",
      "Epoch 121/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3259 - accuracy: 0.8984 - val_loss: 0.5209 - val_accuracy: 0.8507\n",
      "Epoch 122/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3250 - accuracy: 0.8987 - val_loss: 0.5206 - val_accuracy: 0.8508\n",
      "Epoch 123/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3242 - accuracy: 0.8989 - val_loss: 0.5211 - val_accuracy: 0.8503\n",
      "Epoch 124/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3235 - accuracy: 0.8991 - val_loss: 0.5225 - val_accuracy: 0.8505\n",
      "Epoch 125/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3228 - accuracy: 0.8992 - val_loss: 0.5247 - val_accuracy: 0.8495\n",
      "Epoch 126/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3219 - accuracy: 0.8996 - val_loss: 0.5235 - val_accuracy: 0.8500\n",
      "Epoch 127/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3215 - accuracy: 0.8997 - val_loss: 0.5249 - val_accuracy: 0.8501\n",
      "Epoch 128/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3207 - accuracy: 0.8999 - val_loss: 0.5272 - val_accuracy: 0.8500\n",
      "Epoch 129/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3201 - accuracy: 0.9001 - val_loss: 0.5271 - val_accuracy: 0.8497\n",
      "Epoch 130/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3189 - accuracy: 0.9005 - val_loss: 0.5302 - val_accuracy: 0.8496\n",
      "Epoch 131/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3186 - accuracy: 0.9006 - val_loss: 0.5316 - val_accuracy: 0.8487\n",
      "Epoch 132/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3176 - accuracy: 0.9009 - val_loss: 0.5302 - val_accuracy: 0.8497\n",
      "Epoch 133/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3171 - accuracy: 0.9010 - val_loss: 0.5314 - val_accuracy: 0.8495\n",
      "Epoch 134/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3166 - accuracy: 0.9012 - val_loss: 0.5317 - val_accuracy: 0.8488\n",
      "Epoch 135/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3159 - accuracy: 0.9014 - val_loss: 0.5356 - val_accuracy: 0.8482\n",
      "Epoch 136/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3150 - accuracy: 0.9017 - val_loss: 0.5346 - val_accuracy: 0.8487\n",
      "Epoch 137/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3145 - accuracy: 0.9018 - val_loss: 0.5349 - val_accuracy: 0.8489\n",
      "Epoch 138/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3137 - accuracy: 0.9020 - val_loss: 0.5372 - val_accuracy: 0.8482\n",
      "Epoch 139/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3129 - accuracy: 0.9023 - val_loss: 0.5360 - val_accuracy: 0.8493\n",
      "Epoch 140/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3123 - accuracy: 0.9025 - val_loss: 0.5384 - val_accuracy: 0.8480\n",
      "Epoch 141/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3115 - accuracy: 0.9027 - val_loss: 0.5408 - val_accuracy: 0.8480\n",
      "Epoch 142/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3109 - accuracy: 0.9028 - val_loss: 0.5407 - val_accuracy: 0.8483\n",
      "Epoch 143/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3104 - accuracy: 0.9030 - val_loss: 0.5414 - val_accuracy: 0.8481\n",
      "Epoch 144/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3098 - accuracy: 0.9032 - val_loss: 0.5424 - val_accuracy: 0.8482\n",
      "Epoch 145/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3089 - accuracy: 0.9034 - val_loss: 0.5455 - val_accuracy: 0.8476\n",
      "Epoch 146/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3082 - accuracy: 0.9038 - val_loss: 0.5435 - val_accuracy: 0.8481\n",
      "Epoch 147/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3078 - accuracy: 0.9039 - val_loss: 0.5481 - val_accuracy: 0.8472\n",
      "Epoch 148/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3073 - accuracy: 0.9040 - val_loss: 0.5465 - val_accuracy: 0.8476\n",
      "Epoch 149/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3070 - accuracy: 0.9040 - val_loss: 0.5499 - val_accuracy: 0.8470\n",
      "Epoch 150/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3069 - accuracy: 0.9041 - val_loss: 0.5513 - val_accuracy: 0.8472\n",
      "Epoch 151/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3055 - accuracy: 0.9045 - val_loss: 0.5517 - val_accuracy: 0.8468\n",
      "Epoch 152/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3050 - accuracy: 0.9046 - val_loss: 0.5534 - val_accuracy: 0.8467\n",
      "Epoch 153/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.3047 - accuracy: 0.9047 - val_loss: 0.5533 - val_accuracy: 0.8467\n",
      "Epoch 154/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3047 - accuracy: 0.9047 - val_loss: 0.5555 - val_accuracy: 0.8463\n",
      "Epoch 155/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3034 - accuracy: 0.9052 - val_loss: 0.5536 - val_accuracy: 0.8472\n",
      "Epoch 156/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3027 - accuracy: 0.9054 - val_loss: 0.5570 - val_accuracy: 0.8464\n",
      "Epoch 157/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3020 - accuracy: 0.9056 - val_loss: 0.5581 - val_accuracy: 0.8462\n",
      "Epoch 158/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3015 - accuracy: 0.9057 - val_loss: 0.5581 - val_accuracy: 0.8463\n",
      "Epoch 159/250\n",
      "211/211 [==============================] - 14s 66ms/step - loss: 0.3008 - accuracy: 0.9060 - val_loss: 0.5602 - val_accuracy: 0.8463\n",
      "Epoch 160/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.3006 - accuracy: 0.9060 - val_loss: 0.5614 - val_accuracy: 0.8459\n",
      "Epoch 161/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3001 - accuracy: 0.9061 - val_loss: 0.5616 - val_accuracy: 0.8464\n",
      "Epoch 162/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3000 - accuracy: 0.9063 - val_loss: 0.5650 - val_accuracy: 0.8450\n",
      "Epoch 163/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.3023 - accuracy: 0.9052 - val_loss: 0.5609 - val_accuracy: 0.8459\n",
      "Epoch 164/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2988 - accuracy: 0.9066 - val_loss: 0.5640 - val_accuracy: 0.8458\n",
      "Epoch 165/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2979 - accuracy: 0.9069 - val_loss: 0.5641 - val_accuracy: 0.8461\n",
      "Epoch 166/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2973 - accuracy: 0.9070 - val_loss: 0.5665 - val_accuracy: 0.8454\n",
      "Epoch 167/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2967 - accuracy: 0.9073 - val_loss: 0.5681 - val_accuracy: 0.8456\n",
      "Epoch 168/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2962 - accuracy: 0.9074 - val_loss: 0.5687 - val_accuracy: 0.8453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2960 - accuracy: 0.9073 - val_loss: 0.5700 - val_accuracy: 0.8456\n",
      "Epoch 170/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2958 - accuracy: 0.9075 - val_loss: 0.5699 - val_accuracy: 0.8455\n",
      "Epoch 171/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2953 - accuracy: 0.9077 - val_loss: 0.5722 - val_accuracy: 0.8447\n",
      "Epoch 172/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2947 - accuracy: 0.9078 - val_loss: 0.5733 - val_accuracy: 0.8450\n",
      "Epoch 173/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2940 - accuracy: 0.9080 - val_loss: 0.5744 - val_accuracy: 0.8450\n",
      "Epoch 174/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2934 - accuracy: 0.9082 - val_loss: 0.5741 - val_accuracy: 0.8451\n",
      "Epoch 175/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2932 - accuracy: 0.9084 - val_loss: 0.5769 - val_accuracy: 0.8443\n",
      "Epoch 176/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2927 - accuracy: 0.9085 - val_loss: 0.5753 - val_accuracy: 0.8449\n",
      "Epoch 177/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2925 - accuracy: 0.9085 - val_loss: 0.5749 - val_accuracy: 0.8452\n",
      "Epoch 178/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2919 - accuracy: 0.9087 - val_loss: 0.5781 - val_accuracy: 0.8444\n",
      "Epoch 179/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2915 - accuracy: 0.9088 - val_loss: 0.5779 - val_accuracy: 0.8444\n",
      "Epoch 180/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2911 - accuracy: 0.9089 - val_loss: 0.5786 - val_accuracy: 0.8445\n",
      "Epoch 181/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2906 - accuracy: 0.9091 - val_loss: 0.5814 - val_accuracy: 0.8443\n",
      "Epoch 182/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2905 - accuracy: 0.9090 - val_loss: 0.5835 - val_accuracy: 0.8436\n",
      "Epoch 183/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2907 - accuracy: 0.9090 - val_loss: 0.5811 - val_accuracy: 0.8445\n",
      "Epoch 184/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2899 - accuracy: 0.9093 - val_loss: 0.5824 - val_accuracy: 0.8443\n",
      "Epoch 185/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2890 - accuracy: 0.9096 - val_loss: 0.5843 - val_accuracy: 0.8439\n",
      "Epoch 186/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2883 - accuracy: 0.9098 - val_loss: 0.5857 - val_accuracy: 0.8435\n",
      "Epoch 187/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2877 - accuracy: 0.9100 - val_loss: 0.5852 - val_accuracy: 0.8439\n",
      "Epoch 188/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2878 - accuracy: 0.9100 - val_loss: 0.5861 - val_accuracy: 0.8442\n",
      "Epoch 189/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2875 - accuracy: 0.9100 - val_loss: 0.5891 - val_accuracy: 0.8432\n",
      "Epoch 190/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2872 - accuracy: 0.9102 - val_loss: 0.5899 - val_accuracy: 0.8433\n",
      "Epoch 191/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2868 - accuracy: 0.9104 - val_loss: 0.5896 - val_accuracy: 0.8436\n",
      "Epoch 192/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2863 - accuracy: 0.9104 - val_loss: 0.5904 - val_accuracy: 0.8432\n",
      "Epoch 193/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2865 - accuracy: 0.9103 - val_loss: 0.5910 - val_accuracy: 0.8437\n",
      "Epoch 194/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2855 - accuracy: 0.9106 - val_loss: 0.5938 - val_accuracy: 0.8431\n",
      "Epoch 195/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2865 - accuracy: 0.9102 - val_loss: 0.5929 - val_accuracy: 0.8430\n",
      "Epoch 196/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2856 - accuracy: 0.9105 - val_loss: 0.5915 - val_accuracy: 0.8436\n",
      "Epoch 197/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2850 - accuracy: 0.9107 - val_loss: 0.5946 - val_accuracy: 0.8434\n",
      "Epoch 198/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2837 - accuracy: 0.9112 - val_loss: 0.5939 - val_accuracy: 0.8435\n",
      "Epoch 199/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2833 - accuracy: 0.9113 - val_loss: 0.5978 - val_accuracy: 0.8429\n",
      "Epoch 200/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2842 - accuracy: 0.9110 - val_loss: 0.5967 - val_accuracy: 0.8429\n",
      "Epoch 201/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2835 - accuracy: 0.9113 - val_loss: 0.5977 - val_accuracy: 0.8426\n",
      "Epoch 202/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2831 - accuracy: 0.9114 - val_loss: 0.5978 - val_accuracy: 0.8431\n",
      "Epoch 203/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2840 - accuracy: 0.9110 - val_loss: 0.5990 - val_accuracy: 0.8429\n",
      "Epoch 204/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2825 - accuracy: 0.9116 - val_loss: 0.6012 - val_accuracy: 0.8425\n",
      "Epoch 205/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2818 - accuracy: 0.9118 - val_loss: 0.6009 - val_accuracy: 0.8423\n",
      "Epoch 206/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2819 - accuracy: 0.9117 - val_loss: 0.6029 - val_accuracy: 0.8422\n",
      "Epoch 207/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2813 - accuracy: 0.9119 - val_loss: 0.6021 - val_accuracy: 0.8427\n",
      "Epoch 208/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2814 - accuracy: 0.9118 - val_loss: 0.6033 - val_accuracy: 0.8425\n",
      "Epoch 209/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2810 - accuracy: 0.9120 - val_loss: 0.6029 - val_accuracy: 0.8422\n",
      "Epoch 210/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2805 - accuracy: 0.9122 - val_loss: 0.6073 - val_accuracy: 0.8419\n",
      "Epoch 211/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2803 - accuracy: 0.9122 - val_loss: 0.6061 - val_accuracy: 0.8419\n",
      "Epoch 212/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2803 - accuracy: 0.9123 - val_loss: 0.6056 - val_accuracy: 0.8423\n",
      "Epoch 213/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2798 - accuracy: 0.9123 - val_loss: 0.6095 - val_accuracy: 0.8418\n",
      "Epoch 214/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2792 - accuracy: 0.9127 - val_loss: 0.6048 - val_accuracy: 0.8422\n",
      "Epoch 215/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2787 - accuracy: 0.9129 - val_loss: 0.6062 - val_accuracy: 0.8424\n",
      "Epoch 216/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2782 - accuracy: 0.9130 - val_loss: 0.6091 - val_accuracy: 0.8416\n",
      "Epoch 217/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2784 - accuracy: 0.9129 - val_loss: 0.6090 - val_accuracy: 0.8419\n",
      "Epoch 218/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2796 - accuracy: 0.9124 - val_loss: 0.6103 - val_accuracy: 0.8418\n",
      "Epoch 219/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2798 - accuracy: 0.9124 - val_loss: 0.6096 - val_accuracy: 0.8421\n",
      "Epoch 220/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2779 - accuracy: 0.9130 - val_loss: 0.6112 - val_accuracy: 0.8419\n",
      "Epoch 221/250\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 0.2773 - accuracy: 0.9132 - val_loss: 0.6110 - val_accuracy: 0.8418\n",
      "Epoch 222/250\n",
      "211/211 [==============================] - 14s 66ms/step - loss: 0.2772 - accuracy: 0.9133 - val_loss: 0.6125 - val_accuracy: 0.8415\n",
      "Epoch 223/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2773 - accuracy: 0.9131 - val_loss: 0.6143 - val_accuracy: 0.8415\n",
      "Epoch 224/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2768 - accuracy: 0.9134 - val_loss: 0.6161 - val_accuracy: 0.8415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2766 - accuracy: 0.9134 - val_loss: 0.6121 - val_accuracy: 0.8420\n",
      "Epoch 226/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2761 - accuracy: 0.9136 - val_loss: 0.6137 - val_accuracy: 0.8419\n",
      "Epoch 227/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2762 - accuracy: 0.9135 - val_loss: 0.6165 - val_accuracy: 0.8419\n",
      "Epoch 228/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2761 - accuracy: 0.9134 - val_loss: 0.6164 - val_accuracy: 0.8416\n",
      "Epoch 229/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2755 - accuracy: 0.9135 - val_loss: 0.6142 - val_accuracy: 0.8417\n",
      "Epoch 230/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2748 - accuracy: 0.9140 - val_loss: 0.6189 - val_accuracy: 0.8411\n",
      "Epoch 231/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2754 - accuracy: 0.9136 - val_loss: 0.6155 - val_accuracy: 0.8417\n",
      "Epoch 232/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2756 - accuracy: 0.9135 - val_loss: 0.6170 - val_accuracy: 0.8418\n",
      "Epoch 233/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2753 - accuracy: 0.9138 - val_loss: 0.6176 - val_accuracy: 0.8419\n",
      "Epoch 234/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2749 - accuracy: 0.9137 - val_loss: 0.6178 - val_accuracy: 0.8413\n",
      "Epoch 235/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2738 - accuracy: 0.9143 - val_loss: 0.6202 - val_accuracy: 0.8413\n",
      "Epoch 236/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2745 - accuracy: 0.9140 - val_loss: 0.6219 - val_accuracy: 0.8412\n",
      "Epoch 237/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2733 - accuracy: 0.9144 - val_loss: 0.6207 - val_accuracy: 0.8410\n",
      "Epoch 238/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2734 - accuracy: 0.9143 - val_loss: 0.6193 - val_accuracy: 0.8412\n",
      "Epoch 239/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2742 - accuracy: 0.9141 - val_loss: 0.6226 - val_accuracy: 0.8414\n",
      "Epoch 240/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2759 - accuracy: 0.9135 - val_loss: 0.6243 - val_accuracy: 0.8409\n",
      "Epoch 241/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2771 - accuracy: 0.9130 - val_loss: 0.6217 - val_accuracy: 0.8415\n",
      "Epoch 242/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2733 - accuracy: 0.9144 - val_loss: 0.6201 - val_accuracy: 0.8416\n",
      "Epoch 243/250\n",
      "211/211 [==============================] - 14s 69ms/step - loss: 0.2722 - accuracy: 0.9147 - val_loss: 0.6223 - val_accuracy: 0.8412\n",
      "Epoch 244/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2721 - accuracy: 0.9148 - val_loss: 0.6251 - val_accuracy: 0.8409\n",
      "Epoch 245/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2722 - accuracy: 0.9146 - val_loss: 0.6228 - val_accuracy: 0.8415\n",
      "Epoch 246/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2724 - accuracy: 0.9147 - val_loss: 0.6242 - val_accuracy: 0.8413\n",
      "Epoch 247/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2720 - accuracy: 0.9148 - val_loss: 0.6264 - val_accuracy: 0.8410\n",
      "Epoch 248/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2708 - accuracy: 0.9152 - val_loss: 0.6277 - val_accuracy: 0.8404\n",
      "Epoch 249/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2709 - accuracy: 0.9151 - val_loss: 0.6266 - val_accuracy: 0.8412\n",
      "Epoch 250/250\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.2713 - accuracy: 0.9149 - val_loss: 0.6283 - val_accuracy: 0.8408\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb09931",
   "metadata": {},
   "source": [
    "<h1>Guardar el modelo</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c59c1",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Diccionarios</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d954601",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/q2s/input_token_index.txt\", \"w\") as f:\n",
    "    json.dump(input_token_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e77635fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/q2s/target_token_index.txt\", \"w\") as f:\n",
    "    json.dump(target_token_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13f756f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/q2s/history.txt\", \"w\") as f:\n",
    "    json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bb787f",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">NumPy arrays</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0191bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/q2s/encoder_input_data.npy\", \"wb\") as f:\n",
    "    np.save(f, encoder_input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445fbf86",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Valores puntuales</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e93b5e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_decoder_tokens: 118\n",
      "max_decoder_seq_length: 252\n"
     ]
    }
   ],
   "source": [
    "print(\"num_decoder_tokens: {}\".format(num_decoder_tokens))\n",
    "print(\"max_decoder_seq_length: {}\".format(max_decoder_seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5be3bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/q2s/otros.txt\", \"w\") as f:\n",
    "    f.write(\"num_decoder_tokens: {}\".format(num_decoder_tokens))\n",
    "    f.write(\"\\nmax_decoder_seq_length: {}\".format(max_decoder_seq_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f12bbad",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Modelo</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f79defd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Modelos/q2s/quechua_to_spanish\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Modelos/q2s/quechua_to_spanish\\assets\n"
     ]
    }
   ],
   "source": [
    "# s2q = Spanish to Quechua\n",
    "model.save(\"./Modelos/q2s/quechua_to_spanish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a0b29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./Modelos/q2s/quechua_to_spanish_file.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
