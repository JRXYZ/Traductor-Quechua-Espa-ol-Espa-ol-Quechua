{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2c67e2e",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gold; background-color:black; padding:20px; font-size:40px; text-align:center\">TRADUCTOR ESPAÑOL - QUECHUA</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e263aaa4",
   "metadata": {},
   "source": [
    "<h1>Importar librerias a utilizar</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e9ecb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea182627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd6966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809fdacb",
   "metadata": {},
   "source": [
    "<h1>Definir funciones auxiliares</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b727190",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Imprime barra de progreso</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b62cc105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimir_barra_progreso_v2(progreso, total):\n",
    "    # https://www.youtube.com/watch?v=x1eaT88vJUA\n",
    "    \n",
    "    p = int(100 * (progreso + 1)/total)\n",
    "\n",
    "    # Alt+291: █\n",
    "    barra = '█'*p + '-'*(100-p) \n",
    "\n",
    "    print(\"\\r|{}| {}%\".format(barra, p), end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702e8751",
   "metadata": {},
   "source": [
    "<h1>Importar datos</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a89f42",
   "metadata": {},
   "source": [
    "<p>Los archivos contienen palabras/oraciones paralelas\n",
    "<br>\n",
    "La primera columna está en español y la segunda en quechua</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f2c4f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>español</th>\n",
       "      <th>quechua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [español, quechua]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un dataframe vació que almacenará las traducciones (translations)\n",
    "df_trans = pd.DataFrame(columns=[\"español\",\"quechua\"])\n",
    "df_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1513c829",
   "metadata": {},
   "source": [
    "<p>Se utilizó un tab (\"\\t\") como separador de columnas para evitar confusiones con las comas propias de las oraciones</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19401cc0",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Importa DataFrames</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a47ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_opciones = [[40,[40,50,60]],\n",
    "               [50,[50,63,75]],\n",
    "               [60,[60,75,90]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df4e5c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitudes disponibles en español\n",
      "0) - 40\n",
      "1) - 50\n",
      "2) - 60\n",
      "Ingrese la longitud máxima en español: 0\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Longitudes disponibles en quechua\n",
      "0) - 40\n",
      "1) - 50\n",
      "2) - 60\n",
      "Ingrese la longitud máxima en quechua: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Longitudes disponibles en español\")\n",
    "for i in range(3):\n",
    "    print(\"{}) - {}\".format(i, arr_opciones[i][0]) )\n",
    "MAX_ES_index = int(input(\"Ingrese la longitud máxima en español: \"))\n",
    "\n",
    "print(\"\\n\" + \"-\"*100)\n",
    "print(\"Longitudes disponibles en quechua\")\n",
    "for j in range(3):\n",
    "    print(\"{}) - {}\".format(j, arr_opciones[MAX_ES_index][1][j]))\n",
    "MAX_QU_index = int(input(\"Ingrese la longitud máxima en quechua: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb377b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obteniendo datos de ./Datos/consolidado_40_40/\n"
     ]
    }
   ],
   "source": [
    "MAX_ES = arr_opciones[MAX_ES_index][0]\n",
    "MAX_QU = arr_opciones[MAX_ES_index][1][MAX_QU_index]\n",
    "\n",
    "folder_consolidado = \"./Datos/consolidado_{}_{}/\".format(MAX_ES, MAX_QU)\n",
    "print(\"obteniendo datos de {}\".format(folder_consolidado))\n",
    "\n",
    "sub_paths = [folder_consolidado,\n",
    "             #\"./Datos/palabras/\", \"./Datos/grupos/\",\n",
    "             #\"./Datos/libros/\", \"./Datos/oraciones/\"\n",
    "            ]\n",
    "\n",
    "for sub_path in sub_paths:\n",
    "    arr_category = os.listdir(sub_path)\n",
    "\n",
    "    for item in arr_category:\n",
    "        if item[-4:] == \".csv\":\n",
    "            file = \"{}{}\".format(sub_path,item)\n",
    "            df_temp = pd.read_csv(file, encoding=\"utf-8\", sep=\"\\t\")\n",
    "            \n",
    "            df_trans = pd.concat([df_trans, df_temp]\n",
    "                                 , ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f8351c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>español</th>\n",
       "      <th>quechua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ve.</td>\n",
       "      <td>Riy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vete.</td>\n",
       "      <td>Lluqsiy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vaya.</td>\n",
       "      <td>Waw.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Váyase.</td>\n",
       "      <td>Lluqsiy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hola.</td>\n",
       "      <td>Allinllachu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Me escapé.</td>\n",
       "      <td>Ayqirqanim.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Huía.</td>\n",
       "      <td>ayqirqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Me escapaba.</td>\n",
       "      <td>Ayqichkarqanim.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Yo lo sé.</td>\n",
       "      <td>Chaytaqa yachani.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Sé.</td>\n",
       "      <td>PAY.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         español             quechua\n",
       "0            Ve.                Riy.\n",
       "1          Vete.            Lluqsiy.\n",
       "2          Vaya.                Waw.\n",
       "3        Váyase.            Lluqsiy.\n",
       "4          Hola.        Allinllachu.\n",
       "..           ...                 ...\n",
       "95    Me escapé.         Ayqirqanim.\n",
       "96         Huía.             ayqirqa\n",
       "97  Me escapaba.     Ayqichkarqanim.\n",
       "98     Yo lo sé.   Chaytaqa yachani.\n",
       "99           Sé.                PAY.\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c727e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>español</th>\n",
       "      <th>quechua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90213</th>\n",
       "      <td>Como un padre decrépito disfruta</td>\n",
       "      <td>Imaynan huk decrepit tayta kusikun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90214</th>\n",
       "      <td>al ver de su hijo las empresas jóvenes,</td>\n",
       "      <td>churinpa wayna empresankunata rikuspa,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90215</th>\n",
       "      <td>así yo, mutilado por la suene,</td>\n",
       "      <td>chaymi ñoqa, t’oqyaywan mutilado, .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90216</th>\n",
       "      <td>el poder o el ingenio, uno o todos,</td>\n",
       "      <td>atiy utaq ingenio, huk utaq llapan, .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90217</th>\n",
       "      <td>para colmarme a mí con su opulencia,</td>\n",
       "      <td>qhapaq kayninwan hunt'achiwananpaq,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90308</th>\n",
       "      <td>Pobre alma, centro de culpable limo</td>\n",
       "      <td>Wakcha alma, huchayuq limo centro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90309</th>\n",
       "      <td>a la que burla, indócil, quien la ciñe,</td>\n",
       "      <td>burlakuq, mana kamachikuq, chumpikuq, .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90310</th>\n",
       "      <td>ornando tu morada pasajera?</td>\n",
       "      <td>temporal tiyasqaykita sumaqchaspa?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90311</th>\n",
       "      <td>Vive, alma, a expensas de tu servidor;</td>\n",
       "      <td>Kawsay, alma, kamachiykiq qolqenwan;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90312</th>\n",
       "      <td>pues si ella muere, no podrás morir.</td>\n",
       "      <td>Bueno, wañuptinqa manam wañuwaqchu.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       español  \\\n",
       "90213         Como un padre decrépito disfruta   \n",
       "90214  al ver de su hijo las empresas jóvenes,   \n",
       "90215           así yo, mutilado por la suene,   \n",
       "90216      el poder o el ingenio, uno o todos,   \n",
       "90217     para colmarme a mí con su opulencia,   \n",
       "...                                        ...   \n",
       "90308      Pobre alma, centro de culpable limo   \n",
       "90309  a la que burla, indócil, quien la ciñe,   \n",
       "90310              ornando tu morada pasajera?   \n",
       "90311   Vive, alma, a expensas de tu servidor;   \n",
       "90312     pues si ella muere, no podrás morir.   \n",
       "\n",
       "                                        quechua  \n",
       "90213        Imaynan huk decrepit tayta kusikun  \n",
       "90214    churinpa wayna empresankunata rikuspa,  \n",
       "90215       chaymi ñoqa, t’oqyaywan mutilado, .  \n",
       "90216     atiy utaq ingenio, huk utaq llapan, .  \n",
       "90217       qhapaq kayninwan hunt'achiwananpaq,  \n",
       "...                                         ...  \n",
       "90308         Wakcha alma, huchayuq limo centro  \n",
       "90309   burlakuq, mana kamachikuq, chumpikuq, .  \n",
       "90310        temporal tiyasqaykita sumaqchaspa?  \n",
       "90311      Kawsay, alma, kamachiykiq qolqenwan;  \n",
       "90312       Bueno, wañuptinqa manam wañuwaqchu.  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans.tail(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb246c4",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Eliminar frases muy largas</h3>\n",
    "<p>Los tres arreglos de numpy deben entrar en los 8 GB de VRAM, y dejar espacio para el resto de variables</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9183a5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud inicial del arreglo 90313\n"
     ]
    }
   ],
   "source": [
    "print(\"Longitud inicial del arreglo {}\".format(len(df_trans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a073a8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rggistro 0 analizado\n",
      "Rggistro 5000 analizado\n",
      "Rggistro 10000 analizado\n",
      "Rggistro 15000 analizado\n",
      "Rggistro 20000 analizado\n",
      "Rggistro 25000 analizado\n",
      "Rggistro 30000 analizado\n",
      "Rggistro 35000 analizado\n",
      "Rggistro 40000 analizado\n",
      "Rggistro 45000 analizado\n",
      "Rggistro 50000 analizado\n",
      "Rggistro 55000 analizado\n",
      "Rggistro 60000 analizado\n",
      "Rggistro 65000 analizado\n",
      "Rggistro 70000 analizado\n",
      "Rggistro 75000 analizado\n",
      "Rggistro 80000 analizado\n",
      "Rggistro 85000 analizado\n",
      "Rggistro 90000 analizado\n"
     ]
    }
   ],
   "source": [
    "for index, registro in df_trans.iterrows():\n",
    "    txt_es = registro[0].strip()\n",
    "    txt_qu = registro[1].strip()\n",
    "    \n",
    "    if (len(txt_es) > MAX_ES) or (len(txt_qu) > MAX_QU):\n",
    "        #print(\"registro eliminado\")\n",
    "        df_trans = df_trans.drop(index)\n",
    "        \n",
    "    if index % 5000 == 0:\n",
    "        print(\"Rggistro {} analizado\".format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e80d3994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nueva longitud del arreglo 90313\n"
     ]
    }
   ],
   "source": [
    "print(\"Nueva longitud del arreglo {}\".format(len(df_trans)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a2759f",
   "metadata": {},
   "source": [
    "<h1>Configuración</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cb7950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # tamño de los lotes para entrenamiento\n",
    "epochs = 250 # Número de epochs\n",
    "latent_dim = 256 # dimensión del espacio latente para el encoder\n",
    "num_samples = len(df_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc2402",
   "metadata": {},
   "source": [
    "<h1>Preparar los datos</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaf7020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectoriza los datos\n",
    "i=0\n",
    "target_text= ''\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a34ade38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t I: |Ve.|  -----------------  T: |Riy.|\n",
      "1 \t I: |Vete.|  ---------------  T: |Lluqsiy.|\n",
      "2 \t I: |Vaya.|  ---------------  T: |Waw.|\n",
      "3 \t I: |Váyase.|  -------------  T: |Lluqsiy.|\n",
      "4 \t I: |Hola.|  ---------------  T: |Allinllachu.|\n",
      "5 \t I: |¡Corre!|  -------------  T: |¡Runa!|\n",
      "6 \t I: |¡Corran!|  ------------  T: |Paway!|\n",
      "7 \t I: |¡Huye!|  --------------  T: |¡Ascapa!|\n",
      "8 \t I: |¡Corra!|  -------------  T: |Paway!|\n",
      "9 \t I: |¡Corred!|  ------------  T: |Paway!|\n",
      "10 \t I: |Corra.|  --------------  T: |Paway.|\n",
      "11 \t I: |Corred.|  -------------  T: |Paway.|\n",
      "12 \t I: |¿Quién?|  -------------  T: |Pi?|\n",
      "13 \t I: |¡Órale!|  -------------  T: |Waw!|\n",
      "14 \t I: |¡Inclínate!|  ---------  T: |Kumuy!|\n",
      "15 \t I: |¡Fuego!|  -------------  T: |Nina!|\n",
      "16 \t I: |¡Incendio!|  ----------  T: |Nina!|\n",
      "17 \t I: |¡Disparad!|  ----------  T: |disparar!|\n",
      "18 \t I: |¡Ayuda!|  -------------  T: |Yanapay!|\n",
      "19 \t I: |¡Socorro! ¡Auxilio!|  -  T: |Yanapay! Yanapay!|\n",
      "20 \t I: |¡Auxilio!|  -----------  T: |Yanapay!|\n",
      "21 \t I: |Escóndete.|  ----------  T: |pakay.|\n",
      "22 \t I: |¡Salta!|  -------------  T: |paway!|\n",
      "23 \t I: |Salte.|  --------------  T: |paway.|\n",
      "24 \t I: |Salto.|  --------------  T: |Paway.|\n",
      "25 \t I: |Quédate.|  ------------  T: |Takyay.|\n",
      "26 \t I: |¡Parad!|  -------------  T: |Sayay!|\n",
      "27 \t I: |¡Para!|  --------------  T: |¡Por!|\n",
      "28 \t I: |¡Pare!|  --------------  T: |sayay!|\n",
      "29 \t I: |¡Espera!|  ------------  T: |Suyay!|\n",
      "30 \t I: |¡Esperen!|  -----------  T: |suyay!|\n",
      "31 \t I: |¡Espérate!|  ----------  T: |Suyay!|\n",
      "32 \t I: |Esperen.|  ------------  T: |suyay.|\n",
      "33 \t I: |Espera.|  -------------  T: |Suyay.|\n",
      "34 \t I: |Esperad.|  ------------  T: |Suyay.|\n",
      "35 \t I: |Empieza.|  ------------  T: |Qallariy.|\n",
      "36 \t I: |Hacedlo.|  ------------  T: |chayta ruway.|\n",
      "37 \t I: |Continúa.|  -----------  T: |Hinallayá puririy.|\n",
      "38 \t I: |Continúe.|  -----------  T: |qatiq.|\n",
      "39 \t I: |Hola.|  ---------------  T: |Allinllachu.|\n",
      "40 \t I: |Hola.|  ---------------  T: |Allinllachu.|\n",
      "41 \t I: |¡Date prisa!|  --------  T: |Utqay!|\n",
      "42 \t I: |¡Daos prisa!|  --------  T: |Utqay!|\n",
      "43 \t I: |Dese prisa.|  ---------  T: |Utqay.|\n",
      "44 \t I: |Me oculté.|  ----------  T: |Pakakurqanim.|\n",
      "45 \t I: |Me escondí.|  ---------  T: |Pakakurqanim.|\n",
      "46 \t I: |Me ocultaba.|  --------  T: |Pakakuchkarqanim.|\n",
      "47 \t I: |Me escondía.|  --------  T: |Pakakurqanim.|\n",
      "48 \t I: |Corrí.|  --------------  T: |Phawarqanim.|\n",
      "49 \t I: |Corría.|  -------------  T: |pawasqa.|\n",
      "50 \t I: |Lo intento.|  ---------  T: |Kallpanchakuni.|\n",
      "51 \t I: |¡He ganado!|  ---------  T: |¡Ganarqanim!|\n",
      "52 \t I: |¡He ganado yo!|  ------  T: |¡Ñoqaqa ganarqanin!|\n",
      "53 \t I: |¡Oh, no!|  ------------  T: |¡Ay mana!|\n",
      "54 \t I: |Tomátelo con soda.|  --  T: |Gaseosawan chayta hap’iy.|\n",
      "55 \t I: |Tranquila.|  ----------  T: |Llanpu sunqu.|\n",
      "56 \t I: |¡Fuego!|  -------------  T: |Nina!|\n",
      "57 \t I: |¡Disparad!|  ----------  T: |disparar!|\n",
      "58 \t I: |¡Disparen!|  ----------  T: |disparar!|\n",
      "59 \t I: |Dispara.|  ------------  T: |Disparar.|\n",
      "60 \t I: |¡Dispara!|  -----------  T: |Disparar!|\n",
      "61 \t I: |¡Dispará!|  -----------  T: |Disparar!|\n",
      "62 \t I: |¡Dispare!|  -----------  T: |disparar!|\n",
      "63 \t I: |Sonríe.|  -------------  T: |Asiy.|\n",
      "64 \t I: |¿Disculpa?|  ----------  T: |Llakikunim?|\n",
      "65 \t I: |¡Al ataque!|  ---------  T: |Wayka!|\n",
      "66 \t I: |¡Atacad!|  ------------  T: |wayka!|\n",
      "67 \t I: |¡Ataque!|  ------------  T: |Siqi!|\n",
      "68 \t I: |¡Ataquen!|  -----------  T: |wayka!|\n",
      "69 \t I: |¡Ataca!|  -------------  T: |Wayka!|\n",
      "70 \t I: |Cómprela.|  -----------  T: |rantiy.|\n",
      "71 \t I: |Cómpralo.|  -----------  T: |rantiy.|\n",
      "72 \t I: |Cómetelo.|  -----------  T: |Mikhuy.|\n",
      "73 \t I: |Coméoslo.|  -----------  T: |chayta mikhuy|\n",
      "74 \t I: |Cómaselo.|  -----------  T: |chayta mikhuy|\n",
      "75 \t I: |Cómanselo.|  ----------  T: |chayta mikhuy|\n",
      "76 \t I: |Levanta.|  ------------  T: |Wichay.|\n",
      "77 \t I: |Ve ahora mismo.|  -----  T: |Kunanpacha riy.|\n",
      "78 \t I: |Id ahora mismo.|  -----  T: |Kunanpacha riy.|\n",
      "79 \t I: |Vaya ahora mismo.|  ---  T: |Kunanpacha riy.|\n",
      "80 \t I: |Vayan ahora mismo.|  --  T: |Kunanpacha riy.|\n",
      "81 \t I: |Ve ya.|  --------------  T: |Riyña.|\n",
      "82 \t I: |Id ya.|  --------------  T: |kunan riy|\n",
      "83 \t I: |Vaya ya.|  ------------  T: |kunan riy|\n",
      "84 \t I: |Vayan ya.|  -----------  T: |kunan riy|\n",
      "85 \t I: |¡Lo tengo!|  ----------  T: |¡Ñoqaqa chayta chaskini!|\n",
      "86 \t I: |¿Lo pillas?|  ---------  T: |¿Chayta jap’inkichu?|\n",
      "87 \t I: |¿Entendiste?|  --------  T: |entienderqankichu?|\n",
      "88 \t I: |Él corrió.|  ----------  T: |Payqa phawarirqan.|\n",
      "89 \t I: |Corrió.|  -------------  T: |Pawasqa.|\n",
      "90 \t I: |Métete adentro.|  -----  T: |Ukhuman yaykuy.|\n",
      "91 \t I: |Abrázame.|  -----------  T: |Abrazaway.|\n",
      "92 \t I: |Me preocupo.|  --------  T: |Llakisqam kachkani.|\n",
      "93 \t I: |Me caí.|  -------------  T: |Urmarqanim.|\n",
      "94 \t I: |Huí.|  ----------------  T: |Ayqirqanim.|\n",
      "95 \t I: |Me escapé.|  ----------  T: |Ayqirqanim.|\n",
      "96 \t I: |Huía.|  ---------------  T: |ayqirqa|\n",
      "97 \t I: |Me escapaba.|  --------  T: |Ayqichkarqanim.|\n",
      "98 \t I: |Yo lo sé.|  -----------  T: |Chaytaqa yachani.|\n",
      "99 \t I: |Sé.|  -----------------  T: |PAY.|\n"
     ]
    }
   ],
   "source": [
    "for index, registro in df_trans.iterrows():    \n",
    "    \n",
    "    input_text = registro[0].strip()\n",
    "    target_text = registro[1].strip()\n",
    "    \n",
    "    \n",
    "    if (index<100):\n",
    "        pad_dashes = \" \" + \"-\"*(20-len(input_text)) + \" \"\n",
    "        print(\"{} \\t I: |{}| {} T: |{}|\"\n",
    "              .format(index, input_text, pad_dashes, target_text))        \n",
    "\n",
    "    \n",
    "    # Usaremos \"tab\" como el  caracter de inicio (start sequence)\n",
    "    # para los targets, y \"\\n\" como el caracter de fin de secuencia \"end sequence\"\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    # sube las líneas a  las listas\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "  \n",
    "    # completa los conjuntos de caracteres si es necesario\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "666ef763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte los dos conjuntos de caracteres\n",
    "# en dos listas ordenadas\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))  \n",
    "# calcule el número de tokens (caracteres) en ambos lados\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "# calcula la máxima longitud de las secuencias en cada lado\n",
    "max_encoder_seq_length = max([len(text) for text in input_texts])\n",
    "max_decoder_seq_length = max([len(text) for text in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f44f962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 90313\n",
      "Number of unique input tokens: 110\n",
      "Number of unique output tokens: 104\n",
      "Max sequence length for inputs: 40\n",
      "Max sequence length for outputs: 42\n",
      "preparando datos...\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples:\", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
    "print(\"preparando datos...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebba2a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea diccionarios de tokens\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "# crea los tensores 1-hot para el encoder y el decoder\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\n",
    "\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62973e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "datos preparados\n"
     ]
    }
   ],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    # Modificar los valores de la matriz del encoder\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    \n",
    "    \n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    \n",
    "    \n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
    "\n",
    "print (\"\\n....\")\n",
    "print(\"datos preparados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e7a6b1",
   "metadata": {},
   "source": [
    "<h1>Construir el modelo</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b6616e",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Encoder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f2f0cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define una secuencia de entrada y la procesa\n",
    "encoder_inputs = Input(shape = (None, num_encoder_tokens))\n",
    "\n",
    "# capa recurrente del encoder\n",
    "encoder = LSTM(latent_dim, return_state = True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# Descartamos las salidas (encoder_outputs)\n",
    "# solamente se conserva las memoria de  corto (state_h) y \n",
    "# largo plazo(state_c)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85df2bee",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Decoder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4169602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos el decoder, usando 'encoder_states' como estado inicial\n",
    "decoder_inputs = Input(shape= (None, num_decoder_tokens))\n",
    "\n",
    "# capa recurrente del decoder\n",
    "# Configuramos nuestro decodificador para devolver secuencias de salida completas,\n",
    "# y también para devolver estados internos. No usamos los\n",
    "# estados retornados en el modelo de entrenamiento, pero los usaremos en inferencia.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _,_ = decoder_lstm(decoder_inputs,initial_state = encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9068842f",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Modelo Completo</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e58d44a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4505484d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, 110)]  0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None, 104)]  0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 256),        375808      ['input_1[0][0]']                \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 256),  369664      ['input_2[0][0]',                \n",
      "                                 (None, 256),                     'lstm[0][1]',                   \n",
      "                                 (None, 256)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 104)    26728       ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 772,200\n",
      "Trainable params: 772,200\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "plot_model(model, to_file='../Imagenes/s2s.png', \n",
    "           show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8078d390",
   "metadata": {},
   "source": [
    "<h1>Entrenar el modelo</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c3272db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84936b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "565/565 [==============================] - 19s 27ms/step - loss: 1.5433 - accuracy: 0.5709 - val_loss: 1.4891 - val_accuracy: 0.5748\n",
      "Epoch 2/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 1.0688 - accuracy: 0.6778 - val_loss: 1.3151 - val_accuracy: 0.6207\n",
      "Epoch 3/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.9299 - accuracy: 0.7178 - val_loss: 1.2146 - val_accuracy: 0.6515\n",
      "Epoch 4/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.8445 - accuracy: 0.7444 - val_loss: 1.1378 - val_accuracy: 0.6747\n",
      "Epoch 5/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.7839 - accuracy: 0.7631 - val_loss: 1.0901 - val_accuracy: 0.6913\n",
      "Epoch 6/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.7329 - accuracy: 0.7786 - val_loss: 1.0404 - val_accuracy: 0.7049\n",
      "Epoch 7/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.6897 - accuracy: 0.7917 - val_loss: 1.0044 - val_accuracy: 0.7157\n",
      "Epoch 8/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.6550 - accuracy: 0.8018 - val_loss: 0.9769 - val_accuracy: 0.7242\n",
      "Epoch 9/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.6245 - accuracy: 0.8108 - val_loss: 0.9485 - val_accuracy: 0.7319\n",
      "Epoch 10/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.5987 - accuracy: 0.8183 - val_loss: 0.9317 - val_accuracy: 0.7381\n",
      "Epoch 11/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.5764 - accuracy: 0.8248 - val_loss: 0.9141 - val_accuracy: 0.7435\n",
      "Epoch 12/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.5568 - accuracy: 0.8305 - val_loss: 0.8987 - val_accuracy: 0.7483\n",
      "Epoch 13/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.5387 - accuracy: 0.8360 - val_loss: 0.8858 - val_accuracy: 0.7525\n",
      "Epoch 14/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.5226 - accuracy: 0.8407 - val_loss: 0.8775 - val_accuracy: 0.7553\n",
      "Epoch 15/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.5072 - accuracy: 0.8453 - val_loss: 0.8638 - val_accuracy: 0.7589\n",
      "Epoch 16/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.4935 - accuracy: 0.8495 - val_loss: 0.8616 - val_accuracy: 0.7614\n",
      "Epoch 17/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.4802 - accuracy: 0.8536 - val_loss: 0.8500 - val_accuracy: 0.7647\n",
      "Epoch 18/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.4682 - accuracy: 0.8572 - val_loss: 0.8476 - val_accuracy: 0.7662\n",
      "Epoch 19/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.4572 - accuracy: 0.8605 - val_loss: 0.8438 - val_accuracy: 0.7676\n",
      "Epoch 20/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.4467 - accuracy: 0.8635 - val_loss: 0.8387 - val_accuracy: 0.7698\n",
      "Epoch 21/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.4371 - accuracy: 0.8665 - val_loss: 0.8421 - val_accuracy: 0.7698\n",
      "Epoch 22/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.4279 - accuracy: 0.8693 - val_loss: 0.8359 - val_accuracy: 0.7716\n",
      "Epoch 23/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.4193 - accuracy: 0.8718 - val_loss: 0.8352 - val_accuracy: 0.7735\n",
      "Epoch 24/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.4111 - accuracy: 0.8743 - val_loss: 0.8351 - val_accuracy: 0.7744\n",
      "Epoch 25/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.4031 - accuracy: 0.8766 - val_loss: 0.8327 - val_accuracy: 0.7749\n",
      "Epoch 26/250\n",
      "565/565 [==============================] - 13s 24ms/step - loss: 0.3960 - accuracy: 0.8789 - val_loss: 0.8341 - val_accuracy: 0.7758\n",
      "Epoch 27/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.3886 - accuracy: 0.8812 - val_loss: 0.8397 - val_accuracy: 0.7758\n",
      "Epoch 28/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3819 - accuracy: 0.8833 - val_loss: 0.8376 - val_accuracy: 0.7771\n",
      "Epoch 29/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3755 - accuracy: 0.8852 - val_loss: 0.8421 - val_accuracy: 0.7767\n",
      "Epoch 30/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.3694 - accuracy: 0.8871 - val_loss: 0.8448 - val_accuracy: 0.7768\n",
      "Epoch 31/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3633 - accuracy: 0.8888 - val_loss: 0.8482 - val_accuracy: 0.7771\n",
      "Epoch 32/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3578 - accuracy: 0.8904 - val_loss: 0.8489 - val_accuracy: 0.7771\n",
      "Epoch 33/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3520 - accuracy: 0.8923 - val_loss: 0.8557 - val_accuracy: 0.7773\n",
      "Epoch 34/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3469 - accuracy: 0.8939 - val_loss: 0.8620 - val_accuracy: 0.7777\n",
      "Epoch 35/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3417 - accuracy: 0.8955 - val_loss: 0.8646 - val_accuracy: 0.7768\n",
      "Epoch 36/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3368 - accuracy: 0.8970 - val_loss: 0.8725 - val_accuracy: 0.7763\n",
      "Epoch 37/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3318 - accuracy: 0.8985 - val_loss: 0.8717 - val_accuracy: 0.7766\n",
      "Epoch 38/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3276 - accuracy: 0.8996 - val_loss: 0.8760 - val_accuracy: 0.7770\n",
      "Epoch 39/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3232 - accuracy: 0.9012 - val_loss: 0.8780 - val_accuracy: 0.7772\n",
      "Epoch 40/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3185 - accuracy: 0.9026 - val_loss: 0.8913 - val_accuracy: 0.7766\n",
      "Epoch 41/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3146 - accuracy: 0.9038 - val_loss: 0.8936 - val_accuracy: 0.7764\n",
      "Epoch 42/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3102 - accuracy: 0.9051 - val_loss: 0.8969 - val_accuracy: 0.7766\n",
      "Epoch 43/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3065 - accuracy: 0.9062 - val_loss: 0.9026 - val_accuracy: 0.7765\n",
      "Epoch 44/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.3025 - accuracy: 0.9075 - val_loss: 0.9105 - val_accuracy: 0.7752\n",
      "Epoch 45/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2992 - accuracy: 0.9085 - val_loss: 0.9148 - val_accuracy: 0.7760\n",
      "Epoch 46/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2955 - accuracy: 0.9095 - val_loss: 0.9234 - val_accuracy: 0.7746\n",
      "Epoch 47/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.2922 - accuracy: 0.9107 - val_loss: 0.9275 - val_accuracy: 0.7759\n",
      "Epoch 48/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2887 - accuracy: 0.9116 - val_loss: 0.9363 - val_accuracy: 0.7746\n",
      "Epoch 49/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2855 - accuracy: 0.9127 - val_loss: 0.9370 - val_accuracy: 0.7752\n",
      "Epoch 50/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2822 - accuracy: 0.9136 - val_loss: 0.9496 - val_accuracy: 0.7734\n",
      "Epoch 51/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2793 - accuracy: 0.9145 - val_loss: 0.9562 - val_accuracy: 0.7726\n",
      "Epoch 52/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.2761 - accuracy: 0.9155 - val_loss: 0.9619 - val_accuracy: 0.7730\n",
      "Epoch 53/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2735 - accuracy: 0.9163 - val_loss: 0.9614 - val_accuracy: 0.7735\n",
      "Epoch 54/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2706 - accuracy: 0.9171 - val_loss: 0.9732 - val_accuracy: 0.7723\n",
      "Epoch 55/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2682 - accuracy: 0.9179 - val_loss: 0.9799 - val_accuracy: 0.7721\n",
      "Epoch 56/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2651 - accuracy: 0.9187 - val_loss: 0.9819 - val_accuracy: 0.7719\n",
      "Epoch 57/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2628 - accuracy: 0.9194 - val_loss: 0.9919 - val_accuracy: 0.7714\n",
      "Epoch 58/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2600 - accuracy: 0.9202 - val_loss: 0.9986 - val_accuracy: 0.7716\n",
      "Epoch 59/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2576 - accuracy: 0.9209 - val_loss: 1.0000 - val_accuracy: 0.7707\n",
      "Epoch 60/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2553 - accuracy: 0.9219 - val_loss: 1.0065 - val_accuracy: 0.7705\n",
      "Epoch 61/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2531 - accuracy: 0.9223 - val_loss: 1.0152 - val_accuracy: 0.7699\n",
      "Epoch 62/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2509 - accuracy: 0.9231 - val_loss: 1.0173 - val_accuracy: 0.7701\n",
      "Epoch 63/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2485 - accuracy: 0.9237 - val_loss: 1.0314 - val_accuracy: 0.7694\n",
      "Epoch 64/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2467 - accuracy: 0.9242 - val_loss: 1.0309 - val_accuracy: 0.7701\n",
      "Epoch 65/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2445 - accuracy: 0.9248 - val_loss: 1.0338 - val_accuracy: 0.7694\n",
      "Epoch 66/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2424 - accuracy: 0.9257 - val_loss: 1.0449 - val_accuracy: 0.7686\n",
      "Epoch 67/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2406 - accuracy: 0.9261 - val_loss: 1.0551 - val_accuracy: 0.7680\n",
      "Epoch 68/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2386 - accuracy: 0.9266 - val_loss: 1.0532 - val_accuracy: 0.7681\n",
      "Epoch 69/250\n",
      "565/565 [==============================] - 13s 24ms/step - loss: 0.2362 - accuracy: 0.9273 - val_loss: 1.0640 - val_accuracy: 0.7683\n",
      "Epoch 70/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.2347 - accuracy: 0.9278 - val_loss: 1.0704 - val_accuracy: 0.7680\n",
      "Epoch 71/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2333 - accuracy: 0.9282 - val_loss: 1.0775 - val_accuracy: 0.7672\n",
      "Epoch 72/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2309 - accuracy: 0.9289 - val_loss: 1.0822 - val_accuracy: 0.7679\n",
      "Epoch 73/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2301 - accuracy: 0.9291 - val_loss: 1.0851 - val_accuracy: 0.7682\n",
      "Epoch 74/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2279 - accuracy: 0.9299 - val_loss: 1.0874 - val_accuracy: 0.7676\n",
      "Epoch 75/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2261 - accuracy: 0.9303 - val_loss: 1.0974 - val_accuracy: 0.7674\n",
      "Epoch 76/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2248 - accuracy: 0.9308 - val_loss: 1.1037 - val_accuracy: 0.7666\n",
      "Epoch 77/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2237 - accuracy: 0.9310 - val_loss: 1.1063 - val_accuracy: 0.7672\n",
      "Epoch 78/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2217 - accuracy: 0.9317 - val_loss: 1.1118 - val_accuracy: 0.7669\n",
      "Epoch 79/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2203 - accuracy: 0.9320 - val_loss: 1.1233 - val_accuracy: 0.7657\n",
      "Epoch 80/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2188 - accuracy: 0.9324 - val_loss: 1.1225 - val_accuracy: 0.7658\n",
      "Epoch 81/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2174 - accuracy: 0.9330 - val_loss: 1.1377 - val_accuracy: 0.7645\n",
      "Epoch 82/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2157 - accuracy: 0.9333 - val_loss: 1.1330 - val_accuracy: 0.7660\n",
      "Epoch 83/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2147 - accuracy: 0.9339 - val_loss: 1.1378 - val_accuracy: 0.7658\n",
      "Epoch 84/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2143 - accuracy: 0.9337 - val_loss: 1.1422 - val_accuracy: 0.7651\n",
      "Epoch 85/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2123 - accuracy: 0.9343 - val_loss: 1.1480 - val_accuracy: 0.7648\n",
      "Epoch 86/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2109 - accuracy: 0.9348 - val_loss: 1.1560 - val_accuracy: 0.7639\n",
      "Epoch 87/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2097 - accuracy: 0.9351 - val_loss: 1.1686 - val_accuracy: 0.7639\n",
      "Epoch 88/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2089 - accuracy: 0.9353 - val_loss: 1.1677 - val_accuracy: 0.7648\n",
      "Epoch 89/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2079 - accuracy: 0.9357 - val_loss: 1.1694 - val_accuracy: 0.7646\n",
      "Epoch 90/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2063 - accuracy: 0.9360 - val_loss: 1.1767 - val_accuracy: 0.7645\n",
      "Epoch 91/250\n",
      "565/565 [==============================] - 15s 26ms/step - loss: 0.2053 - accuracy: 0.9364 - val_loss: 1.1825 - val_accuracy: 0.7635\n",
      "Epoch 92/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.2045 - accuracy: 0.9366 - val_loss: 1.1849 - val_accuracy: 0.7639\n",
      "Epoch 93/250\n",
      "565/565 [==============================] - 13s 24ms/step - loss: 0.2028 - accuracy: 0.9372 - val_loss: 1.1950 - val_accuracy: 0.7630\n",
      "Epoch 94/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2025 - accuracy: 0.9373 - val_loss: 1.1943 - val_accuracy: 0.7633\n",
      "Epoch 95/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2013 - accuracy: 0.9376 - val_loss: 1.2008 - val_accuracy: 0.7638\n",
      "Epoch 96/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.2001 - accuracy: 0.9379 - val_loss: 1.2046 - val_accuracy: 0.7633\n",
      "Epoch 97/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1994 - accuracy: 0.9382 - val_loss: 1.2125 - val_accuracy: 0.7623\n",
      "Epoch 98/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1988 - accuracy: 0.9381 - val_loss: 1.2162 - val_accuracy: 0.7625\n",
      "Epoch 99/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.1969 - accuracy: 0.9390 - val_loss: 1.2196 - val_accuracy: 0.7624\n",
      "Epoch 100/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1965 - accuracy: 0.9389 - val_loss: 1.2205 - val_accuracy: 0.7622\n",
      "Epoch 101/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1950 - accuracy: 0.9394 - val_loss: 1.2266 - val_accuracy: 0.7627\n",
      "Epoch 102/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1948 - accuracy: 0.9394 - val_loss: 1.2289 - val_accuracy: 0.7625\n",
      "Epoch 103/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1931 - accuracy: 0.9399 - val_loss: 1.2360 - val_accuracy: 0.7627\n",
      "Epoch 104/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1927 - accuracy: 0.9401 - val_loss: 1.2410 - val_accuracy: 0.7621\n",
      "Epoch 105/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1917 - accuracy: 0.9405 - val_loss: 1.2457 - val_accuracy: 0.7613\n",
      "Epoch 106/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1911 - accuracy: 0.9404 - val_loss: 1.2538 - val_accuracy: 0.7612\n",
      "Epoch 107/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1904 - accuracy: 0.9408 - val_loss: 1.2572 - val_accuracy: 0.7613\n",
      "Epoch 108/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1905 - accuracy: 0.9406 - val_loss: 1.2613 - val_accuracy: 0.7603\n",
      "Epoch 109/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1888 - accuracy: 0.9411 - val_loss: 1.2606 - val_accuracy: 0.7611\n",
      "Epoch 110/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1880 - accuracy: 0.9413 - val_loss: 1.2653 - val_accuracy: 0.7607\n",
      "Epoch 111/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1878 - accuracy: 0.9415 - val_loss: 1.2635 - val_accuracy: 0.7613\n",
      "Epoch 112/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1867 - accuracy: 0.9418 - val_loss: 1.2741 - val_accuracy: 0.7609\n",
      "Epoch 113/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1853 - accuracy: 0.9423 - val_loss: 1.2759 - val_accuracy: 0.7614\n",
      "Epoch 114/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1854 - accuracy: 0.9421 - val_loss: 1.2836 - val_accuracy: 0.7603\n",
      "Epoch 115/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1846 - accuracy: 0.9424 - val_loss: 1.2839 - val_accuracy: 0.7613\n",
      "Epoch 116/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.1843 - accuracy: 0.9423 - val_loss: 1.2848 - val_accuracy: 0.7602\n",
      "Epoch 117/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1834 - accuracy: 0.9426 - val_loss: 1.2914 - val_accuracy: 0.7599\n",
      "Epoch 118/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1818 - accuracy: 0.9434 - val_loss: 1.3039 - val_accuracy: 0.7601\n",
      "Epoch 119/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1818 - accuracy: 0.9432 - val_loss: 1.3060 - val_accuracy: 0.7597\n",
      "Epoch 120/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1808 - accuracy: 0.9436 - val_loss: 1.3032 - val_accuracy: 0.7605\n",
      "Epoch 121/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1804 - accuracy: 0.9435 - val_loss: 1.3109 - val_accuracy: 0.7594\n",
      "Epoch 122/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1801 - accuracy: 0.9436 - val_loss: 1.3143 - val_accuracy: 0.7593\n",
      "Epoch 123/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1790 - accuracy: 0.9441 - val_loss: 1.3209 - val_accuracy: 0.7588\n",
      "Epoch 124/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1795 - accuracy: 0.9437 - val_loss: 1.3182 - val_accuracy: 0.7597\n",
      "Epoch 125/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1777 - accuracy: 0.9443 - val_loss: 1.3220 - val_accuracy: 0.7597\n",
      "Epoch 126/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1794 - accuracy: 0.9437 - val_loss: 1.3202 - val_accuracy: 0.7593\n",
      "Epoch 127/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1763 - accuracy: 0.9447 - val_loss: 1.3313 - val_accuracy: 0.7592\n",
      "Epoch 128/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1762 - accuracy: 0.9447 - val_loss: 1.3339 - val_accuracy: 0.7584\n",
      "Epoch 129/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1758 - accuracy: 0.9449 - val_loss: 1.3372 - val_accuracy: 0.7591\n",
      "Epoch 130/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1755 - accuracy: 0.9449 - val_loss: 1.3379 - val_accuracy: 0.7593\n",
      "Epoch 131/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1752 - accuracy: 0.9450 - val_loss: 1.3396 - val_accuracy: 0.7599\n",
      "Epoch 132/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1742 - accuracy: 0.9454 - val_loss: 1.3479 - val_accuracy: 0.7588\n",
      "Epoch 133/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1734 - accuracy: 0.9455 - val_loss: 1.3521 - val_accuracy: 0.7591\n",
      "Epoch 134/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1730 - accuracy: 0.9456 - val_loss: 1.3522 - val_accuracy: 0.7585\n",
      "Epoch 135/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1725 - accuracy: 0.9458 - val_loss: 1.3579 - val_accuracy: 0.7586\n",
      "Epoch 136/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1723 - accuracy: 0.9459 - val_loss: 1.3597 - val_accuracy: 0.7593\n",
      "Epoch 137/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1714 - accuracy: 0.9461 - val_loss: 1.3615 - val_accuracy: 0.7587\n",
      "Epoch 138/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1716 - accuracy: 0.9460 - val_loss: 1.3682 - val_accuracy: 0.7579\n",
      "Epoch 139/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1706 - accuracy: 0.9463 - val_loss: 1.3728 - val_accuracy: 0.7586\n",
      "Epoch 140/250\n",
      "565/565 [==============================] - 14s 26ms/step - loss: 0.1696 - accuracy: 0.9467 - val_loss: 1.3796 - val_accuracy: 0.7571\n",
      "Epoch 141/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1705 - accuracy: 0.9462 - val_loss: 1.3768 - val_accuracy: 0.7574\n",
      "Epoch 142/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.1697 - accuracy: 0.9465 - val_loss: 1.3881 - val_accuracy: 0.7581\n",
      "Epoch 143/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1686 - accuracy: 0.9470 - val_loss: 1.3859 - val_accuracy: 0.7587\n",
      "Epoch 144/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1684 - accuracy: 0.9470 - val_loss: 1.3823 - val_accuracy: 0.7581\n",
      "Epoch 145/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1678 - accuracy: 0.9470 - val_loss: 1.3870 - val_accuracy: 0.7581\n",
      "Epoch 146/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1669 - accuracy: 0.9473 - val_loss: 1.3985 - val_accuracy: 0.7570\n",
      "Epoch 147/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1662 - accuracy: 0.9476 - val_loss: 1.3896 - val_accuracy: 0.7577\n",
      "Epoch 148/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1668 - accuracy: 0.9474 - val_loss: 1.3961 - val_accuracy: 0.7579\n",
      "Epoch 149/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1658 - accuracy: 0.9478 - val_loss: 1.3991 - val_accuracy: 0.7578\n",
      "Epoch 150/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1660 - accuracy: 0.9475 - val_loss: 1.4039 - val_accuracy: 0.7580\n",
      "Epoch 151/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1650 - accuracy: 0.9479 - val_loss: 1.3987 - val_accuracy: 0.7580\n",
      "Epoch 152/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1651 - accuracy: 0.9478 - val_loss: 1.4061 - val_accuracy: 0.7579\n",
      "Epoch 153/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1648 - accuracy: 0.9479 - val_loss: 1.4148 - val_accuracy: 0.7574\n",
      "Epoch 154/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1645 - accuracy: 0.9479 - val_loss: 1.4191 - val_accuracy: 0.7567\n",
      "Epoch 155/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1641 - accuracy: 0.9481 - val_loss: 1.4139 - val_accuracy: 0.7571\n",
      "Epoch 156/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1637 - accuracy: 0.9483 - val_loss: 1.4187 - val_accuracy: 0.7575\n",
      "Epoch 157/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1626 - accuracy: 0.9486 - val_loss: 1.4248 - val_accuracy: 0.7568\n",
      "Epoch 158/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.1626 - accuracy: 0.9486 - val_loss: 1.4320 - val_accuracy: 0.7574\n",
      "Epoch 159/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.1622 - accuracy: 0.9488 - val_loss: 1.4268 - val_accuracy: 0.7565\n",
      "Epoch 160/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1620 - accuracy: 0.9487 - val_loss: 1.4230 - val_accuracy: 0.7573\n",
      "Epoch 161/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1611 - accuracy: 0.9490 - val_loss: 1.4342 - val_accuracy: 0.7569\n",
      "Epoch 162/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1609 - accuracy: 0.9491 - val_loss: 1.4327 - val_accuracy: 0.7571\n",
      "Epoch 163/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1618 - accuracy: 0.9487 - val_loss: 1.4393 - val_accuracy: 0.7572\n",
      "Epoch 164/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1596 - accuracy: 0.9495 - val_loss: 1.4353 - val_accuracy: 0.7571\n",
      "Epoch 165/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1602 - accuracy: 0.9494 - val_loss: 1.4460 - val_accuracy: 0.7567\n",
      "Epoch 166/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1599 - accuracy: 0.9494 - val_loss: 1.4572 - val_accuracy: 0.7564\n",
      "Epoch 167/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1592 - accuracy: 0.9496 - val_loss: 1.4512 - val_accuracy: 0.7565\n",
      "Epoch 168/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.1585 - accuracy: 0.9497 - val_loss: 1.4482 - val_accuracy: 0.7570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1583 - accuracy: 0.9498 - val_loss: 1.4550 - val_accuracy: 0.7572\n",
      "Epoch 170/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1585 - accuracy: 0.9497 - val_loss: 1.4605 - val_accuracy: 0.7567\n",
      "Epoch 171/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1590 - accuracy: 0.9495 - val_loss: 1.4556 - val_accuracy: 0.7569\n",
      "Epoch 172/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1584 - accuracy: 0.9498 - val_loss: 1.4540 - val_accuracy: 0.7574\n",
      "Epoch 173/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1566 - accuracy: 0.9503 - val_loss: 1.4631 - val_accuracy: 0.7564\n",
      "Epoch 174/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1565 - accuracy: 0.9504 - val_loss: 1.4752 - val_accuracy: 0.7561\n",
      "Epoch 175/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1572 - accuracy: 0.9500 - val_loss: 1.4652 - val_accuracy: 0.7560\n",
      "Epoch 176/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1568 - accuracy: 0.9501 - val_loss: 1.4745 - val_accuracy: 0.7559\n",
      "Epoch 177/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1577 - accuracy: 0.9498 - val_loss: 1.4758 - val_accuracy: 0.7559\n",
      "Epoch 178/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1573 - accuracy: 0.9500 - val_loss: 1.4752 - val_accuracy: 0.7564\n",
      "Epoch 179/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1551 - accuracy: 0.9507 - val_loss: 1.4762 - val_accuracy: 0.7564\n",
      "Epoch 180/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1558 - accuracy: 0.9505 - val_loss: 1.4771 - val_accuracy: 0.7570\n",
      "Epoch 181/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1540 - accuracy: 0.9511 - val_loss: 1.4818 - val_accuracy: 0.7566\n",
      "Epoch 182/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1550 - accuracy: 0.9508 - val_loss: 1.4845 - val_accuracy: 0.7560\n",
      "Epoch 183/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1543 - accuracy: 0.9509 - val_loss: 1.4932 - val_accuracy: 0.7563\n",
      "Epoch 184/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1566 - accuracy: 0.9501 - val_loss: 1.4943 - val_accuracy: 0.7562\n",
      "Epoch 185/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.1539 - accuracy: 0.9510 - val_loss: 1.4909 - val_accuracy: 0.7565\n",
      "Epoch 186/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1526 - accuracy: 0.9515 - val_loss: 1.4873 - val_accuracy: 0.7565\n",
      "Epoch 187/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1526 - accuracy: 0.9514 - val_loss: 1.4932 - val_accuracy: 0.7561\n",
      "Epoch 188/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1530 - accuracy: 0.9513 - val_loss: 1.4973 - val_accuracy: 0.7560\n",
      "Epoch 189/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1527 - accuracy: 0.9515 - val_loss: 1.5046 - val_accuracy: 0.7562\n",
      "Epoch 190/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1522 - accuracy: 0.9515 - val_loss: 1.5068 - val_accuracy: 0.7558\n",
      "Epoch 191/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1523 - accuracy: 0.9515 - val_loss: 1.5076 - val_accuracy: 0.7559\n",
      "Epoch 192/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1531 - accuracy: 0.9511 - val_loss: 1.4995 - val_accuracy: 0.7564\n",
      "Epoch 193/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1518 - accuracy: 0.9516 - val_loss: 1.5012 - val_accuracy: 0.7558\n",
      "Epoch 194/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1500 - accuracy: 0.9524 - val_loss: 1.5049 - val_accuracy: 0.7556\n",
      "Epoch 195/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1508 - accuracy: 0.9518 - val_loss: 1.5051 - val_accuracy: 0.7566\n",
      "Epoch 196/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1517 - accuracy: 0.9516 - val_loss: 1.5139 - val_accuracy: 0.7561\n",
      "Epoch 197/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1502 - accuracy: 0.9522 - val_loss: 1.5178 - val_accuracy: 0.7554\n",
      "Epoch 198/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1502 - accuracy: 0.9521 - val_loss: 1.5268 - val_accuracy: 0.7559\n",
      "Epoch 199/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1511 - accuracy: 0.9519 - val_loss: 1.5176 - val_accuracy: 0.7558\n",
      "Epoch 200/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1505 - accuracy: 0.9518 - val_loss: 1.5198 - val_accuracy: 0.7558\n",
      "Epoch 201/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1492 - accuracy: 0.9525 - val_loss: 1.5252 - val_accuracy: 0.7554\n",
      "Epoch 202/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.1504 - accuracy: 0.9521 - val_loss: 1.5227 - val_accuracy: 0.7563\n",
      "Epoch 203/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1492 - accuracy: 0.9524 - val_loss: 1.5325 - val_accuracy: 0.7559\n",
      "Epoch 204/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1492 - accuracy: 0.9523 - val_loss: 1.5367 - val_accuracy: 0.7552\n",
      "Epoch 205/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1480 - accuracy: 0.9526 - val_loss: 1.5284 - val_accuracy: 0.7560\n",
      "Epoch 206/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1478 - accuracy: 0.9529 - val_loss: 1.5372 - val_accuracy: 0.7555\n",
      "Epoch 207/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1477 - accuracy: 0.9529 - val_loss: 1.5330 - val_accuracy: 0.7554\n",
      "Epoch 208/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1478 - accuracy: 0.9528 - val_loss: 1.5341 - val_accuracy: 0.7558\n",
      "Epoch 209/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1475 - accuracy: 0.9529 - val_loss: 1.5380 - val_accuracy: 0.7555\n",
      "Epoch 210/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1486 - accuracy: 0.9524 - val_loss: 1.5485 - val_accuracy: 0.7543\n",
      "Epoch 211/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1475 - accuracy: 0.9527 - val_loss: 1.5480 - val_accuracy: 0.7551\n",
      "Epoch 212/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1468 - accuracy: 0.9530 - val_loss: 1.5367 - val_accuracy: 0.7562\n",
      "Epoch 213/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1462 - accuracy: 0.9532 - val_loss: 1.5518 - val_accuracy: 0.7550\n",
      "Epoch 214/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1472 - accuracy: 0.9529 - val_loss: 1.5474 - val_accuracy: 0.7549\n",
      "Epoch 215/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1469 - accuracy: 0.9530 - val_loss: 1.5513 - val_accuracy: 0.7552\n",
      "Epoch 216/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1458 - accuracy: 0.9533 - val_loss: 1.5483 - val_accuracy: 0.7560\n",
      "Epoch 217/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1457 - accuracy: 0.9534 - val_loss: 1.5595 - val_accuracy: 0.7542\n",
      "Epoch 218/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1455 - accuracy: 0.9534 - val_loss: 1.5589 - val_accuracy: 0.7555\n",
      "Epoch 219/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.1456 - accuracy: 0.9535 - val_loss: 1.5633 - val_accuracy: 0.7543\n",
      "Epoch 220/250\n",
      "565/565 [==============================] - 13s 24ms/step - loss: 0.1454 - accuracy: 0.9535 - val_loss: 1.5546 - val_accuracy: 0.7554\n",
      "Epoch 221/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.1457 - accuracy: 0.9533 - val_loss: 1.5676 - val_accuracy: 0.7543\n",
      "Epoch 222/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1445 - accuracy: 0.9537 - val_loss: 1.5663 - val_accuracy: 0.7549\n",
      "Epoch 223/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1444 - accuracy: 0.9537 - val_loss: 1.5655 - val_accuracy: 0.7542\n",
      "Epoch 224/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1444 - accuracy: 0.9538 - val_loss: 1.5655 - val_accuracy: 0.7550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1438 - accuracy: 0.9540 - val_loss: 1.5730 - val_accuracy: 0.7544\n",
      "Epoch 226/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1446 - accuracy: 0.9537 - val_loss: 1.5739 - val_accuracy: 0.7552\n",
      "Epoch 227/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1433 - accuracy: 0.9541 - val_loss: 1.5800 - val_accuracy: 0.7551\n",
      "Epoch 228/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.1434 - accuracy: 0.9539 - val_loss: 1.5799 - val_accuracy: 0.7541\n",
      "Epoch 229/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1446 - accuracy: 0.9534 - val_loss: 1.5765 - val_accuracy: 0.7543\n",
      "Epoch 230/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1437 - accuracy: 0.9538 - val_loss: 1.5842 - val_accuracy: 0.7537\n",
      "Epoch 231/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1434 - accuracy: 0.9540 - val_loss: 1.5974 - val_accuracy: 0.7542\n",
      "Epoch 232/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1430 - accuracy: 0.9542 - val_loss: 1.5851 - val_accuracy: 0.7548\n",
      "Epoch 233/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1426 - accuracy: 0.9542 - val_loss: 1.5819 - val_accuracy: 0.7551\n",
      "Epoch 234/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1420 - accuracy: 0.9546 - val_loss: 1.5865 - val_accuracy: 0.7546\n",
      "Epoch 235/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1429 - accuracy: 0.9540 - val_loss: 1.5893 - val_accuracy: 0.7548\n",
      "Epoch 236/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1437 - accuracy: 0.9538 - val_loss: 1.6020 - val_accuracy: 0.7542\n",
      "Epoch 237/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1425 - accuracy: 0.9542 - val_loss: 1.5924 - val_accuracy: 0.7551\n",
      "Epoch 238/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1415 - accuracy: 0.9547 - val_loss: 1.5988 - val_accuracy: 0.7542\n",
      "Epoch 239/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1415 - accuracy: 0.9545 - val_loss: 1.5868 - val_accuracy: 0.7556\n",
      "Epoch 240/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1415 - accuracy: 0.9546 - val_loss: 1.6009 - val_accuracy: 0.7544\n",
      "Epoch 241/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1412 - accuracy: 0.9547 - val_loss: 1.6012 - val_accuracy: 0.7544\n",
      "Epoch 242/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1422 - accuracy: 0.9542 - val_loss: 1.6028 - val_accuracy: 0.7545\n",
      "Epoch 243/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1406 - accuracy: 0.9548 - val_loss: 1.5926 - val_accuracy: 0.7547\n",
      "Epoch 244/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1402 - accuracy: 0.9549 - val_loss: 1.6120 - val_accuracy: 0.7543\n",
      "Epoch 245/250\n",
      "565/565 [==============================] - 14s 24ms/step - loss: 0.1409 - accuracy: 0.9548 - val_loss: 1.6044 - val_accuracy: 0.7544\n",
      "Epoch 246/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1398 - accuracy: 0.9550 - val_loss: 1.6068 - val_accuracy: 0.7544\n",
      "Epoch 247/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1415 - accuracy: 0.9545 - val_loss: 1.5966 - val_accuracy: 0.7546\n",
      "Epoch 248/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1407 - accuracy: 0.9547 - val_loss: 1.6117 - val_accuracy: 0.7539\n",
      "Epoch 249/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1397 - accuracy: 0.9551 - val_loss: 1.6037 - val_accuracy: 0.7546\n",
      "Epoch 250/250\n",
      "565/565 [==============================] - 14s 25ms/step - loss: 0.1404 - accuracy: 0.9546 - val_loss: 1.6160 - val_accuracy: 0.7546\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb09931",
   "metadata": {},
   "source": [
    "<h1>Guardar el modelo</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c59c1",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Diccionarios</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d954601",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/s2q/input_token_index.txt\", \"w\") as f:\n",
    "    json.dump(input_token_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e77635fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/s2q/target_token_index.txt\", \"w\") as f:\n",
    "    json.dump(target_token_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13f756f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/s2q/history.txt\", \"w\") as f:\n",
    "    json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445fbf86",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Valores puntuales</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e93b5e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_decoder_tokens: 104\n",
      "max_decoder_seq_length: 42\n",
      "Number of unique input tokens: 110\n",
      "Number of unique output tokens: 104\n",
      "Max sequence length for inputs: 40\n",
      "Max sequence length for outputs: 42\n"
     ]
    }
   ],
   "source": [
    "print(\"num_decoder_tokens: {}\".format(num_decoder_tokens))\n",
    "print(\"max_decoder_seq_length: {}\".format(max_decoder_seq_length))\n",
    "\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5be3bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Modelos/s2q/otros.txt\", \"w\") as f:\n",
    "    f.write(\"num_encoder_tokens = {}\\n\".format(num_encoder_tokens))\n",
    "    f.write(\"num_decoder_tokens = {}\\n\".format(num_decoder_tokens))\n",
    "    \n",
    "    f.write(\"max_encoder_seq_length = {}\\n\".format(max_encoder_seq_length))\n",
    "    f.write(\"max_decoder_seq_length = {}\".format(max_decoder_seq_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880cf75b",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Arreglo numpy</h3>\n",
    "<p>Sólo las primeras 100 posiciones</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e456f8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./Modelos/s2q/encoder_input_data_sample.npy\"\n",
    "with open(file_name, \"wb\") as f:\n",
    "    np.save(f, encoder_input_data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f12bbad",
   "metadata": {},
   "source": [
    "<h3 style=\"color:crimson\">Modelo</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f79defd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Modelos/s2q/spanish_to_quechua\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Modelos/s2q/spanish_to_quechua\\assets\n"
     ]
    }
   ],
   "source": [
    "# s2q = Spanish to Quechua\n",
    "model.save(\"./Modelos/s2q/spanish_to_quechua\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a0b29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./Modelos/s2q/spanish_to_quechua_file.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
